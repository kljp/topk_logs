2022-08-04 10:02:05,665 [dist_trainer.py:135] INFO Configurations: Namespace(batch_size=32, compressor='topk', data_dir='./data', dataset='cifar10', density=1.0, dnn='resnet20', lr=0.1, max_epochs=141, nsteps_update=1, num_steps=35, nworkers=8, nwpernode=8, pretrain=None, saved_dir='./logs/iclr', threshold=524288000)
2022-08-04 10:02:30,142 [dl_trainer.py:254] INFO num_batches_per_epoch: 196
2022-08-04 10:02:30,436 [distributed_optimizer.py:63] INFO _dynamic_densities: [0.015625, 0.004, 0.001]
2022-08-04 10:02:30,438 [distributed_optimizer.py:323] INFO # of parameters: 269722
2022-08-04 10:02:30,438 [distributed_optimizer.py:324] INFO Total number of tensors: 59
2022-08-04 10:02:30,438 [distributed_optimizer.py:325] INFO Merged Number of groups: 1
2022-08-04 10:02:31,170 [dist_trainer.py:62] INFO max_epochs: 141
2022-08-04 10:02:34,807 [dl_trainer.py:731] WARNING [  0][   40/  196][rank:0] loss: 1.957, average forward (0.049262) and backward (0.023476) time: 0.075101, iotime: 0.001513 
2022-08-04 10:02:34,872 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.090269, Speed: 354.496868 images/s
2022-08-04 10:02:36,715 [dl_trainer.py:731] WARNING [  0][   80/  196][rank:0] loss: 1.785, average forward (0.009177) and backward (0.021402) time: 0.032198, iotime: 0.001388 
2022-08-04 10:02:36,774 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047539, Speed: 673.126531 images/s
2022-08-04 10:02:38,640 [dl_trainer.py:731] WARNING [  0][  120/  196][rank:0] loss: 1.627, average forward (0.008989) and backward (0.021708) time: 0.032340, iotime: 0.001403 
2022-08-04 10:02:38,705 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048247, Speed: 663.252642 images/s
2022-08-04 10:02:40,503 [dl_trainer.py:731] WARNING [  0][  160/  196][rank:0] loss: 1.707, average forward (0.009673) and backward (0.021370) time: 0.032692, iotime: 0.001421 
2022-08-04 10:02:40,558 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046322, Speed: 690.819569 images/s
2022-08-04 10:02:42,178 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 1078
2022-08-04 10:02:42,179 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:02:42,351 [dl_trainer.py:634] INFO train iter: 196, num_batches_per_epoch: 196
2022-08-04 10:02:42,352 [dl_trainer.py:635] INFO Epoch 1, avg train acc: 35.889668, lr: 0.020082, avg loss: 1.769138
2022-08-04 10:02:44,982 [dl_trainer.py:822] INFO Epoch 1, lr: 0.020082, val loss: 1.695782, val top-1 acc: 38.458466, top-5 acc: 91.174121
2022-08-04 10:02:45,152 [dl_trainer.py:731] WARNING [  1][  200/  196][rank:0] loss: 1.356, average forward (0.010677) and backward (0.020791) time: 0.101962, iotime: 0.004400 
2022-08-04 10:02:46,863 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083866, Speed: 381.560735 images/s
2022-08-04 10:02:47,029 [dl_trainer.py:731] WARNING [  1][  240/  196][rank:0] loss: 1.701, average forward (0.009733) and backward (0.019572) time: 0.031013, iotime: 0.001455 
2022-08-04 10:02:48,744 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047011, Speed: 680.685713 images/s
2022-08-04 10:02:48,928 [dl_trainer.py:731] WARNING [  1][  280/  196][rank:0] loss: 1.084, average forward (0.009074) and backward (0.019338) time: 0.030016, iotime: 0.001373 
2022-08-04 10:02:50,625 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046995, Speed: 680.926064 images/s
2022-08-04 10:02:50,800 [dl_trainer.py:731] WARNING [  1][  320/  196][rank:0] loss: 1.318, average forward (0.009254) and backward (0.018523) time: 0.029470, iotime: 0.001435 
2022-08-04 10:02:52,582 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048912, Speed: 654.240237 images/s
2022-08-04 10:02:52,769 [dl_trainer.py:731] WARNING [  1][  360/  196][rank:0] loss: 1.020, average forward (0.008448) and backward (0.019447) time: 0.029426, iotime: 0.001299 
2022-08-04 10:02:54,183 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:02:54,183 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:02:54,434 [dl_trainer.py:634] INFO train iter: 392, num_batches_per_epoch: 196
2022-08-04 10:02:54,434 [dl_trainer.py:635] INFO Epoch 2, avg train acc: 56.457270, lr: 0.040061, avg loss: 1.223612
2022-08-04 10:02:57,061 [dl_trainer.py:822] INFO Epoch 2, lr: 0.040061, val loss: 1.428845, val top-1 acc: 54.263179, top-5 acc: 95.017971
2022-08-04 10:02:57,480 [dl_trainer.py:731] WARNING [  2][  400/  196][rank:0] loss: 1.075, average forward (0.010181) and backward (0.021237) time: 0.104011, iotime: 0.005311 
2022-08-04 10:02:58,968 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085139, Speed: 375.854390 images/s
2022-08-04 10:02:59,378 [dl_trainer.py:731] WARNING [  2][  440/  196][rank:0] loss: 1.045, average forward (0.010180) and backward (0.022440) time: 0.034421, iotime: 0.001554 
2022-08-04 10:03:00,779 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045260, Speed: 707.023833 images/s
2022-08-04 10:03:01,165 [dl_trainer.py:731] WARNING [  2][  480/  196][rank:0] loss: 1.164, average forward (0.009762) and backward (0.019123) time: 0.030617, iotime: 0.001493 
2022-08-04 10:03:02,609 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045742, Speed: 699.582732 images/s
2022-08-04 10:03:03,011 [dl_trainer.py:731] WARNING [  2][  520/  196][rank:0] loss: 0.824, average forward (0.011298) and backward (0.020329) time: 0.033590, iotime: 0.001705 
2022-08-04 10:03:04,465 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046403, Speed: 689.612228 images/s
2022-08-04 10:03:04,865 [dl_trainer.py:731] WARNING [  2][  560/  196][rank:0] loss: 1.250, average forward (0.010790) and backward (0.019290) time: 0.031852, iotime: 0.001510 
2022-08-04 10:03:06,080 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:03:06,080 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:03:06,386 [dl_trainer.py:634] INFO train iter: 588, num_batches_per_epoch: 196
2022-08-04 10:03:06,386 [dl_trainer.py:635] INFO Epoch 3, avg train acc: 65.497449, lr: 0.060041, avg loss: 0.976649
2022-08-04 10:03:09,003 [dl_trainer.py:822] INFO Epoch 3, lr: 0.060041, val loss: 1.494115, val top-1 acc: 55.221645, top-5 acc: 94.249201
2022-08-04 10:03:09,569 [dl_trainer.py:731] WARNING [  3][  600/  196][rank:0] loss: 1.025, average forward (0.011271) and backward (0.021360) time: 0.103581, iotime: 0.005190 
2022-08-04 10:03:10,815 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084639, Speed: 378.075963 images/s
2022-08-04 10:03:11,455 [dl_trainer.py:731] WARNING [  3][  640/  196][rank:0] loss: 0.854, average forward (0.009540) and backward (0.021313) time: 0.032612, iotime: 0.001508 
2022-08-04 10:03:12,688 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046809, Speed: 683.633398 images/s
2022-08-04 10:03:13,349 [dl_trainer.py:731] WARNING [  3][  680/  196][rank:0] loss: 0.715, average forward (0.010299) and backward (0.017690) time: 0.029723, iotime: 0.001483 
2022-08-04 10:03:14,557 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046717, Speed: 684.978025 images/s
2022-08-04 10:03:15,207 [dl_trainer.py:731] WARNING [  3][  720/  196][rank:0] loss: 0.899, average forward (0.011183) and backward (0.019395) time: 0.032400, iotime: 0.001543 
2022-08-04 10:03:16,451 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047349, Speed: 675.831116 images/s
2022-08-04 10:03:17,077 [dl_trainer.py:731] WARNING [  3][  760/  196][rank:0] loss: 0.634, average forward (0.009586) and backward (0.018057) time: 0.029337, iotime: 0.001451 
2022-08-04 10:03:18,041 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:03:18,041 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:03:18,393 [dl_trainer.py:634] INFO train iter: 784, num_batches_per_epoch: 196
2022-08-04 10:03:18,393 [dl_trainer.py:635] INFO Epoch 4, avg train acc: 70.535714, lr: 0.080020, avg loss: 0.823415
2022-08-04 10:03:20,995 [dl_trainer.py:822] INFO Epoch 4, lr: 0.080020, val loss: 1.032888, val top-1 acc: 66.663339, top-5 acc: 97.414137
2022-08-04 10:03:21,742 [dl_trainer.py:731] WARNING [  4][  800/  196][rank:0] loss: 0.763, average forward (0.009752) and backward (0.020319) time: 0.101016, iotime: 0.005167 
2022-08-04 10:03:22,781 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084379, Speed: 379.240770 images/s
2022-08-04 10:03:23,715 [dl_trainer.py:731] WARNING [  4][  840/  196][rank:0] loss: 0.726, average forward (0.010721) and backward (0.018720) time: 0.031400, iotime: 0.001706 
2022-08-04 10:03:24,697 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047890, Speed: 668.199346 images/s
2022-08-04 10:03:25,599 [dl_trainer.py:731] WARNING [  4][  880/  196][rank:0] loss: 0.689, average forward (0.009063) and backward (0.017597) time: 0.028293, iotime: 0.001394 
2022-08-04 10:03:26,636 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048470, Speed: 660.197770 images/s
2022-08-04 10:03:27,534 [dl_trainer.py:731] WARNING [  4][  920/  196][rank:0] loss: 0.610, average forward (0.009087) and backward (0.018532) time: 0.029308, iotime: 0.001456 
2022-08-04 10:03:28,574 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048442, Speed: 660.588015 images/s
2022-08-04 10:03:29,371 [dl_trainer.py:731] WARNING [  4][  960/  196][rank:0] loss: 0.611, average forward (0.009859) and backward (0.019691) time: 0.031242, iotime: 0.001445 
2022-08-04 10:03:30,112 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:03:30,112 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:03:30,511 [dl_trainer.py:634] INFO train iter: 980, num_batches_per_epoch: 196
2022-08-04 10:03:30,511 [dl_trainer.py:635] INFO Epoch 5, avg train acc: 73.628827, lr: 0.100000, avg loss: 0.747737
2022-08-04 10:03:33,137 [dl_trainer.py:822] INFO Epoch 5, lr: 0.100000, val loss: 0.736396, val top-1 acc: 75.628994, top-5 acc: 98.242812
2022-08-04 10:03:34,098 [dl_trainer.py:731] WARNING [  5][ 1000/  196][rank:0] loss: 0.946, average forward (0.009939) and backward (0.020689) time: 0.101719, iotime: 0.005111 
2022-08-04 10:03:34,853 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083702, Speed: 382.307599 images/s
2022-08-04 10:03:36,026 [dl_trainer.py:731] WARNING [  5][ 1040/  196][rank:0] loss: 0.946, average forward (0.010681) and backward (0.021871) time: 0.034362, iotime: 0.001554 
2022-08-04 10:03:36,786 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048303, Speed: 662.481515 images/s
2022-08-04 10:03:37,920 [dl_trainer.py:731] WARNING [  5][ 1080/  196][rank:0] loss: 0.955, average forward (0.010192) and backward (0.022343) time: 0.034320, iotime: 0.001531 
2022-08-04 10:03:38,663 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046909, Speed: 682.170240 images/s
2022-08-04 10:03:39,751 [dl_trainer.py:731] WARNING [  5][ 1120/  196][rank:0] loss: 0.855, average forward (0.011323) and backward (0.020400) time: 0.033596, iotime: 0.001604 
2022-08-04 10:03:40,505 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046039, Speed: 695.068413 images/s
2022-08-04 10:03:41,656 [dl_trainer.py:731] WARNING [  5][ 1160/  196][rank:0] loss: 0.493, average forward (0.009368) and backward (0.021685) time: 0.032712, iotime: 0.001421 
2022-08-04 10:03:42,160 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:03:42,160 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:03:42,598 [dl_trainer.py:634] INFO train iter: 1176, num_batches_per_epoch: 196
2022-08-04 10:03:42,598 [dl_trainer.py:635] INFO Epoch 6, avg train acc: 76.961097, lr: 0.100000, avg loss: 0.671674
2022-08-04 10:03:45,223 [dl_trainer.py:822] INFO Epoch 6, lr: 0.100000, val loss: 0.731873, val top-1 acc: 75.219649, top-5 acc: 98.602236
2022-08-04 10:03:46,378 [dl_trainer.py:731] WARNING [  6][ 1200/  196][rank:0] loss: 0.465, average forward (0.008916) and backward (0.019821) time: 0.100146, iotime: 0.005063 
2022-08-04 10:03:46,947 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085878, Speed: 372.623418 images/s
2022-08-04 10:03:48,280 [dl_trainer.py:731] WARNING [  6][ 1240/  196][rank:0] loss: 0.520, average forward (0.009137) and backward (0.016422) time: 0.027238, iotime: 0.001426 
2022-08-04 10:03:48,820 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046820, Speed: 683.471521 images/s
2022-08-04 10:03:50,199 [dl_trainer.py:731] WARNING [  6][ 1280/  196][rank:0] loss: 0.403, average forward (0.008959) and backward (0.018512) time: 0.029196, iotime: 0.001475 
2022-08-04 10:03:50,744 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048109, Speed: 665.159162 images/s
2022-08-04 10:03:52,143 [dl_trainer.py:731] WARNING [  6][ 1320/  196][rank:0] loss: 0.837, average forward (0.009046) and backward (0.018972) time: 0.029713, iotime: 0.001448 
2022-08-04 10:03:52,714 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049229, Speed: 650.022075 images/s
2022-08-04 10:03:54,062 [dl_trainer.py:731] WARNING [  6][ 1360/  196][rank:0] loss: 0.384, average forward (0.009529) and backward (0.019713) time: 0.030907, iotime: 0.001421 
2022-08-04 10:03:54,319 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:03:54,319 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:03:54,800 [dl_trainer.py:634] INFO train iter: 1372, num_batches_per_epoch: 196
2022-08-04 10:03:54,801 [dl_trainer.py:635] INFO Epoch 7, avg train acc: 80.309311, lr: 0.100000, avg loss: 0.583624
2022-08-04 10:03:57,415 [dl_trainer.py:822] INFO Epoch 7, lr: 0.100000, val loss: 0.697336, val top-1 acc: 77.436102, top-5 acc: 98.232827
2022-08-04 10:03:58,744 [dl_trainer.py:731] WARNING [  7][ 1400/  196][rank:0] loss: 0.552, average forward (0.010351) and backward (0.021231) time: 0.102382, iotime: 0.005093 
2022-08-04 10:03:59,053 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084503, Speed: 378.684443 images/s
2022-08-04 10:04:00,700 [dl_trainer.py:731] WARNING [  7][ 1440/  196][rank:0] loss: 0.312, average forward (0.010699) and backward (0.021559) time: 0.034036, iotime: 0.001517 
2022-08-04 10:04:01,016 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049075, Speed: 652.057130 images/s
2022-08-04 10:04:02,607 [dl_trainer.py:731] WARNING [  7][ 1480/  196][rank:0] loss: 0.592, average forward (0.010985) and backward (0.021982) time: 0.034819, iotime: 0.001600 
2022-08-04 10:04:02,897 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047008, Speed: 680.735686 images/s
2022-08-04 10:04:04,459 [dl_trainer.py:731] WARNING [  7][ 1520/  196][rank:0] loss: 0.482, average forward (0.010240) and backward (0.020877) time: 0.032936, iotime: 0.001562 
2022-08-04 10:04:04,754 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046417, Speed: 689.407047 images/s
2022-08-04 10:04:06,357 [dl_trainer.py:731] WARNING [  7][ 1560/  196][rank:0] loss: 0.560, average forward (0.010867) and backward (0.020740) time: 0.033443, iotime: 0.001569 
2022-08-04 10:04:06,365 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:04:06,365 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:04:06,873 [dl_trainer.py:634] INFO train iter: 1568, num_batches_per_epoch: 196
2022-08-04 10:04:06,874 [dl_trainer.py:635] INFO Epoch 8, avg train acc: 81.441327, lr: 0.100000, avg loss: 0.544589
2022-08-04 10:04:09,498 [dl_trainer.py:822] INFO Epoch 8, lr: 0.100000, val loss: 0.626195, val top-1 acc: 79.113419, top-5 acc: 98.761981
2022-08-04 10:04:11,215 [dl_trainer.py:731] WARNING [  8][ 1600/  196][rank:0] loss: 0.490, average forward (0.009595) and backward (0.019778) time: 0.105991, iotime: 0.005218 
2022-08-04 10:04:11,278 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.086948, Speed: 368.037451 images/s
2022-08-04 10:04:13,067 [dl_trainer.py:731] WARNING [  8][ 1640/  196][rank:0] loss: 0.452, average forward (0.009297) and backward (0.018570) time: 0.029583, iotime: 0.001474 
2022-08-04 10:04:13,131 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046324, Speed: 690.791392 images/s
2022-08-04 10:04:14,983 [dl_trainer.py:731] WARNING [  8][ 1680/  196][rank:0] loss: 0.296, average forward (0.009006) and backward (0.019383) time: 0.030043, iotime: 0.001422 
2022-08-04 10:04:15,042 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047775, Speed: 669.805209 images/s
2022-08-04 10:04:16,829 [dl_trainer.py:731] WARNING [  8][ 1720/  196][rank:0] loss: 0.162, average forward (0.010698) and backward (0.018063) time: 0.030617, iotime: 0.001596 
2022-08-04 10:04:16,886 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046091, Speed: 694.277958 images/s
2022-08-04 10:04:18,497 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:04:18,498 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:04:18,870 [dl_trainer.py:731] WARNING [  8][ 1760/  196][rank:0] loss: 0.570, average forward (0.009383) and backward (0.020520) time: 0.035337, iotime: 0.005180 
2022-08-04 10:04:19,100 [dl_trainer.py:634] INFO train iter: 1764, num_batches_per_epoch: 196
2022-08-04 10:04:19,100 [dl_trainer.py:635] INFO Epoch 9, avg train acc: 82.621173, lr: 0.100000, avg loss: 0.504124
2022-08-04 10:04:21,821 [dl_trainer.py:822] INFO Epoch 9, lr: 0.100000, val loss: 0.800231, val top-1 acc: 76.108227, top-5 acc: 97.464058
2022-08-04 10:04:23,345 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.086097, Speed: 371.672017 images/s
2022-08-04 10:04:23,528 [dl_trainer.py:731] WARNING [  9][ 1800/  196][rank:0] loss: 0.867, average forward (0.009746) and backward (0.019756) time: 0.099329, iotime: 0.001494 
2022-08-04 10:04:25,216 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046769, Speed: 684.221066 images/s
2022-08-04 10:04:25,394 [dl_trainer.py:731] WARNING [  9][ 1840/  196][rank:0] loss: 0.730, average forward (0.010890) and backward (0.019991) time: 0.032747, iotime: 0.001598 
2022-08-04 10:04:27,125 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047710, Speed: 670.718403 images/s
2022-08-04 10:04:27,300 [dl_trainer.py:731] WARNING [  9][ 1880/  196][rank:0] loss: 0.436, average forward (0.009135) and backward (0.020672) time: 0.031453, iotime: 0.001417 
2022-08-04 10:04:29,009 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047084, Speed: 679.638062 images/s
2022-08-04 10:04:29,185 [dl_trainer.py:731] WARNING [  9][ 1920/  196][rank:0] loss: 0.480, average forward (0.009855) and backward (0.020318) time: 0.031910, iotime: 0.001488 
2022-08-04 10:04:30,649 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:04:30,649 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:04:31,244 [dl_trainer.py:731] WARNING [  9][ 1960/  196][rank:0] loss: 0.321, average forward (0.010008) and backward (0.021103) time: 0.036582, iotime: 0.005212 
2022-08-04 10:04:31,261 [dl_trainer.py:634] INFO train iter: 1960, num_batches_per_epoch: 196
2022-08-04 10:04:31,261 [dl_trainer.py:635] INFO Epoch 10, avg train acc: 83.434311, lr: 0.100000, avg loss: 0.482067
2022-08-04 10:04:33,911 [dl_trainer.py:822] INFO Epoch 10, lr: 0.100000, val loss: 0.708409, val top-1 acc: 78.274760, top-5 acc: 97.903355
2022-08-04 10:04:35,383 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084960, Speed: 376.646694 images/s
2022-08-04 10:04:35,771 [dl_trainer.py:731] WARNING [ 10][ 2000/  196][rank:0] loss: 0.413, average forward (0.010312) and backward (0.020130) time: 0.098941, iotime: 0.001496 
2022-08-04 10:04:37,260 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046934, Speed: 681.807939 images/s
2022-08-04 10:04:37,645 [dl_trainer.py:731] WARNING [ 10][ 2040/  196][rank:0] loss: 0.453, average forward (0.010515) and backward (0.019787) time: 0.032111, iotime: 0.001542 
2022-08-04 10:04:39,137 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046891, Speed: 682.436449 images/s
2022-08-04 10:04:39,551 [dl_trainer.py:731] WARNING [ 10][ 2080/  196][rank:0] loss: 0.736, average forward (0.008817) and backward (0.018830) time: 0.029227, iotime: 0.001339 
2022-08-04 10:04:41,071 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048358, Speed: 661.731998 images/s
2022-08-04 10:04:41,499 [dl_trainer.py:731] WARNING [ 10][ 2120/  196][rank:0] loss: 0.359, average forward (0.008247) and backward (0.019967) time: 0.029773, iotime: 0.001341 
2022-08-04 10:04:42,695 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:04:42,696 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:04:43,399 [dl_trainer.py:634] INFO train iter: 2156, num_batches_per_epoch: 196
2022-08-04 10:04:43,399 [dl_trainer.py:635] INFO Epoch 11, avg train acc: 84.853316, lr: 0.100000, avg loss: 0.435711
2022-08-04 10:04:46,042 [dl_trainer.py:822] INFO Epoch 11, lr: 0.100000, val loss: 0.566532, val top-1 acc: 81.329872, top-5 acc: 99.321086
2022-08-04 10:04:46,220 [dl_trainer.py:731] WARNING [ 11][ 2160/  196][rank:0] loss: 0.278, average forward (0.009384) and backward (0.020808) time: 0.101616, iotime: 0.005019 
2022-08-04 10:04:47,469 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085276, Speed: 375.253998 images/s
2022-08-04 10:04:48,084 [dl_trainer.py:731] WARNING [ 11][ 2200/  196][rank:0] loss: 1.101, average forward (0.010176) and backward (0.022106) time: 0.033946, iotime: 0.001414 
2022-08-04 10:04:49,318 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046233, Speed: 692.147844 images/s
2022-08-04 10:04:49,974 [dl_trainer.py:731] WARNING [ 11][ 2240/  196][rank:0] loss: 0.583, average forward (0.011531) and backward (0.021865) time: 0.035255, iotime: 0.001602 
2022-08-04 10:04:51,203 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047101, Speed: 679.392171 images/s
2022-08-04 10:04:51,865 [dl_trainer.py:731] WARNING [ 11][ 2280/  196][rank:0] loss: 0.537, average forward (0.008848) and backward (0.020212) time: 0.030703, iotime: 0.001415 
2022-08-04 10:04:53,064 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046513, Speed: 687.980628 images/s
2022-08-04 10:04:53,670 [dl_trainer.py:731] WARNING [ 11][ 2320/  196][rank:0] loss: 0.322, average forward (0.010533) and backward (0.019230) time: 0.031532, iotime: 0.001536 
2022-08-04 10:04:54,646 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:04:54,646 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:04:55,372 [dl_trainer.py:634] INFO train iter: 2352, num_batches_per_epoch: 196
2022-08-04 10:04:55,373 [dl_trainer.py:635] INFO Epoch 12, avg train acc: 85.267857, lr: 0.100000, avg loss: 0.435295
2022-08-04 10:04:58,059 [dl_trainer.py:822] INFO Epoch 12, lr: 0.100000, val loss: 0.533263, val top-1 acc: 82.507987, top-5 acc: 99.131390
2022-08-04 10:04:58,429 [dl_trainer.py:731] WARNING [ 12][ 2360/  196][rank:0] loss: 0.277, average forward (0.011064) and backward (0.021004) time: 0.105275, iotime: 0.005298 
2022-08-04 10:04:59,400 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084469, Speed: 378.839272 images/s
2022-08-04 10:05:00,230 [dl_trainer.py:731] WARNING [ 12][ 2400/  196][rank:0] loss: 0.398, average forward (0.011053) and backward (0.019563) time: 0.032471, iotime: 0.001594 
2022-08-04 10:05:01,262 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046540, Speed: 687.573208 images/s
2022-08-04 10:05:02,160 [dl_trainer.py:731] WARNING [ 12][ 2440/  196][rank:0] loss: 0.628, average forward (0.008365) and backward (0.020048) time: 0.030011, iotime: 0.001362 
2022-08-04 10:05:03,168 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047623, Speed: 671.945959 images/s
2022-08-04 10:05:04,030 [dl_trainer.py:731] WARNING [ 12][ 2480/  196][rank:0] loss: 0.324, average forward (0.010023) and backward (0.018327) time: 0.030088, iotime: 0.001488 
2022-08-04 10:05:05,009 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046035, Speed: 695.125831 images/s
2022-08-04 10:05:05,878 [dl_trainer.py:731] WARNING [ 12][ 2520/  196][rank:0] loss: 0.406, average forward (0.010700) and backward (0.019470) time: 0.032004, iotime: 0.001568 
2022-08-04 10:05:06,582 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:05:06,582 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:05:07,344 [dl_trainer.py:634] INFO train iter: 2548, num_batches_per_epoch: 196
2022-08-04 10:05:07,345 [dl_trainer.py:635] INFO Epoch 13, avg train acc: 85.634566, lr: 0.100000, avg loss: 0.421563
2022-08-04 10:05:09,954 [dl_trainer.py:822] INFO Epoch 13, lr: 0.100000, val loss: 0.726435, val top-1 acc: 77.545927, top-5 acc: 98.801917
2022-08-04 10:05:10,518 [dl_trainer.py:731] WARNING [ 13][ 2560/  196][rank:0] loss: 0.739, average forward (0.011322) and backward (0.019789) time: 0.102365, iotime: 0.005641 
2022-08-04 10:05:11,268 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083430, Speed: 383.553990 images/s
2022-08-04 10:05:12,390 [dl_trainer.py:731] WARNING [ 13][ 2600/  196][rank:0] loss: 0.214, average forward (0.010622) and backward (0.021266) time: 0.033747, iotime: 0.001607 
2022-08-04 10:05:13,172 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047584, Speed: 672.497691 images/s
2022-08-04 10:05:14,273 [dl_trainer.py:731] WARNING [ 13][ 2640/  196][rank:0] loss: 0.426, average forward (0.009882) and backward (0.020144) time: 0.031842, iotime: 0.001571 
2022-08-04 10:05:14,981 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045231, Speed: 707.476267 images/s
2022-08-04 10:05:16,088 [dl_trainer.py:731] WARNING [ 13][ 2680/  196][rank:0] loss: 0.336, average forward (0.010673) and backward (0.019562) time: 0.032080, iotime: 0.001596 
2022-08-04 10:05:16,862 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046993, Speed: 680.946360 images/s
2022-08-04 10:05:18,017 [dl_trainer.py:731] WARNING [ 13][ 2720/  196][rank:0] loss: 0.578, average forward (0.009390) and backward (0.021239) time: 0.032325, iotime: 0.001459 
2022-08-04 10:05:18,515 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:05:18,515 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:05:19,343 [dl_trainer.py:634] INFO train iter: 2744, num_batches_per_epoch: 196
2022-08-04 10:05:19,344 [dl_trainer.py:635] INFO Epoch 14, avg train acc: 85.841837, lr: 0.100000, avg loss: 0.413969
2022-08-04 10:05:21,992 [dl_trainer.py:822] INFO Epoch 14, lr: 0.100000, val loss: 0.588824, val top-1 acc: 80.601038, top-5 acc: 98.851837
2022-08-04 10:05:22,771 [dl_trainer.py:731] WARNING [ 14][ 2760/  196][rank:0] loss: 0.391, average forward (0.009765) and backward (0.016594) time: 0.098881, iotime: 0.004937 
2022-08-04 10:05:23,314 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.086014, Speed: 372.030752 images/s
2022-08-04 10:05:24,717 [dl_trainer.py:731] WARNING [ 14][ 2800/  196][rank:0] loss: 0.300, average forward (0.010124) and backward (0.020812) time: 0.032682, iotime: 0.001487 
2022-08-04 10:05:25,268 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048833, Speed: 655.296086 images/s
2022-08-04 10:05:26,630 [dl_trainer.py:731] WARNING [ 14][ 2840/  196][rank:0] loss: 0.421, average forward (0.009523) and backward (0.020382) time: 0.031586, iotime: 0.001439 
2022-08-04 10:05:27,160 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047292, Speed: 676.641243 images/s
2022-08-04 10:05:28,505 [dl_trainer.py:731] WARNING [ 14][ 2880/  196][rank:0] loss: 0.450, average forward (0.009324) and backward (0.020074) time: 0.031070, iotime: 0.001435 
2022-08-04 10:05:29,054 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047364, Speed: 675.617473 images/s
2022-08-04 10:05:30,463 [dl_trainer.py:731] WARNING [ 14][ 2920/  196][rank:0] loss: 0.459, average forward (0.008913) and backward (0.020006) time: 0.030506, iotime: 0.001346 
2022-08-04 10:05:30,718 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:05:30,719 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:05:31,600 [dl_trainer.py:634] INFO train iter: 2940, num_batches_per_epoch: 196
2022-08-04 10:05:31,601 [dl_trainer.py:635] INFO Epoch 15, avg train acc: 86.527423, lr: 0.100000, avg loss: 0.392162
2022-08-04 10:05:34,257 [dl_trainer.py:822] INFO Epoch 15, lr: 0.100000, val loss: 0.560410, val top-1 acc: 82.058706, top-5 acc: 98.931709
2022-08-04 10:05:35,199 [dl_trainer.py:731] WARNING [ 15][ 2960/  196][rank:0] loss: 0.274, average forward (0.010764) and backward (0.020297) time: 0.103274, iotime: 0.005469 
2022-08-04 10:05:35,504 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085985, Speed: 372.156837 images/s
2022-08-04 10:05:37,057 [dl_trainer.py:731] WARNING [ 15][ 3000/  196][rank:0] loss: 0.367, average forward (0.008667) and backward (0.019131) time: 0.029444, iotime: 0.001416 
2022-08-04 10:05:37,368 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046587, Speed: 686.881505 images/s
2022-08-04 10:05:39,006 [dl_trainer.py:731] WARNING [ 15][ 3040/  196][rank:0] loss: 0.585, average forward (0.010473) and backward (0.018500) time: 0.030791, iotime: 0.001570 
2022-08-04 10:05:39,307 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048458, Speed: 660.360018 images/s
2022-08-04 10:05:40,929 [dl_trainer.py:731] WARNING [ 15][ 3080/  196][rank:0] loss: 0.243, average forward (0.009146) and backward (0.019886) time: 0.030788, iotime: 0.001519 
2022-08-04 10:05:41,229 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048056, Speed: 665.885659 images/s
2022-08-04 10:05:42,764 [dl_trainer.py:731] WARNING [ 15][ 3120/  196][rank:0] loss: 0.252, average forward (0.009772) and backward (0.018856) time: 0.030307, iotime: 0.001443 
2022-08-04 10:05:42,787 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:05:42,787 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:05:43,687 [dl_trainer.py:634] INFO train iter: 3136, num_batches_per_epoch: 196
2022-08-04 10:05:43,688 [dl_trainer.py:635] INFO Epoch 16, avg train acc: 86.670918, lr: 0.100000, avg loss: 0.378585
2022-08-04 10:05:46,346 [dl_trainer.py:822] INFO Epoch 16, lr: 0.100000, val loss: 0.566205, val top-1 acc: 81.309904, top-5 acc: 99.201278
2022-08-04 10:05:47,468 [dl_trainer.py:731] WARNING [ 16][ 3160/  196][rank:0] loss: 0.316, average forward (0.010095) and backward (0.019748) time: 0.102416, iotime: 0.005236 
2022-08-04 10:05:47,534 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084052, Speed: 380.717088 images/s
2022-08-04 10:05:49,304 [dl_trainer.py:731] WARNING [ 16][ 3200/  196][rank:0] loss: 0.277, average forward (0.010094) and backward (0.020983) time: 0.032847, iotime: 0.001523 
2022-08-04 10:05:49,367 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045815, Speed: 698.455252 images/s
2022-08-04 10:05:51,179 [dl_trainer.py:731] WARNING [ 16][ 3240/  196][rank:0] loss: 0.270, average forward (0.009451) and backward (0.020146) time: 0.031370, iotime: 0.001512 
2022-08-04 10:05:51,237 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046742, Speed: 684.611689 images/s
2022-08-04 10:05:53,081 [dl_trainer.py:731] WARNING [ 16][ 3280/  196][rank:0] loss: 0.335, average forward (0.011024) and backward (0.020427) time: 0.033291, iotime: 0.001589 
2022-08-04 10:05:53,143 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047627, Speed: 671.890794 images/s
2022-08-04 10:05:54,701 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:05:54,702 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:05:55,075 [dl_trainer.py:731] WARNING [ 16][ 3320/  196][rank:0] loss: 0.456, average forward (0.008899) and backward (0.018056) time: 0.032329, iotime: 0.005134 
2022-08-04 10:05:55,673 [dl_trainer.py:634] INFO train iter: 3332, num_batches_per_epoch: 196
2022-08-04 10:05:55,674 [dl_trainer.py:635] INFO Epoch 17, avg train acc: 87.388393, lr: 0.100000, avg loss: 0.364205
2022-08-04 10:05:58,302 [dl_trainer.py:822] INFO Epoch 17, lr: 0.100000, val loss: 0.566052, val top-1 acc: 82.727636, top-5 acc: 98.931709
2022-08-04 10:05:59,481 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084489, Speed: 378.747078 images/s
2022-08-04 10:05:59,653 [dl_trainer.py:731] WARNING [ 17][ 3360/  196][rank:0] loss: 0.350, average forward (0.009923) and backward (0.018909) time: 0.096354, iotime: 0.001491 
2022-08-04 10:06:01,360 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046968, Speed: 681.312414 images/s
2022-08-04 10:06:01,530 [dl_trainer.py:731] WARNING [ 17][ 3400/  196][rank:0] loss: 0.298, average forward (0.008868) and backward (0.018683) time: 0.029127, iotime: 0.001349 
2022-08-04 10:06:03,250 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047231, Speed: 677.522735 images/s
2022-08-04 10:06:03,424 [dl_trainer.py:731] WARNING [ 17][ 3440/  196][rank:0] loss: 0.272, average forward (0.009159) and backward (0.019707) time: 0.030504, iotime: 0.001398 
2022-08-04 10:06:05,117 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046670, Speed: 685.671239 images/s
2022-08-04 10:06:05,303 [dl_trainer.py:731] WARNING [ 17][ 3480/  196][rank:0] loss: 0.304, average forward (0.010034) and backward (0.020117) time: 0.031891, iotime: 0.001498 
2022-08-04 10:06:06,755 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:06:06,755 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:06:07,365 [dl_trainer.py:731] WARNING [ 17][ 3520/  196][rank:0] loss: 0.221, average forward (0.009760) and backward (0.021022) time: 0.036174, iotime: 0.005128 
2022-08-04 10:06:07,762 [dl_trainer.py:634] INFO train iter: 3528, num_batches_per_epoch: 196
2022-08-04 10:06:07,762 [dl_trainer.py:635] INFO Epoch 18, avg train acc: 87.547832, lr: 0.100000, avg loss: 0.362992
2022-08-04 10:06:10,403 [dl_trainer.py:822] INFO Epoch 18, lr: 0.100000, val loss: 0.594215, val top-1 acc: 81.210064, top-5 acc: 99.351038
2022-08-04 10:06:11,513 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085262, Speed: 375.314593 images/s
2022-08-04 10:06:11,915 [dl_trainer.py:731] WARNING [ 18][ 3560/  196][rank:0] loss: 0.267, average forward (0.010608) and backward (0.021463) time: 0.100476, iotime: 0.001628 
2022-08-04 10:06:13,385 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046769, Speed: 684.207986 images/s
2022-08-04 10:06:13,795 [dl_trainer.py:731] WARNING [ 18][ 3600/  196][rank:0] loss: 0.266, average forward (0.009708) and backward (0.020384) time: 0.031864, iotime: 0.001525 
2022-08-04 10:06:15,243 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046436, Speed: 689.124669 images/s
2022-08-04 10:06:15,659 [dl_trainer.py:731] WARNING [ 18][ 3640/  196][rank:0] loss: 0.627, average forward (0.009932) and backward (0.021919) time: 0.033570, iotime: 0.001480 
2022-08-04 10:06:17,104 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046512, Speed: 687.995793 images/s
2022-08-04 10:06:17,522 [dl_trainer.py:731] WARNING [ 18][ 3680/  196][rank:0] loss: 0.566, average forward (0.009315) and backward (0.019525) time: 0.030531, iotime: 0.001448 
2022-08-04 10:06:18,731 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:06:18,731 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:06:19,583 [dl_trainer.py:731] WARNING [ 18][ 3720/  196][rank:0] loss: 0.355, average forward (0.009908) and backward (0.020476) time: 0.036191, iotime: 0.005540 
2022-08-04 10:06:19,798 [dl_trainer.py:634] INFO train iter: 3724, num_batches_per_epoch: 196
2022-08-04 10:06:19,799 [dl_trainer.py:635] INFO Epoch 19, avg train acc: 88.297194, lr: 0.100000, avg loss: 0.335313
2022-08-04 10:06:22,462 [dl_trainer.py:822] INFO Epoch 19, lr: 0.100000, val loss: 0.499730, val top-1 acc: 83.915735, top-5 acc: 99.151358
2022-08-04 10:06:23,503 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085304, Speed: 375.126897 images/s
2022-08-04 10:06:24,151 [dl_trainer.py:731] WARNING [ 19][ 3760/  196][rank:0] loss: 0.575, average forward (0.010985) and backward (0.020715) time: 0.100194, iotime: 0.001559 
2022-08-04 10:06:25,405 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047552, Speed: 672.949851 images/s
2022-08-04 10:06:26,030 [dl_trainer.py:731] WARNING [ 19][ 3800/  196][rank:0] loss: 0.434, average forward (0.008684) and backward (0.019404) time: 0.029743, iotime: 0.001422 
2022-08-04 10:06:27,231 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045639, Speed: 701.156418 images/s
2022-08-04 10:06:27,848 [dl_trainer.py:731] WARNING [ 19][ 3840/  196][rank:0] loss: 0.367, average forward (0.008883) and backward (0.020696) time: 0.031193, iotime: 0.001393 
2022-08-04 10:06:29,127 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047381, Speed: 675.379495 images/s
2022-08-04 10:06:29,763 [dl_trainer.py:731] WARNING [ 19][ 3880/  196][rank:0] loss: 0.325, average forward (0.010467) and backward (0.022938) time: 0.035220, iotime: 0.001561 
2022-08-04 10:06:30,704 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:06:30,705 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:06:31,821 [dl_trainer.py:731] WARNING [ 19][ 3920/  196][rank:0] loss: 0.276, average forward (0.009673) and backward (0.021155) time: 0.036138, iotime: 0.005065 
2022-08-04 10:06:31,825 [dl_trainer.py:634] INFO train iter: 3920, num_batches_per_epoch: 196
2022-08-04 10:06:31,826 [dl_trainer.py:635] INFO Epoch 20, avg train acc: 88.807398, lr: 0.100000, avg loss: 0.336375
2022-08-04 10:06:34,466 [dl_trainer.py:822] INFO Epoch 20, lr: 0.100000, val loss: 0.647834, val top-1 acc: 81.659345, top-5 acc: 98.292732
2022-08-04 10:06:35,463 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084460, Speed: 378.876073 images/s
2022-08-04 10:06:36,355 [dl_trainer.py:731] WARNING [ 20][ 3960/  196][rank:0] loss: 0.345, average forward (0.009097) and backward (0.021400) time: 0.098763, iotime: 0.001416 
2022-08-04 10:06:37,377 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047853, Speed: 668.710788 images/s
2022-08-04 10:06:38,259 [dl_trainer.py:731] WARNING [ 20][ 4000/  196][rank:0] loss: 0.281, average forward (0.011769) and backward (0.021603) time: 0.035260, iotime: 0.001613 
2022-08-04 10:06:39,272 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047373, Speed: 675.487414 images/s
2022-08-04 10:06:40,169 [dl_trainer.py:731] WARNING [ 20][ 4040/  196][rank:0] loss: 0.252, average forward (0.010023) and backward (0.021204) time: 0.033029, iotime: 0.001549 
2022-08-04 10:06:41,147 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046851, Speed: 683.016499 images/s
2022-08-04 10:06:42,013 [dl_trainer.py:731] WARNING [ 20][ 4080/  196][rank:0] loss: 0.674, average forward (0.009926) and backward (0.021405) time: 0.033080, iotime: 0.001502 
2022-08-04 10:06:42,743 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:06:42,744 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:06:43,877 [dl_trainer.py:634] INFO train iter: 4116, num_batches_per_epoch: 196
2022-08-04 10:06:43,878 [dl_trainer.py:635] INFO Epoch 21, avg train acc: 89.142219, lr: 0.100000, avg loss: 0.318781
2022-08-04 10:06:46,508 [dl_trainer.py:822] INFO Epoch 21, lr: 0.100000, val loss: 0.437100, val top-1 acc: 85.702875, top-5 acc: 99.341054
2022-08-04 10:06:46,699 [dl_trainer.py:731] WARNING [ 21][ 4120/  196][rank:0] loss: 0.318, average forward (0.010991) and backward (0.020454) time: 0.102837, iotime: 0.005303 
2022-08-04 10:06:47,472 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084320, Speed: 379.507693 images/s
2022-08-04 10:06:48,566 [dl_trainer.py:731] WARNING [ 21][ 4160/  196][rank:0] loss: 0.301, average forward (0.010243) and backward (0.020196) time: 0.032207, iotime: 0.001533 
2022-08-04 10:06:49,326 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046329, Speed: 690.714605 images/s
2022-08-04 10:06:50,427 [dl_trainer.py:731] WARNING [ 21][ 4200/  196][rank:0] loss: 0.314, average forward (0.010476) and backward (0.020326) time: 0.032575, iotime: 0.001521 
2022-08-04 10:06:51,196 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046739, Speed: 684.652548 images/s
2022-08-04 10:06:52,310 [dl_trainer.py:731] WARNING [ 21][ 4240/  196][rank:0] loss: 0.189, average forward (0.008693) and backward (0.020002) time: 0.030283, iotime: 0.001359 
2022-08-04 10:06:53,090 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047346, Speed: 675.870593 images/s
2022-08-04 10:06:54,236 [dl_trainer.py:731] WARNING [ 21][ 4280/  196][rank:0] loss: 0.363, average forward (0.009269) and backward (0.021008) time: 0.031947, iotime: 0.001429 
2022-08-04 10:06:54,717 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:06:54,717 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:06:55,882 [dl_trainer.py:634] INFO train iter: 4312, num_batches_per_epoch: 196
2022-08-04 10:06:55,883 [dl_trainer.py:635] INFO Epoch 22, avg train acc: 88.647959, lr: 0.100000, avg loss: 0.328627
2022-08-04 10:06:58,492 [dl_trainer.py:822] INFO Epoch 22, lr: 0.100000, val loss: 0.553717, val top-1 acc: 82.488019, top-5 acc: 98.861821
2022-08-04 10:06:58,855 [dl_trainer.py:731] WARNING [ 22][ 4320/  196][rank:0] loss: 0.211, average forward (0.010382) and backward (0.021154) time: 0.102796, iotime: 0.005253 
2022-08-04 10:06:59,418 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084355, Speed: 379.348086 images/s
2022-08-04 10:07:00,756 [dl_trainer.py:731] WARNING [ 22][ 4360/  196][rank:0] loss: 0.147, average forward (0.010501) and backward (0.021404) time: 0.033730, iotime: 0.001565 
2022-08-04 10:07:01,292 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046840, Speed: 683.170510 images/s
2022-08-04 10:07:02,637 [dl_trainer.py:731] WARNING [ 22][ 4400/  196][rank:0] loss: 0.311, average forward (0.009982) and backward (0.020597) time: 0.032395, iotime: 0.001580 
2022-08-04 10:07:03,170 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046935, Speed: 681.794086 images/s
2022-08-04 10:07:04,526 [dl_trainer.py:731] WARNING [ 22][ 4440/  196][rank:0] loss: 0.281, average forward (0.009063) and backward (0.020935) time: 0.031661, iotime: 0.001426 
2022-08-04 10:07:05,050 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046994, Speed: 680.944805 images/s
2022-08-04 10:07:06,390 [dl_trainer.py:731] WARNING [ 22][ 4480/  196][rank:0] loss: 0.386, average forward (0.010331) and backward (0.020608) time: 0.032714, iotime: 0.001513 
2022-08-04 10:07:06,648 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:07:06,649 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:07:07,924 [dl_trainer.py:634] INFO train iter: 4508, num_batches_per_epoch: 196
2022-08-04 10:07:07,925 [dl_trainer.py:635] INFO Epoch 23, avg train acc: 89.158163, lr: 0.100000, avg loss: 0.314341
2022-08-04 10:07:10,533 [dl_trainer.py:822] INFO Epoch 23, lr: 0.100000, val loss: 0.573242, val top-1 acc: 81.659345, top-5 acc: 99.211262
2022-08-04 10:07:11,055 [dl_trainer.py:731] WARNING [ 23][ 4520/  196][rank:0] loss: 0.455, average forward (0.009912) and backward (0.020218) time: 0.100924, iotime: 0.005229 
2022-08-04 10:07:11,370 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084252, Speed: 379.813036 images/s
2022-08-04 10:07:12,946 [dl_trainer.py:731] WARNING [ 23][ 4560/  196][rank:0] loss: 0.229, average forward (0.011871) and backward (0.018848) time: 0.032631, iotime: 0.001647 
2022-08-04 10:07:13,253 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047062, Speed: 679.958012 images/s
2022-08-04 10:07:14,885 [dl_trainer.py:731] WARNING [ 23][ 4600/  196][rank:0] loss: 0.299, average forward (0.008745) and backward (0.018901) time: 0.029280, iotime: 0.001395 
2022-08-04 10:07:15,153 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047503, Speed: 673.638784 images/s
2022-08-04 10:07:16,715 [dl_trainer.py:731] WARNING [ 23][ 4640/  196][rank:0] loss: 0.258, average forward (0.008882) and backward (0.020624) time: 0.031119, iotime: 0.001390 
2022-08-04 10:07:16,994 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046000, Speed: 695.648150 images/s
2022-08-04 10:07:18,628 [dl_trainer.py:731] WARNING [ 23][ 4680/  196][rank:0] loss: 0.186, average forward (0.010162) and backward (0.020610) time: 0.032525, iotime: 0.001500 
2022-08-04 10:07:18,640 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:07:18,640 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:07:19,902 [dl_trainer.py:634] INFO train iter: 4704, num_batches_per_epoch: 196
2022-08-04 10:07:19,903 [dl_trainer.py:635] INFO Epoch 24, avg train acc: 89.429209, lr: 0.100000, avg loss: 0.303471
2022-08-04 10:07:22,548 [dl_trainer.py:822] INFO Epoch 24, lr: 0.100000, val loss: 0.461675, val top-1 acc: 85.283546, top-5 acc: 99.351038
2022-08-04 10:07:23,279 [dl_trainer.py:731] WARNING [ 24][ 4720/  196][rank:0] loss: 0.259, average forward (0.010460) and backward (0.019454) time: 0.102169, iotime: 0.005333 
2022-08-04 10:07:23,354 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084790, Speed: 377.403883 images/s
2022-08-04 10:07:25,168 [dl_trainer.py:731] WARNING [ 24][ 4760/  196][rank:0] loss: 0.471, average forward (0.011134) and backward (0.021421) time: 0.034343, iotime: 0.001535 
2022-08-04 10:07:25,228 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046837, Speed: 683.222675 images/s
2022-08-04 10:07:27,049 [dl_trainer.py:731] WARNING [ 24][ 4800/  196][rank:0] loss: 0.131, average forward (0.009641) and backward (0.019657) time: 0.031013, iotime: 0.001473 
2022-08-04 10:07:27,124 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047388, Speed: 675.273564 images/s
2022-08-04 10:07:28,959 [dl_trainer.py:731] WARNING [ 24][ 4840/  196][rank:0] loss: 0.197, average forward (0.011550) and backward (0.020931) time: 0.034368, iotime: 0.001610 
2022-08-04 10:07:29,017 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047320, Speed: 676.253952 images/s
2022-08-04 10:07:30,638 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:07:30,638 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:07:31,009 [dl_trainer.py:731] WARNING [ 24][ 4880/  196][rank:0] loss: 0.139, average forward (0.009601) and backward (0.021473) time: 0.036677, iotime: 0.005349 
2022-08-04 10:07:31,955 [dl_trainer.py:634] INFO train iter: 4900, num_batches_per_epoch: 196
2022-08-04 10:07:31,956 [dl_trainer.py:635] INFO Epoch 25, avg train acc: 89.700255, lr: 0.100000, avg loss: 0.288664
2022-08-04 10:07:34,615 [dl_trainer.py:822] INFO Epoch 25, lr: 0.100000, val loss: 0.429509, val top-1 acc: 86.271965, top-5 acc: 99.380990
2022-08-04 10:07:35,374 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084746, Speed: 377.599842 images/s
2022-08-04 10:07:35,558 [dl_trainer.py:731] WARNING [ 25][ 4920/  196][rank:0] loss: 0.302, average forward (0.011033) and backward (0.019874) time: 0.099283, iotime: 0.001562 
2022-08-04 10:07:37,298 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048088, Speed: 665.443516 images/s
2022-08-04 10:07:37,480 [dl_trainer.py:731] WARNING [ 25][ 4960/  196][rank:0] loss: 0.499, average forward (0.009082) and backward (0.020455) time: 0.031209, iotime: 0.001443 
2022-08-04 10:07:39,220 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048050, Speed: 665.969334 images/s
2022-08-04 10:07:39,383 [dl_trainer.py:731] WARNING [ 25][ 5000/  196][rank:0] loss: 0.223, average forward (0.009030) and backward (0.017119) time: 0.027769, iotime: 0.001387 
2022-08-04 10:07:41,116 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047376, Speed: 675.445772 images/s
2022-08-04 10:07:41,285 [dl_trainer.py:731] WARNING [ 25][ 5040/  196][rank:0] loss: 0.287, average forward (0.010422) and backward (0.020085) time: 0.032329, iotime: 0.001579 
2022-08-04 10:07:42,727 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:07:42,728 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:07:43,325 [dl_trainer.py:731] WARNING [ 25][ 5080/  196][rank:0] loss: 0.485, average forward (0.009881) and backward (0.019756) time: 0.035255, iotime: 0.005374 
2022-08-04 10:07:44,077 [dl_trainer.py:634] INFO train iter: 5096, num_batches_per_epoch: 196
2022-08-04 10:07:44,078 [dl_trainer.py:635] INFO Epoch 26, avg train acc: 89.588648, lr: 0.100000, avg loss: 0.297875
2022-08-04 10:07:46,730 [dl_trainer.py:822] INFO Epoch 26, lr: 0.100000, val loss: 0.577149, val top-1 acc: 82.957268, top-5 acc: 99.231230
2022-08-04 10:07:47,441 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084322, Speed: 379.495875 images/s
2022-08-04 10:07:47,840 [dl_trainer.py:731] WARNING [ 26][ 5120/  196][rank:0] loss: 0.159, average forward (0.009662) and backward (0.021036) time: 0.099265, iotime: 0.001473 
2022-08-04 10:07:49,324 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047046, Speed: 680.185785 images/s
2022-08-04 10:07:49,716 [dl_trainer.py:731] WARNING [ 26][ 5160/  196][rank:0] loss: 0.194, average forward (0.012132) and backward (0.020577) time: 0.034718, iotime: 0.001697 
2022-08-04 10:07:51,146 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045521, Speed: 702.976534 images/s
2022-08-04 10:07:51,588 [dl_trainer.py:731] WARNING [ 26][ 5200/  196][rank:0] loss: 0.236, average forward (0.009286) and backward (0.022511) time: 0.033477, iotime: 0.001442 
2022-08-04 10:07:53,028 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047051, Speed: 680.117282 images/s
2022-08-04 10:07:53,434 [dl_trainer.py:731] WARNING [ 26][ 5240/  196][rank:0] loss: 0.346, average forward (0.010480) and backward (0.019988) time: 0.032216, iotime: 0.001498 
2022-08-04 10:07:54,644 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:07:54,645 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:07:55,482 [dl_trainer.py:731] WARNING [ 26][ 5280/  196][rank:0] loss: 0.343, average forward (0.009838) and backward (0.021644) time: 0.036884, iotime: 0.005140 
2022-08-04 10:07:56,038 [dl_trainer.py:634] INFO train iter: 5292, num_batches_per_epoch: 196
2022-08-04 10:07:56,039 [dl_trainer.py:635] INFO Epoch 27, avg train acc: 89.333546, lr: 0.100000, avg loss: 0.298284
2022-08-04 10:07:58,658 [dl_trainer.py:822] INFO Epoch 27, lr: 0.100000, val loss: 0.564300, val top-1 acc: 83.785942, top-5 acc: 99.091454
2022-08-04 10:07:59,360 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084411, Speed: 379.097034 images/s
2022-08-04 10:08:00,023 [dl_trainer.py:731] WARNING [ 27][ 5320/  196][rank:0] loss: 0.247, average forward (0.009873) and backward (0.021916) time: 0.099045, iotime: 0.001443 
2022-08-04 10:08:01,314 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048832, Speed: 655.304565 images/s
2022-08-04 10:08:01,979 [dl_trainer.py:731] WARNING [ 27][ 5360/  196][rank:0] loss: 0.347, average forward (0.010608) and backward (0.020267) time: 0.032619, iotime: 0.001467 
2022-08-04 10:08:03,214 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047479, Speed: 673.980183 images/s
2022-08-04 10:08:03,889 [dl_trainer.py:731] WARNING [ 27][ 5400/  196][rank:0] loss: 0.514, average forward (0.008998) and backward (0.018042) time: 0.028651, iotime: 0.001369 
2022-08-04 10:08:05,140 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048154, Speed: 664.540507 images/s
2022-08-04 10:08:05,787 [dl_trainer.py:731] WARNING [ 27][ 5440/  196][rank:0] loss: 0.307, average forward (0.009081) and backward (0.020662) time: 0.031316, iotime: 0.001343 
2022-08-04 10:08:06,730 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:08:06,731 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:08:07,804 [dl_trainer.py:731] WARNING [ 27][ 5480/  196][rank:0] loss: 0.183, average forward (0.011553) and backward (0.021749) time: 0.038892, iotime: 0.005305 
2022-08-04 10:08:08,213 [dl_trainer.py:634] INFO train iter: 5488, num_batches_per_epoch: 196
2022-08-04 10:08:08,214 [dl_trainer.py:635] INFO Epoch 28, avg train acc: 91.087372, lr: 0.100000, avg loss: 0.263778
2022-08-04 10:08:10,806 [dl_trainer.py:822] INFO Epoch 28, lr: 0.100000, val loss: 0.458523, val top-1 acc: 85.613019, top-5 acc: 99.251198
2022-08-04 10:08:11,430 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083851, Speed: 381.629939 images/s
2022-08-04 10:08:12,301 [dl_trainer.py:731] WARNING [ 28][ 5520/  196][rank:0] loss: 0.244, average forward (0.008896) and backward (0.018173) time: 0.093975, iotime: 0.001346 
2022-08-04 10:08:13,338 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047682, Speed: 671.112297 images/s
2022-08-04 10:08:14,226 [dl_trainer.py:731] WARNING [ 28][ 5560/  196][rank:0] loss: 0.333, average forward (0.008772) and backward (0.018112) time: 0.028552, iotime: 0.001438 
2022-08-04 10:08:15,216 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046931, Speed: 681.854700 images/s
2022-08-04 10:08:16,125 [dl_trainer.py:731] WARNING [ 28][ 5600/  196][rank:0] loss: 0.549, average forward (0.008524) and backward (0.019835) time: 0.029934, iotime: 0.001351 
2022-08-04 10:08:17,165 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048724, Speed: 656.757614 images/s
2022-08-04 10:08:18,056 [dl_trainer.py:731] WARNING [ 28][ 5640/  196][rank:0] loss: 0.134, average forward (0.008934) and backward (0.019640) time: 0.030200, iotime: 0.001394 
2022-08-04 10:08:18,786 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:08:18,787 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:08:20,108 [dl_trainer.py:731] WARNING [ 28][ 5680/  196][rank:0] loss: 0.233, average forward (0.010982) and backward (0.020693) time: 0.036982, iotime: 0.005025 
2022-08-04 10:08:20,332 [dl_trainer.py:634] INFO train iter: 5684, num_batches_per_epoch: 196
2022-08-04 10:08:20,332 [dl_trainer.py:635] INFO Epoch 29, avg train acc: 89.748087, lr: 0.100000, avg loss: 0.293912
2022-08-04 10:08:22,953 [dl_trainer.py:822] INFO Epoch 29, lr: 0.100000, val loss: 0.493123, val top-1 acc: 85.013978, top-5 acc: 99.351038
2022-08-04 10:08:23,523 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084757, Speed: 377.550132 images/s
2022-08-04 10:08:24,642 [dl_trainer.py:731] WARNING [ 29][ 5720/  196][rank:0] loss: 0.205, average forward (0.009127) and backward (0.019098) time: 0.095460, iotime: 0.001393 
2022-08-04 10:08:25,414 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047261, Speed: 677.097884 images/s
2022-08-04 10:08:26,509 [dl_trainer.py:731] WARNING [ 29][ 5760/  196][rank:0] loss: 0.296, average forward (0.010402) and backward (0.021094) time: 0.033292, iotime: 0.001551 
2022-08-04 10:08:27,286 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046785, Speed: 683.975682 images/s
2022-08-04 10:08:28,398 [dl_trainer.py:731] WARNING [ 29][ 5800/  196][rank:0] loss: 0.197, average forward (0.010465) and backward (0.020163) time: 0.032449, iotime: 0.001570 
2022-08-04 10:08:29,171 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047119, Speed: 679.126355 images/s
2022-08-04 10:08:30,283 [dl_trainer.py:731] WARNING [ 29][ 5840/  196][rank:0] loss: 0.342, average forward (0.009649) and backward (0.017354) time: 0.028661, iotime: 0.001424 
2022-08-04 10:08:30,776 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:08:30,776 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:08:32,332 [dl_trainer.py:731] WARNING [ 29][ 5880/  196][rank:0] loss: 0.209, average forward (0.009088) and backward (0.020218) time: 0.034661, iotime: 0.005116 
2022-08-04 10:08:32,347 [dl_trainer.py:634] INFO train iter: 5880, num_batches_per_epoch: 196
2022-08-04 10:08:32,347 [dl_trainer.py:635] INFO Epoch 30, avg train acc: 90.258291, lr: 0.100000, avg loss: 0.279760
2022-08-04 10:08:34,982 [dl_trainer.py:822] INFO Epoch 30, lr: 0.100000, val loss: 0.525590, val top-1 acc: 84.394968, top-5 acc: 99.231230
2022-08-04 10:08:35,526 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084727, Speed: 377.684960 images/s
2022-08-04 10:08:36,897 [dl_trainer.py:731] WARNING [ 30][ 5920/  196][rank:0] loss: 0.333, average forward (0.010259) and backward (0.020616) time: 0.099013, iotime: 0.001519 
2022-08-04 10:08:37,408 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047020, Speed: 680.563617 images/s
2022-08-04 10:08:38,804 [dl_trainer.py:731] WARNING [ 30][ 5960/  196][rank:0] loss: 0.061, average forward (0.008836) and backward (0.020066) time: 0.030492, iotime: 0.001358 
2022-08-04 10:08:39,333 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048119, Speed: 665.019094 images/s
2022-08-04 10:08:40,695 [dl_trainer.py:731] WARNING [ 30][ 6000/  196][rank:0] loss: 0.203, average forward (0.011040) and backward (0.020569) time: 0.033484, iotime: 0.001618 
2022-08-04 10:08:41,210 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046917, Speed: 682.056795 images/s
2022-08-04 10:08:42,531 [dl_trainer.py:731] WARNING [ 30][ 6040/  196][rank:0] loss: 0.409, average forward (0.010454) and backward (0.020227) time: 0.032432, iotime: 0.001503 
2022-08-04 10:08:42,784 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:08:42,784 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:08:44,377 [dl_trainer.py:634] INFO train iter: 6076, num_batches_per_epoch: 196
2022-08-04 10:08:44,378 [dl_trainer.py:635] INFO Epoch 31, avg train acc: 90.561224, lr: 0.100000, avg loss: 0.262126
2022-08-04 10:08:47,039 [dl_trainer.py:822] INFO Epoch 31, lr: 0.100000, val loss: 0.437574, val top-1 acc: 85.722843, top-5 acc: 99.520767
2022-08-04 10:08:47,223 [dl_trainer.py:731] WARNING [ 31][ 6080/  196][rank:0] loss: 0.218, average forward (0.010167) and backward (0.019479) time: 0.101732, iotime: 0.005215 
2022-08-04 10:08:47,501 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083877, Speed: 381.509948 images/s
2022-08-04 10:08:49,054 [dl_trainer.py:731] WARNING [ 31][ 6120/  196][rank:0] loss: 0.311, average forward (0.009065) and backward (0.018630) time: 0.029308, iotime: 0.001384 
2022-08-04 10:08:49,358 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046399, Speed: 689.663431 images/s
2022-08-04 10:08:50,966 [dl_trainer.py:731] WARNING [ 31][ 6160/  196][rank:0] loss: 0.302, average forward (0.011293) and backward (0.020639) time: 0.033838, iotime: 0.001644 
2022-08-04 10:08:51,254 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047393, Speed: 675.207575 images/s
2022-08-04 10:08:52,820 [dl_trainer.py:731] WARNING [ 31][ 6200/  196][rank:0] loss: 0.233, average forward (0.010451) and backward (0.020051) time: 0.032288, iotime: 0.001528 
2022-08-04 10:08:53,120 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046641, Speed: 686.088157 images/s
2022-08-04 10:08:54,723 [dl_trainer.py:731] WARNING [ 31][ 6240/  196][rank:0] loss: 0.172, average forward (0.010531) and backward (0.021224) time: 0.033550, iotime: 0.001534 
2022-08-04 10:08:54,737 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:08:54,738 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:08:56,329 [dl_trainer.py:634] INFO train iter: 6272, num_batches_per_epoch: 196
2022-08-04 10:08:56,329 [dl_trainer.py:635] INFO Epoch 32, avg train acc: 90.561224, lr: 0.100000, avg loss: 0.268823
2022-08-04 10:08:58,932 [dl_trainer.py:822] INFO Epoch 32, lr: 0.100000, val loss: 0.430285, val top-1 acc: 86.122204, top-5 acc: 99.470847
2022-08-04 10:08:59,326 [dl_trainer.py:731] WARNING [ 32][ 6280/  196][rank:0] loss: 0.275, average forward (0.009577) and backward (0.020601) time: 0.100908, iotime: 0.004901 
2022-08-04 10:08:59,381 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083470, Speed: 383.373499 images/s
2022-08-04 10:09:01,217 [dl_trainer.py:731] WARNING [ 32][ 6320/  196][rank:0] loss: 0.245, average forward (0.010709) and backward (0.021824) time: 0.034339, iotime: 0.001564 
2022-08-04 10:09:01,272 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047267, Speed: 677.004730 images/s
2022-08-04 10:09:03,173 [dl_trainer.py:731] WARNING [ 32][ 6360/  196][rank:0] loss: 0.232, average forward (0.010624) and backward (0.023301) time: 0.035633, iotime: 0.001455 
2022-08-04 10:09:03,225 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048806, Speed: 655.656134 images/s
2022-08-04 10:09:05,058 [dl_trainer.py:731] WARNING [ 32][ 6400/  196][rank:0] loss: 0.594, average forward (0.011434) and backward (0.022398) time: 0.035676, iotime: 0.001575 
2022-08-04 10:09:05,107 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047038, Speed: 680.300159 images/s
2022-08-04 10:09:06,715 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:09:06,716 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:09:07,084 [dl_trainer.py:731] WARNING [ 32][ 6440/  196][rank:0] loss: 0.135, average forward (0.010837) and backward (0.021519) time: 0.038014, iotime: 0.005394 
2022-08-04 10:09:08,423 [dl_trainer.py:634] INFO train iter: 6468, num_batches_per_epoch: 196
2022-08-04 10:09:08,423 [dl_trainer.py:635] INFO Epoch 33, avg train acc: 90.656888, lr: 0.100000, avg loss: 0.274244
2022-08-04 10:09:11,027 [dl_trainer.py:822] INFO Epoch 33, lr: 0.100000, val loss: 0.422288, val top-1 acc: 86.970847, top-5 acc: 99.430911
2022-08-04 10:09:11,406 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083970, Speed: 381.090158 images/s
2022-08-04 10:09:11,582 [dl_trainer.py:731] WARNING [ 33][ 6480/  196][rank:0] loss: 0.386, average forward (0.011307) and backward (0.020913) time: 0.099264, iotime: 0.001591 
2022-08-04 10:09:13,354 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048687, Speed: 657.260455 images/s
2022-08-04 10:09:13,539 [dl_trainer.py:731] WARNING [ 33][ 6520/  196][rank:0] loss: 0.266, average forward (0.009496) and backward (0.018630) time: 0.029788, iotime: 0.001422 
2022-08-04 10:09:15,310 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048903, Speed: 654.361205 images/s
2022-08-04 10:09:15,485 [dl_trainer.py:731] WARNING [ 33][ 6560/  196][rank:0] loss: 0.206, average forward (0.009828) and backward (0.019781) time: 0.031348, iotime: 0.001485 
2022-08-04 10:09:17,236 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048142, Speed: 664.705556 images/s
2022-08-04 10:09:17,422 [dl_trainer.py:731] WARNING [ 33][ 6600/  196][rank:0] loss: 0.335, average forward (0.009137) and backward (0.019313) time: 0.030091, iotime: 0.001410 
2022-08-04 10:09:18,864 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:09:18,864 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:09:19,462 [dl_trainer.py:731] WARNING [ 33][ 6640/  196][rank:0] loss: 0.305, average forward (0.009346) and backward (0.019303) time: 0.034029, iotime: 0.005125 
2022-08-04 10:09:20,641 [dl_trainer.py:634] INFO train iter: 6664, num_batches_per_epoch: 196
2022-08-04 10:09:20,641 [dl_trainer.py:635] INFO Epoch 34, avg train acc: 91.198980, lr: 0.100000, avg loss: 0.256724
2022-08-04 10:09:23,364 [dl_trainer.py:822] INFO Epoch 34, lr: 0.100000, val loss: 0.424181, val top-1 acc: 86.251997, top-5 acc: 99.580671
2022-08-04 10:09:23,714 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.086357, Speed: 370.555981 images/s
2022-08-04 10:09:24,132 [dl_trainer.py:731] WARNING [ 34][ 6680/  196][rank:0] loss: 0.425, average forward (0.009764) and backward (0.021548) time: 0.101666, iotime: 0.001461 
2022-08-04 10:09:25,665 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048766, Speed: 656.194261 images/s
2022-08-04 10:09:26,073 [dl_trainer.py:731] WARNING [ 34][ 6720/  196][rank:0] loss: 0.381, average forward (0.009273) and backward (0.021078) time: 0.032050, iotime: 0.001471 
2022-08-04 10:09:27,539 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046829, Speed: 683.343378 images/s
2022-08-04 10:09:27,947 [dl_trainer.py:731] WARNING [ 34][ 6760/  196][rank:0] loss: 0.366, average forward (0.010469) and backward (0.020733) time: 0.032973, iotime: 0.001526 
2022-08-04 10:09:29,421 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047057, Speed: 680.024071 images/s
2022-08-04 10:09:29,831 [dl_trainer.py:731] WARNING [ 34][ 6800/  196][rank:0] loss: 0.216, average forward (0.009897) and backward (0.021291) time: 0.032955, iotime: 0.001520 
2022-08-04 10:09:31,025 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:09:31,025 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:09:31,840 [dl_trainer.py:731] WARNING [ 34][ 6840/  196][rank:0] loss: 0.291, average forward (0.009707) and backward (0.019789) time: 0.035130, iotime: 0.005385 
2022-08-04 10:09:32,785 [dl_trainer.py:634] INFO train iter: 6860, num_batches_per_epoch: 196
2022-08-04 10:09:32,786 [dl_trainer.py:635] INFO Epoch 35, avg train acc: 91.406250, lr: 0.100000, avg loss: 0.252039
2022-08-04 10:09:35,412 [dl_trainer.py:822] INFO Epoch 35, lr: 0.100000, val loss: 0.429565, val top-1 acc: 86.142173, top-5 acc: 99.500799
2022-08-04 10:09:35,715 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083894, Speed: 381.432550 images/s
2022-08-04 10:09:36,382 [dl_trainer.py:731] WARNING [ 35][ 6880/  196][rank:0] loss: 0.079, average forward (0.008829) and backward (0.021336) time: 0.097509, iotime: 0.001401 
2022-08-04 10:09:37,615 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047512, Speed: 673.513372 images/s
2022-08-04 10:09:38,247 [dl_trainer.py:731] WARNING [ 35][ 6920/  196][rank:0] loss: 0.162, average forward (0.008971) and backward (0.020060) time: 0.030613, iotime: 0.001356 
2022-08-04 10:09:39,469 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046316, Speed: 690.912296 images/s
2022-08-04 10:09:40,100 [dl_trainer.py:731] WARNING [ 35][ 6960/  196][rank:0] loss: 0.111, average forward (0.009606) and backward (0.018860) time: 0.030144, iotime: 0.001436 
2022-08-04 10:09:41,353 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047113, Speed: 679.215195 images/s
2022-08-04 10:09:41,982 [dl_trainer.py:731] WARNING [ 35][ 7000/  196][rank:0] loss: 0.263, average forward (0.009870) and backward (0.019561) time: 0.031128, iotime: 0.001452 
2022-08-04 10:09:42,963 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:09:42,963 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:09:44,082 [dl_trainer.py:731] WARNING [ 35][ 7040/  196][rank:0] loss: 0.210, average forward (0.010785) and backward (0.019315) time: 0.035689, iotime: 0.005291 
2022-08-04 10:09:44,890 [dl_trainer.py:634] INFO train iter: 7056, num_batches_per_epoch: 196
2022-08-04 10:09:44,891 [dl_trainer.py:635] INFO Epoch 36, avg train acc: 91.230867, lr: 0.100000, avg loss: 0.254987
2022-08-04 10:09:47,581 [dl_trainer.py:822] INFO Epoch 36, lr: 0.100000, val loss: 0.447207, val top-1 acc: 85.902556, top-5 acc: 99.371006
2022-08-04 10:09:47,845 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.086538, Speed: 369.779410 images/s
2022-08-04 10:09:48,735 [dl_trainer.py:731] WARNING [ 36][ 7080/  196][rank:0] loss: 0.148, average forward (0.010512) and backward (0.021924) time: 0.102112, iotime: 0.001657 
2022-08-04 10:09:49,736 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047258, Speed: 677.131958 images/s
2022-08-04 10:09:50,646 [dl_trainer.py:731] WARNING [ 36][ 7120/  196][rank:0] loss: 0.065, average forward (0.010011) and backward (0.022240) time: 0.033996, iotime: 0.001496 
2022-08-04 10:09:51,652 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047875, Speed: 668.403829 images/s
2022-08-04 10:09:52,520 [dl_trainer.py:731] WARNING [ 36][ 7160/  196][rank:0] loss: 0.082, average forward (0.010369) and backward (0.019120) time: 0.031333, iotime: 0.001582 
2022-08-04 10:09:53,506 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046336, Speed: 690.602299 images/s
2022-08-04 10:09:54,438 [dl_trainer.py:731] WARNING [ 36][ 7200/  196][rank:0] loss: 0.071, average forward (0.009933) and backward (0.020272) time: 0.031893, iotime: 0.001425 
2022-08-04 10:09:55,154 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:09:55,154 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:09:56,483 [dl_trainer.py:731] WARNING [ 36][ 7240/  196][rank:0] loss: 0.278, average forward (0.011005) and backward (0.019994) time: 0.036567, iotime: 0.005280 
2022-08-04 10:09:57,074 [dl_trainer.py:634] INFO train iter: 7252, num_batches_per_epoch: 196
2022-08-04 10:09:57,074 [dl_trainer.py:635] INFO Epoch 37, avg train acc: 91.087372, lr: 0.100000, avg loss: 0.254660
2022-08-04 10:09:59,666 [dl_trainer.py:822] INFO Epoch 37, lr: 0.100000, val loss: 0.428153, val top-1 acc: 86.641374, top-5 acc: 99.430911
2022-08-04 10:09:59,864 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084755, Speed: 377.559663 images/s
2022-08-04 10:10:00,943 [dl_trainer.py:731] WARNING [ 37][ 7280/  196][rank:0] loss: 0.438, average forward (0.009768) and backward (0.020306) time: 0.096735, iotime: 0.001537 
2022-08-04 10:10:01,705 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046034, Speed: 695.141221 images/s
2022-08-04 10:10:02,810 [dl_trainer.py:731] WARNING [ 37][ 7320/  196][rank:0] loss: 0.342, average forward (0.009794) and backward (0.020757) time: 0.032280, iotime: 0.001482 
2022-08-04 10:10:03,590 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047100, Speed: 679.401285 images/s
2022-08-04 10:10:04,698 [dl_trainer.py:731] WARNING [ 37][ 7360/  196][rank:0] loss: 0.321, average forward (0.011770) and backward (0.021133) time: 0.034930, iotime: 0.001738 
2022-08-04 10:10:05,458 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046693, Speed: 685.325244 images/s
2022-08-04 10:10:06,604 [dl_trainer.py:731] WARNING [ 37][ 7400/  196][rank:0] loss: 0.215, average forward (0.010260) and backward (0.019309) time: 0.031368, iotime: 0.001546 
2022-08-04 10:10:07,112 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:10:07,112 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:10:08,659 [dl_trainer.py:731] WARNING [ 37][ 7440/  196][rank:0] loss: 0.197, average forward (0.010047) and backward (0.020864) time: 0.036440, iotime: 0.005262 
2022-08-04 10:10:09,053 [dl_trainer.py:634] INFO train iter: 7448, num_batches_per_epoch: 196
2022-08-04 10:10:09,054 [dl_trainer.py:635] INFO Epoch 38, avg train acc: 91.214923, lr: 0.100000, avg loss: 0.252247
2022-08-04 10:10:11,721 [dl_trainer.py:822] INFO Epoch 38, lr: 0.100000, val loss: 0.434300, val top-1 acc: 86.232029, top-5 acc: 99.510783
2022-08-04 10:10:11,936 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.086354, Speed: 370.567917 images/s
2022-08-04 10:10:13,289 [dl_trainer.py:731] WARNING [ 38][ 7480/  196][rank:0] loss: 0.367, average forward (0.009200) and backward (0.021209) time: 0.101017, iotime: 0.001441 
2022-08-04 10:10:13,803 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046664, Speed: 685.760398 images/s
2022-08-04 10:10:15,178 [dl_trainer.py:731] WARNING [ 38][ 7520/  196][rank:0] loss: 0.250, average forward (0.009497) and backward (0.020127) time: 0.031323, iotime: 0.001460 
2022-08-04 10:10:15,667 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046587, Speed: 686.881154 images/s
2022-08-04 10:10:17,034 [dl_trainer.py:731] WARNING [ 38][ 7560/  196][rank:0] loss: 0.249, average forward (0.010041) and backward (0.020295) time: 0.032141, iotime: 0.001557 
2022-08-04 10:10:17,561 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047345, Speed: 675.891525 images/s
2022-08-04 10:10:18,864 [dl_trainer.py:731] WARNING [ 38][ 7600/  196][rank:0] loss: 0.311, average forward (0.010454) and backward (0.019392) time: 0.031655, iotime: 0.001567 
2022-08-04 10:10:19,118 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:10:19,119 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:10:20,879 [dl_trainer.py:731] WARNING [ 38][ 7640/  196][rank:0] loss: 0.607, average forward (0.010267) and backward (0.019701) time: 0.035428, iotime: 0.005195 
2022-08-04 10:10:21,075 [dl_trainer.py:634] INFO train iter: 7644, num_batches_per_epoch: 196
2022-08-04 10:10:21,076 [dl_trainer.py:635] INFO Epoch 39, avg train acc: 90.433673, lr: 0.100000, avg loss: 0.268508
2022-08-04 10:10:23,709 [dl_trainer.py:822] INFO Epoch 39, lr: 0.100000, val loss: 0.522019, val top-1 acc: 84.135383, top-5 acc: 99.311102
2022-08-04 10:10:23,806 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083253, Speed: 384.370538 images/s
2022-08-04 10:10:25,407 [dl_trainer.py:731] WARNING [ 39][ 7680/  196][rank:0] loss: 0.265, average forward (0.009606) and backward (0.019039) time: 0.096170, iotime: 0.001385 
2022-08-04 10:10:25,731 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048102, Speed: 665.255843 images/s
2022-08-04 10:10:27,303 [dl_trainer.py:731] WARNING [ 39][ 7720/  196][rank:0] loss: 0.277, average forward (0.009092) and backward (0.018169) time: 0.028890, iotime: 0.001392 
2022-08-04 10:10:27,618 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047163, Speed: 678.498094 images/s
2022-08-04 10:10:29,190 [dl_trainer.py:731] WARNING [ 39][ 7760/  196][rank:0] loss: 0.119, average forward (0.008851) and backward (0.019303) time: 0.029746, iotime: 0.001374 
2022-08-04 10:10:29,497 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046983, Speed: 681.093132 images/s
2022-08-04 10:10:31,059 [dl_trainer.py:731] WARNING [ 39][ 7800/  196][rank:0] loss: 0.150, average forward (0.011430) and backward (0.019218) time: 0.032489, iotime: 0.001587 
2022-08-04 10:10:31,077 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:10:31,077 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:10:33,082 [dl_trainer.py:731] WARNING [ 39][ 7840/  196][rank:0] loss: 0.307, average forward (0.009183) and backward (0.020430) time: 0.035184, iotime: 0.005327 
2022-08-04 10:10:33,101 [dl_trainer.py:634] INFO train iter: 7840, num_batches_per_epoch: 196
2022-08-04 10:10:33,102 [dl_trainer.py:635] INFO Epoch 40, avg train acc: 91.342474, lr: 0.100000, avg loss: 0.242638
2022-08-04 10:10:35,710 [dl_trainer.py:822] INFO Epoch 40, lr: 0.100000, val loss: 0.397620, val top-1 acc: 87.500000, top-5 acc: 99.540735
2022-08-04 10:10:35,774 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083683, Speed: 382.394635 images/s
2022-08-04 10:10:37,643 [dl_trainer.py:731] WARNING [ 40][ 7880/  196][rank:0] loss: 0.262, average forward (0.010025) and backward (0.018421) time: 0.096199, iotime: 0.001461 
2022-08-04 10:10:37,704 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048241, Speed: 663.335984 images/s
2022-08-04 10:10:39,596 [dl_trainer.py:731] WARNING [ 40][ 7920/  196][rank:0] loss: 0.262, average forward (0.008778) and backward (0.021160) time: 0.031555, iotime: 0.001385 
2022-08-04 10:10:39,643 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048464, Speed: 660.290091 images/s
2022-08-04 10:10:41,467 [dl_trainer.py:731] WARNING [ 40][ 7960/  196][rank:0] loss: 0.281, average forward (0.010141) and backward (0.018164) time: 0.030024, iotime: 0.001477 
2022-08-04 10:10:41,549 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047625, Speed: 671.915180 images/s
2022-08-04 10:10:43,154 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:10:43,154 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:10:43,548 [dl_trainer.py:731] WARNING [ 40][ 8000/  196][rank:0] loss: 0.177, average forward (0.010041) and backward (0.020267) time: 0.036080, iotime: 0.005508 
2022-08-04 10:10:45,236 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049145, Speed: 651.129313 images/s
2022-08-04 10:10:45,237 [dl_trainer.py:634] INFO train iter: 8036, num_batches_per_epoch: 196
2022-08-04 10:10:45,237 [dl_trainer.py:635] INFO Epoch 41, avg train acc: 91.852679, lr: 0.100000, avg loss: 0.231766
2022-08-04 10:10:47,833 [dl_trainer.py:822] INFO Epoch 41, lr: 0.100000, val loss: 0.443065, val top-1 acc: 86.331869, top-5 acc: 99.430911
2022-08-04 10:10:47,998 [dl_trainer.py:731] WARNING [ 41][ 8040/  196][rank:0] loss: 0.109, average forward (0.010105) and backward (0.021745) time: 0.098556, iotime: 0.001503 
2022-08-04 10:10:49,722 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112147, Speed: 285.339116 images/s
2022-08-04 10:10:49,897 [dl_trainer.py:731] WARNING [ 41][ 8080/  196][rank:0] loss: 0.245, average forward (0.010676) and backward (0.018705) time: 0.031146, iotime: 0.001514 
2022-08-04 10:10:51,573 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046254, Speed: 691.830051 images/s
2022-08-04 10:10:51,746 [dl_trainer.py:731] WARNING [ 41][ 8120/  196][rank:0] loss: 0.246, average forward (0.011080) and backward (0.019551) time: 0.032417, iotime: 0.001541 
2022-08-04 10:10:53,515 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048527, Speed: 659.429838 images/s
2022-08-04 10:10:53,685 [dl_trainer.py:731] WARNING [ 41][ 8160/  196][rank:0] loss: 0.258, average forward (0.010168) and backward (0.017408) time: 0.029306, iotime: 0.001476 
2022-08-04 10:10:55,119 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:10:55,119 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:10:55,748 [dl_trainer.py:731] WARNING [ 41][ 8200/  196][rank:0] loss: 0.295, average forward (0.010608) and backward (0.019597) time: 0.035503, iotime: 0.005054 
2022-08-04 10:10:57,229 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049500, Speed: 646.462928 images/s
2022-08-04 10:10:57,277 [dl_trainer.py:634] INFO train iter: 8232, num_batches_per_epoch: 196
2022-08-04 10:10:57,277 [dl_trainer.py:635] INFO Epoch 42, avg train acc: 91.996173, lr: 0.100000, avg loss: 0.226610
2022-08-04 10:10:59,942 [dl_trainer.py:822] INFO Epoch 42, lr: 0.100000, val loss: 0.509467, val top-1 acc: 84.255192, top-5 acc: 99.480831
2022-08-04 10:11:00,329 [dl_trainer.py:731] WARNING [ 42][ 8240/  196][rank:0] loss: 0.159, average forward (0.010530) and backward (0.019583) time: 0.099029, iotime: 0.001565 
2022-08-04 10:11:01,799 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114258, Speed: 280.068435 images/s
2022-08-04 10:11:02,227 [dl_trainer.py:731] WARNING [ 42][ 8280/  196][rank:0] loss: 0.319, average forward (0.009599) and backward (0.021190) time: 0.032441, iotime: 0.001416 
2022-08-04 10:11:03,705 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047626, Speed: 671.907948 images/s
2022-08-04 10:11:04,118 [dl_trainer.py:731] WARNING [ 42][ 8320/  196][rank:0] loss: 0.193, average forward (0.010071) and backward (0.020789) time: 0.032655, iotime: 0.001550 
2022-08-04 10:11:05,589 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047097, Speed: 679.453821 images/s
2022-08-04 10:11:06,001 [dl_trainer.py:731] WARNING [ 42][ 8360/  196][rank:0] loss: 0.270, average forward (0.009010) and backward (0.020519) time: 0.031173, iotime: 0.001418 
2022-08-04 10:11:07,171 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:11:07,172 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:11:08,019 [dl_trainer.py:731] WARNING [ 42][ 8400/  196][rank:0] loss: 0.215, average forward (0.009667) and backward (0.019961) time: 0.034836, iotime: 0.004956 
2022-08-04 10:11:09,279 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049175, Speed: 650.735247 images/s
2022-08-04 10:11:09,373 [dl_trainer.py:634] INFO train iter: 8428, num_batches_per_epoch: 196
2022-08-04 10:11:09,373 [dl_trainer.py:635] INFO Epoch 43, avg train acc: 92.139668, lr: 0.100000, avg loss: 0.221206
2022-08-04 10:11:12,005 [dl_trainer.py:822] INFO Epoch 43, lr: 0.100000, val loss: 0.415910, val top-1 acc: 86.940895, top-5 acc: 99.520767
2022-08-04 10:11:12,559 [dl_trainer.py:731] WARNING [ 43][ 8440/  196][rank:0] loss: 0.133, average forward (0.009379) and backward (0.021123) time: 0.098020, iotime: 0.001419 
2022-08-04 10:11:13,786 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112669, Speed: 284.016577 images/s
2022-08-04 10:11:14,420 [dl_trainer.py:731] WARNING [ 43][ 8480/  196][rank:0] loss: 0.229, average forward (0.009617) and backward (0.020006) time: 0.031332, iotime: 0.001475 
2022-08-04 10:11:15,719 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048305, Speed: 662.463203 images/s
2022-08-04 10:11:16,348 [dl_trainer.py:731] WARNING [ 43][ 8520/  196][rank:0] loss: 0.317, average forward (0.008879) and backward (0.015074) time: 0.025542, iotime: 0.001343 
2022-08-04 10:11:17,642 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048059, Speed: 665.843788 images/s
2022-08-04 10:11:18,274 [dl_trainer.py:731] WARNING [ 43][ 8560/  196][rank:0] loss: 0.072, average forward (0.010517) and backward (0.019152) time: 0.031395, iotime: 0.001469 
2022-08-04 10:11:19,256 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:11:19,256 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:11:20,365 [dl_trainer.py:731] WARNING [ 43][ 8600/  196][rank:0] loss: 0.149, average forward (0.010190) and backward (0.019997) time: 0.035477, iotime: 0.005025 
2022-08-04 10:11:21,336 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049246, Speed: 649.800399 images/s
2022-08-04 10:11:21,480 [dl_trainer.py:634] INFO train iter: 8624, num_batches_per_epoch: 196
2022-08-04 10:11:21,481 [dl_trainer.py:635] INFO Epoch 44, avg train acc: 92.538265, lr: 0.100000, avg loss: 0.221293
2022-08-04 10:11:24,355 [dl_trainer.py:822] INFO Epoch 44, lr: 0.100000, val loss: 0.416265, val top-1 acc: 87.330272, top-5 acc: 99.380990
2022-08-04 10:11:25,150 [dl_trainer.py:731] WARNING [ 44][ 8640/  196][rank:0] loss: 0.108, average forward (0.010729) and backward (0.019794) time: 0.104919, iotime: 0.001525 
2022-08-04 10:11:26,129 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.119801, Speed: 267.110003 images/s
2022-08-04 10:11:27,006 [dl_trainer.py:731] WARNING [ 44][ 8680/  196][rank:0] loss: 0.054, average forward (0.010960) and backward (0.019924) time: 0.032749, iotime: 0.001605 
2022-08-04 10:11:28,023 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047351, Speed: 675.806445 images/s
2022-08-04 10:11:28,967 [dl_trainer.py:731] WARNING [ 44][ 8720/  196][rank:0] loss: 0.394, average forward (0.012084) and backward (0.022338) time: 0.036436, iotime: 0.001729 
2022-08-04 10:11:30,013 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049737, Speed: 643.386816 images/s
2022-08-04 10:11:30,960 [dl_trainer.py:731] WARNING [ 44][ 8760/  196][rank:0] loss: 0.277, average forward (0.013554) and backward (0.024135) time: 0.039938, iotime: 0.001926 
2022-08-04 10:11:31,714 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:11:31,714 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:11:33,022 [dl_trainer.py:731] WARNING [ 44][ 8800/  196][rank:0] loss: 0.311, average forward (0.012068) and backward (0.020110) time: 0.037714, iotime: 0.005238 
2022-08-04 10:11:33,806 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050543, Speed: 633.123435 images/s
2022-08-04 10:11:33,993 [dl_trainer.py:634] INFO train iter: 8820, num_batches_per_epoch: 196
2022-08-04 10:11:33,994 [dl_trainer.py:635] INFO Epoch 45, avg train acc: 91.565689, lr: 0.100000, avg loss: 0.243291
2022-08-04 10:11:36,617 [dl_trainer.py:822] INFO Epoch 45, lr: 0.100000, val loss: 0.498226, val top-1 acc: 85.443291, top-5 acc: 99.440895
2022-08-04 10:11:37,581 [dl_trainer.py:731] WARNING [ 45][ 8840/  196][rank:0] loss: 0.340, average forward (0.010905) and backward (0.021561) time: 0.099942, iotime: 0.001576 
2022-08-04 10:11:38,339 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113328, Speed: 282.366902 images/s
2022-08-04 10:11:39,446 [dl_trainer.py:731] WARNING [ 45][ 8880/  196][rank:0] loss: 0.097, average forward (0.009519) and backward (0.022275) time: 0.033464, iotime: 0.001434 
2022-08-04 10:11:40,193 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046338, Speed: 690.578047 images/s
2022-08-04 10:11:41,345 [dl_trainer.py:731] WARNING [ 45][ 8920/  196][rank:0] loss: 0.062, average forward (0.010298) and backward (0.021993) time: 0.034063, iotime: 0.001519 
2022-08-04 10:11:42,112 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047964, Speed: 667.166535 images/s
2022-08-04 10:11:43,257 [dl_trainer.py:731] WARNING [ 45][ 8960/  196][rank:0] loss: 0.192, average forward (0.011167) and backward (0.021250) time: 0.034324, iotime: 0.001648 
2022-08-04 10:11:43,746 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:11:43,746 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:11:45,297 [dl_trainer.py:731] WARNING [ 45][ 9000/  196][rank:0] loss: 0.528, average forward (0.011111) and backward (0.021987) time: 0.038397, iotime: 0.005028 
2022-08-04 10:11:45,832 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049578, Speed: 645.447713 images/s
2022-08-04 10:11:46,079 [dl_trainer.py:634] INFO train iter: 9016, num_batches_per_epoch: 196
2022-08-04 10:11:46,079 [dl_trainer.py:635] INFO Epoch 46, avg train acc: 92.251276, lr: 0.100000, avg loss: 0.236890
2022-08-04 10:11:48,715 [dl_trainer.py:822] INFO Epoch 46, lr: 0.100000, val loss: 0.458546, val top-1 acc: 85.802716, top-5 acc: 99.510783
2022-08-04 10:11:49,803 [dl_trainer.py:731] WARNING [ 46][ 9040/  196][rank:0] loss: 0.085, average forward (0.010554) and backward (0.021436) time: 0.100226, iotime: 0.001574 
2022-08-04 10:11:50,341 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112722, Speed: 283.884268 images/s
2022-08-04 10:11:51,702 [dl_trainer.py:731] WARNING [ 46][ 9080/  196][rank:0] loss: 0.331, average forward (0.010094) and backward (0.021730) time: 0.033624, iotime: 0.001554 
2022-08-04 10:11:52,248 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047654, Speed: 671.500690 images/s
2022-08-04 10:11:53,575 [dl_trainer.py:731] WARNING [ 46][ 9120/  196][rank:0] loss: 0.147, average forward (0.009648) and backward (0.020520) time: 0.031851, iotime: 0.001444 
2022-08-04 10:11:54,107 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046459, Speed: 688.784902 images/s
2022-08-04 10:11:55,413 [dl_trainer.py:731] WARNING [ 46][ 9160/  196][rank:0] loss: 0.377, average forward (0.009381) and backward (0.018509) time: 0.029574, iotime: 0.001426 
2022-08-04 10:11:55,661 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:11:55,661 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:11:57,451 [dl_trainer.py:731] WARNING [ 46][ 9200/  196][rank:0] loss: 0.098, average forward (0.009523) and backward (0.019324) time: 0.034181, iotime: 0.005076 
2022-08-04 10:11:57,747 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048514, Speed: 659.608419 images/s
2022-08-04 10:11:58,043 [dl_trainer.py:634] INFO train iter: 9212, num_batches_per_epoch: 196
2022-08-04 10:11:58,043 [dl_trainer.py:635] INFO Epoch 47, avg train acc: 92.123724, lr: 0.100000, avg loss: 0.230520
2022-08-04 10:12:00,665 [dl_trainer.py:822] INFO Epoch 47, lr: 0.100000, val loss: 0.511709, val top-1 acc: 85.153754, top-5 acc: 99.341054
2022-08-04 10:12:01,981 [dl_trainer.py:731] WARNING [ 47][ 9240/  196][rank:0] loss: 0.099, average forward (0.011304) and backward (0.018419) time: 0.097163, iotime: 0.001583 
2022-08-04 10:12:02,285 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113435, Speed: 282.099836 images/s
2022-08-04 10:12:03,900 [dl_trainer.py:731] WARNING [ 47][ 9280/  196][rank:0] loss: 0.052, average forward (0.008358) and backward (0.018983) time: 0.028918, iotime: 0.001353 
2022-08-04 10:12:04,194 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047707, Speed: 670.761141 images/s
2022-08-04 10:12:05,773 [dl_trainer.py:731] WARNING [ 47][ 9320/  196][rank:0] loss: 0.226, average forward (0.010201) and backward (0.020961) time: 0.032853, iotime: 0.001451 
2022-08-04 10:12:06,086 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047301, Speed: 676.513432 images/s
2022-08-04 10:12:07,678 [dl_trainer.py:731] WARNING [ 47][ 9360/  196][rank:0] loss: 0.437, average forward (0.008094) and backward (0.019725) time: 0.029308, iotime: 0.001274 
2022-08-04 10:12:07,696 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:12:07,697 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:12:09,712 [dl_trainer.py:731] WARNING [ 47][ 9400/  196][rank:0] loss: 0.256, average forward (0.009082) and backward (0.020094) time: 0.034413, iotime: 0.004985 
2022-08-04 10:12:09,778 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049204, Speed: 650.350565 images/s
2022-08-04 10:12:10,117 [dl_trainer.py:634] INFO train iter: 9408, num_batches_per_epoch: 196
2022-08-04 10:12:10,117 [dl_trainer.py:635] INFO Epoch 48, avg train acc: 92.123724, lr: 0.100000, avg loss: 0.228960
2022-08-04 10:12:12,778 [dl_trainer.py:822] INFO Epoch 48, lr: 0.100000, val loss: 0.463287, val top-1 acc: 86.291933, top-5 acc: 99.470847
2022-08-04 10:12:14,234 [dl_trainer.py:731] WARNING [ 48][ 9440/  196][rank:0] loss: 0.226, average forward (0.010192) and backward (0.021115) time: 0.100086, iotime: 0.001522 
2022-08-04 10:12:14,285 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112667, Speed: 284.024045 images/s
2022-08-04 10:12:16,169 [dl_trainer.py:731] WARNING [ 48][ 9480/  196][rank:0] loss: 0.401, average forward (0.008830) and backward (0.018981) time: 0.029394, iotime: 0.001353 
2022-08-04 10:12:16,231 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048648, Speed: 657.784940 images/s
2022-08-04 10:12:18,000 [dl_trainer.py:731] WARNING [ 48][ 9520/  196][rank:0] loss: 0.311, average forward (0.008771) and backward (0.021126) time: 0.031470, iotime: 0.001363 
2022-08-04 10:12:18,062 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045761, Speed: 699.289773 images/s
2022-08-04 10:12:19,676 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:12:19,676 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:12:20,051 [dl_trainer.py:731] WARNING [ 48][ 9560/  196][rank:0] loss: 0.163, average forward (0.009665) and backward (0.019817) time: 0.035043, iotime: 0.005295 
2022-08-04 10:12:21,805 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049880, Speed: 641.540442 images/s
2022-08-04 10:12:21,973 [dl_trainer.py:731] WARNING [ 48][ 9600/  196][rank:0] loss: 0.302, average forward (0.009210) and backward (0.020207) time: 0.031068, iotime: 0.001405 
2022-08-04 10:12:22,182 [dl_trainer.py:634] INFO train iter: 9604, num_batches_per_epoch: 196
2022-08-04 10:12:22,182 [dl_trainer.py:635] INFO Epoch 49, avg train acc: 92.315051, lr: 0.100000, avg loss: 0.220127
2022-08-04 10:12:24,832 [dl_trainer.py:822] INFO Epoch 49, lr: 0.100000, val loss: 0.440997, val top-1 acc: 87.300319, top-5 acc: 99.480831
2022-08-04 10:12:26,318 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112821, Speed: 283.634283 images/s
2022-08-04 10:12:26,492 [dl_trainer.py:731] WARNING [ 49][ 9640/  196][rank:0] loss: 0.181, average forward (0.010016) and backward (0.020098) time: 0.098289, iotime: 0.001490 
2022-08-04 10:12:28,233 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047859, Speed: 668.634584 images/s
2022-08-04 10:12:28,420 [dl_trainer.py:731] WARNING [ 49][ 9680/  196][rank:0] loss: 0.253, average forward (0.009587) and backward (0.020923) time: 0.032214, iotime: 0.001466 
2022-08-04 10:12:30,146 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047821, Speed: 669.167127 images/s
2022-08-04 10:12:30,314 [dl_trainer.py:731] WARNING [ 49][ 9720/  196][rank:0] loss: 0.350, average forward (0.010213) and backward (0.020519) time: 0.032469, iotime: 0.001487 
2022-08-04 10:12:31,750 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:12:31,750 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:12:32,385 [dl_trainer.py:731] WARNING [ 49][ 9760/  196][rank:0] loss: 0.084, average forward (0.010014) and backward (0.020132) time: 0.035470, iotime: 0.005067 
2022-08-04 10:12:33,890 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049907, Speed: 641.189136 images/s
2022-08-04 10:12:34,304 [dl_trainer.py:731] WARNING [ 49][ 9800/  196][rank:0] loss: 0.165, average forward (0.008931) and backward (0.020744) time: 0.031200, iotime: 0.001295 
2022-08-04 10:12:34,331 [dl_trainer.py:634] INFO train iter: 9800, num_batches_per_epoch: 196
2022-08-04 10:12:34,331 [dl_trainer.py:635] INFO Epoch 50, avg train acc: 92.713648, lr: 0.100000, avg loss: 0.213896
2022-08-04 10:12:36,985 [dl_trainer.py:822] INFO Epoch 50, lr: 0.100000, val loss: 0.427234, val top-1 acc: 86.880990, top-5 acc: 99.530751
2022-08-04 10:12:38,449 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113948, Speed: 280.829398 images/s
2022-08-04 10:12:38,856 [dl_trainer.py:731] WARNING [ 50][ 9840/  196][rank:0] loss: 0.231, average forward (0.009732) and backward (0.020630) time: 0.098885, iotime: 0.001485 
2022-08-04 10:12:40,357 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047693, Speed: 670.961409 images/s
2022-08-04 10:12:40,770 [dl_trainer.py:731] WARNING [ 50][ 9880/  196][rank:0] loss: 0.186, average forward (0.008664) and backward (0.020353) time: 0.030574, iotime: 0.001333 
2022-08-04 10:12:42,257 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047492, Speed: 673.799927 images/s
2022-08-04 10:12:42,670 [dl_trainer.py:731] WARNING [ 50][ 9920/  196][rank:0] loss: 0.408, average forward (0.010796) and backward (0.021884) time: 0.034460, iotime: 0.001515 
2022-08-04 10:12:43,835 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:12:43,835 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:12:44,678 [dl_trainer.py:731] WARNING [ 50][ 9960/  196][rank:0] loss: 0.166, average forward (0.008991) and backward (0.019163) time: 0.033504, iotime: 0.005107 
2022-08-04 10:12:45,910 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048687, Speed: 657.264269 images/s
2022-08-04 10:12:46,400 [dl_trainer.py:634] INFO train iter: 9996, num_batches_per_epoch: 196
2022-08-04 10:12:46,400 [dl_trainer.py:635] INFO Epoch 51, avg train acc: 92.809311, lr: 0.100000, avg loss: 0.200081
2022-08-04 10:12:49,032 [dl_trainer.py:822] INFO Epoch 51, lr: 0.100000, val loss: 0.420827, val top-1 acc: 87.160543, top-5 acc: 99.460863
2022-08-04 10:12:49,212 [dl_trainer.py:731] WARNING [ 51][10000/  196][rank:0] loss: 0.347, average forward (0.008879) and backward (0.020578) time: 0.096929, iotime: 0.001358 
2022-08-04 10:12:50,432 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113047, Speed: 283.066961 images/s
2022-08-04 10:12:51,092 [dl_trainer.py:731] WARNING [ 51][10040/  196][rank:0] loss: 0.121, average forward (0.009730) and backward (0.019305) time: 0.030741, iotime: 0.001471 
2022-08-04 10:12:52,349 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047928, Speed: 667.669920 images/s
2022-08-04 10:12:52,989 [dl_trainer.py:731] WARNING [ 51][10080/  196][rank:0] loss: 0.150, average forward (0.009610) and backward (0.018655) time: 0.029948, iotime: 0.001433 
2022-08-04 10:12:54,273 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048069, Speed: 665.713915 images/s
2022-08-04 10:12:54,909 [dl_trainer.py:731] WARNING [ 51][10120/  196][rank:0] loss: 0.239, average forward (0.008902) and backward (0.021608) time: 0.032149, iotime: 0.001411 
2022-08-04 10:12:55,888 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:12:55,888 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:12:57,018 [dl_trainer.py:731] WARNING [ 51][10160/  196][rank:0] loss: 0.062, average forward (0.010642) and backward (0.021578) time: 0.037958, iotime: 0.005472 
2022-08-04 10:12:57,988 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049512, Speed: 646.304002 images/s
2022-08-04 10:12:58,496 [dl_trainer.py:634] INFO train iter: 10192, num_batches_per_epoch: 196
2022-08-04 10:12:58,496 [dl_trainer.py:635] INFO Epoch 52, avg train acc: 92.346939, lr: 0.100000, avg loss: 0.217696
2022-08-04 10:13:01,091 [dl_trainer.py:822] INFO Epoch 52, lr: 0.100000, val loss: 0.448862, val top-1 acc: 86.331869, top-5 acc: 99.380990
2022-08-04 10:13:01,461 [dl_trainer.py:731] WARNING [ 52][10200/  196][rank:0] loss: 0.315, average forward (0.011542) and backward (0.018076) time: 0.096886, iotime: 0.001599 
2022-08-04 10:13:02,479 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112273, Speed: 285.020031 images/s
2022-08-04 10:13:03,397 [dl_trainer.py:731] WARNING [ 52][10240/  196][rank:0] loss: 0.362, average forward (0.010801) and backward (0.021356) time: 0.033973, iotime: 0.001539 
2022-08-04 10:13:04,389 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047746, Speed: 670.214262 images/s
2022-08-04 10:13:05,234 [dl_trainer.py:731] WARNING [ 52][10280/  196][rank:0] loss: 0.335, average forward (0.009480) and backward (0.019680) time: 0.030858, iotime: 0.001462 
2022-08-04 10:13:06,251 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046525, Speed: 687.806728 images/s
2022-08-04 10:13:07,171 [dl_trainer.py:731] WARNING [ 52][10320/  196][rank:0] loss: 0.207, average forward (0.011510) and backward (0.019009) time: 0.032439, iotime: 0.001653 
2022-08-04 10:13:07,939 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:13:07,939 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:13:09,299 [dl_trainer.py:731] WARNING [ 52][10360/  196][rank:0] loss: 0.234, average forward (0.008446) and backward (0.020655) time: 0.034142, iotime: 0.004808 
2022-08-04 10:13:10,066 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050847, Speed: 629.332984 images/s
2022-08-04 10:13:10,650 [dl_trainer.py:634] INFO train iter: 10388, num_batches_per_epoch: 196
2022-08-04 10:13:10,650 [dl_trainer.py:635] INFO Epoch 53, avg train acc: 92.729592, lr: 0.100000, avg loss: 0.203534
2022-08-04 10:13:13,266 [dl_trainer.py:822] INFO Epoch 53, lr: 0.100000, val loss: 0.400856, val top-1 acc: 87.160543, top-5 acc: 99.460863
2022-08-04 10:13:13,823 [dl_trainer.py:731] WARNING [ 53][10400/  196][rank:0] loss: 0.080, average forward (0.009528) and backward (0.021629) time: 0.098279, iotime: 0.001428 
2022-08-04 10:13:14,605 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113478, Speed: 281.992010 images/s
2022-08-04 10:13:15,758 [dl_trainer.py:731] WARNING [ 53][10440/  196][rank:0] loss: 0.194, average forward (0.011704) and backward (0.022810) time: 0.036491, iotime: 0.001697 
2022-08-04 10:13:16,510 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047594, Speed: 672.347358 images/s
2022-08-04 10:13:17,642 [dl_trainer.py:731] WARNING [ 53][10480/  196][rank:0] loss: 0.104, average forward (0.011261) and backward (0.021281) time: 0.034426, iotime: 0.001622 
2022-08-04 10:13:18,448 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048434, Speed: 660.698008 images/s
2022-08-04 10:13:19,574 [dl_trainer.py:731] WARNING [ 53][10520/  196][rank:0] loss: 0.453, average forward (0.011133) and backward (0.021817) time: 0.034801, iotime: 0.001586 
2022-08-04 10:13:20,054 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:13:20,054 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:13:21,593 [dl_trainer.py:731] WARNING [ 53][10560/  196][rank:0] loss: 0.392, average forward (0.010646) and backward (0.021939) time: 0.038138, iotime: 0.005278 
2022-08-04 10:13:22,127 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049035, Speed: 652.589723 images/s
2022-08-04 10:13:22,747 [dl_trainer.py:634] INFO train iter: 10584, num_batches_per_epoch: 196
2022-08-04 10:13:22,748 [dl_trainer.py:635] INFO Epoch 54, avg train acc: 92.841199, lr: 0.100000, avg loss: 0.205443
2022-08-04 10:13:25,389 [dl_trainer.py:822] INFO Epoch 54, lr: 0.100000, val loss: 0.414746, val top-1 acc: 87.490016, top-5 acc: 99.480831
2022-08-04 10:13:26,173 [dl_trainer.py:731] WARNING [ 54][10600/  196][rank:0] loss: 0.164, average forward (0.009707) and backward (0.020238) time: 0.098244, iotime: 0.001497 
2022-08-04 10:13:26,706 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114471, Speed: 279.546755 images/s
2022-08-04 10:13:28,053 [dl_trainer.py:731] WARNING [ 54][10640/  196][rank:0] loss: 0.119, average forward (0.010849) and backward (0.019443) time: 0.032100, iotime: 0.001536 
2022-08-04 10:13:28,563 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046410, Speed: 689.506478 images/s
2022-08-04 10:13:29,919 [dl_trainer.py:731] WARNING [ 54][10680/  196][rank:0] loss: 0.281, average forward (0.009433) and backward (0.021108) time: 0.032259, iotime: 0.001471 
2022-08-04 10:13:30,461 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047449, Speed: 674.405281 images/s
2022-08-04 10:13:31,782 [dl_trainer.py:731] WARNING [ 54][10720/  196][rank:0] loss: 0.227, average forward (0.008929) and backward (0.021733) time: 0.032314, iotime: 0.001411 
2022-08-04 10:13:32,042 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:13:32,043 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:13:33,859 [dl_trainer.py:731] WARNING [ 54][10760/  196][rank:0] loss: 0.189, average forward (0.009726) and backward (0.021591) time: 0.036730, iotime: 0.005151 
2022-08-04 10:13:34,161 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049311, Speed: 648.943403 images/s
2022-08-04 10:13:34,816 [dl_trainer.py:634] INFO train iter: 10780, num_batches_per_epoch: 196
2022-08-04 10:13:34,816 [dl_trainer.py:635] INFO Epoch 55, avg train acc: 92.554209, lr: 0.100000, avg loss: 0.209055
2022-08-04 10:13:37,455 [dl_trainer.py:822] INFO Epoch 55, lr: 0.100000, val loss: 0.606795, val top-1 acc: 82.857428, top-5 acc: 99.331070
2022-08-04 10:13:38,383 [dl_trainer.py:731] WARNING [ 55][10800/  196][rank:0] loss: 0.042, average forward (0.009853) and backward (0.020520) time: 0.098135, iotime: 0.001488 
2022-08-04 10:13:38,689 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113214, Speed: 282.650293 images/s
2022-08-04 10:13:40,309 [dl_trainer.py:731] WARNING [ 55][10840/  196][rank:0] loss: 0.199, average forward (0.010650) and backward (0.021108) time: 0.033573, iotime: 0.001549 
2022-08-04 10:13:40,595 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047632, Speed: 671.815881 images/s
2022-08-04 10:13:42,206 [dl_trainer.py:731] WARNING [ 55][10880/  196][rank:0] loss: 0.122, average forward (0.010051) and backward (0.019816) time: 0.031667, iotime: 0.001545 
2022-08-04 10:13:42,495 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047490, Speed: 673.820477 images/s
2022-08-04 10:13:44,104 [dl_trainer.py:731] WARNING [ 55][10920/  196][rank:0] loss: 0.092, average forward (0.009924) and backward (0.020257) time: 0.031872, iotime: 0.001453 
2022-08-04 10:13:44,121 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:13:44,121 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:13:46,192 [dl_trainer.py:731] WARNING [ 55][10960/  196][rank:0] loss: 0.174, average forward (0.009559) and backward (0.021919) time: 0.036659, iotime: 0.004929 
2022-08-04 10:13:46,257 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050146, Speed: 638.142290 images/s
2022-08-04 10:13:46,942 [dl_trainer.py:634] INFO train iter: 10976, num_batches_per_epoch: 196
2022-08-04 10:13:46,942 [dl_trainer.py:635] INFO Epoch 56, avg train acc: 92.936862, lr: 0.100000, avg loss: 0.200186
2022-08-04 10:13:49,548 [dl_trainer.py:822] INFO Epoch 56, lr: 0.100000, val loss: 0.562541, val top-1 acc: 83.696086, top-5 acc: 99.131390
2022-08-04 10:13:50,704 [dl_trainer.py:731] WARNING [ 56][11000/  196][rank:0] loss: 0.201, average forward (0.010324) and backward (0.020459) time: 0.098165, iotime: 0.001507 
2022-08-04 10:13:50,767 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112749, Speed: 283.816659 images/s
2022-08-04 10:13:52,669 [dl_trainer.py:731] WARNING [ 56][11040/  196][rank:0] loss: 0.125, average forward (0.008523) and backward (0.022562) time: 0.032678, iotime: 0.001366 
2022-08-04 10:13:52,729 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049044, Speed: 652.480706 images/s
2022-08-04 10:13:54,531 [dl_trainer.py:731] WARNING [ 56][11080/  196][rank:0] loss: 0.283, average forward (0.008898) and backward (0.020131) time: 0.030615, iotime: 0.001359 
2022-08-04 10:13:54,603 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046837, Speed: 683.213371 images/s
2022-08-04 10:13:56,234 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:13:56,235 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:13:56,608 [dl_trainer.py:731] WARNING [ 56][11120/  196][rank:0] loss: 0.235, average forward (0.008698) and backward (0.020302) time: 0.034324, iotime: 0.005091 
2022-08-04 10:13:58,307 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049364, Speed: 648.244754 images/s
2022-08-04 10:13:58,484 [dl_trainer.py:731] WARNING [ 56][11160/  196][rank:0] loss: 0.281, average forward (0.010695) and backward (0.021135) time: 0.033604, iotime: 0.001525 
2022-08-04 10:13:59,082 [dl_trainer.py:634] INFO train iter: 11172, num_batches_per_epoch: 196
2022-08-04 10:13:59,083 [dl_trainer.py:635] INFO Epoch 57, avg train acc: 92.713648, lr: 0.100000, avg loss: 0.208061
2022-08-04 10:14:01,743 [dl_trainer.py:822] INFO Epoch 57, lr: 0.100000, val loss: 0.434864, val top-1 acc: 86.571486, top-5 acc: 99.560703
2022-08-04 10:14:02,861 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113829, Speed: 281.122721 images/s
2022-08-04 10:14:03,051 [dl_trainer.py:731] WARNING [ 57][11200/  196][rank:0] loss: 0.106, average forward (0.010425) and backward (0.020212) time: 0.099011, iotime: 0.001549 
2022-08-04 10:14:04,759 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047441, Speed: 674.525177 images/s
2022-08-04 10:14:04,937 [dl_trainer.py:731] WARNING [ 57][11240/  196][rank:0] loss: 0.309, average forward (0.010002) and backward (0.019885) time: 0.031642, iotime: 0.001511 
2022-08-04 10:14:06,643 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047115, Speed: 679.194487 images/s
2022-08-04 10:14:06,818 [dl_trainer.py:731] WARNING [ 57][11280/  196][rank:0] loss: 0.450, average forward (0.009909) and backward (0.021111) time: 0.032734, iotime: 0.001475 
2022-08-04 10:14:08,294 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:14:08,295 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:14:08,927 [dl_trainer.py:731] WARNING [ 57][11320/  196][rank:0] loss: 0.349, average forward (0.011426) and backward (0.019411) time: 0.036130, iotime: 0.005010 
2022-08-04 10:14:10,436 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050552, Speed: 633.006982 images/s
2022-08-04 10:14:10,844 [dl_trainer.py:731] WARNING [ 57][11360/  196][rank:0] loss: 0.219, average forward (0.008353) and backward (0.020461) time: 0.030319, iotime: 0.001290 
2022-08-04 10:14:11,228 [dl_trainer.py:634] INFO train iter: 11368, num_batches_per_epoch: 196
2022-08-04 10:14:11,228 [dl_trainer.py:635] INFO Epoch 58, avg train acc: 93.191964, lr: 0.100000, avg loss: 0.196541
2022-08-04 10:14:13,864 [dl_trainer.py:822] INFO Epoch 58, lr: 0.100000, val loss: 0.378028, val top-1 acc: 88.458466, top-5 acc: 99.540735
2022-08-04 10:14:14,957 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113024, Speed: 283.126299 images/s
2022-08-04 10:14:15,373 [dl_trainer.py:731] WARNING [ 58][11400/  196][rank:0] loss: 0.196, average forward (0.009311) and backward (0.020104) time: 0.097418, iotime: 0.001451 
2022-08-04 10:14:16,800 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046053, Speed: 694.857815 images/s
2022-08-04 10:14:17,223 [dl_trainer.py:731] WARNING [ 58][11440/  196][rank:0] loss: 0.103, average forward (0.010195) and backward (0.019070) time: 0.031008, iotime: 0.001491 
2022-08-04 10:14:18,699 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047467, Speed: 674.155203 images/s
2022-08-04 10:14:19,106 [dl_trainer.py:731] WARNING [ 58][11480/  196][rank:0] loss: 0.196, average forward (0.010862) and backward (0.019510) time: 0.032176, iotime: 0.001552 
2022-08-04 10:14:20,306 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:14:20,306 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:14:21,145 [dl_trainer.py:731] WARNING [ 58][11520/  196][rank:0] loss: 0.074, average forward (0.010079) and backward (0.021437) time: 0.037008, iotime: 0.005244 
2022-08-04 10:14:22,330 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048404, Speed: 661.103900 images/s
2022-08-04 10:14:22,994 [dl_trainer.py:731] WARNING [ 58][11560/  196][rank:0] loss: 0.062, average forward (0.010384) and backward (0.020186) time: 0.032311, iotime: 0.001487 
2022-08-04 10:14:23,182 [dl_trainer.py:634] INFO train iter: 11564, num_batches_per_epoch: 196
2022-08-04 10:14:23,182 [dl_trainer.py:635] INFO Epoch 59, avg train acc: 92.968750, lr: 0.100000, avg loss: 0.194326
2022-08-04 10:14:25,800 [dl_trainer.py:822] INFO Epoch 59, lr: 0.100000, val loss: 0.424177, val top-1 acc: 87.559904, top-5 acc: 99.341054
2022-08-04 10:14:26,816 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112129, Speed: 285.385485 images/s
2022-08-04 10:14:27,433 [dl_trainer.py:731] WARNING [ 59][11600/  196][rank:0] loss: 0.220, average forward (0.009826) and backward (0.020055) time: 0.097219, iotime: 0.001549 
2022-08-04 10:14:28,617 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045006, Speed: 711.023073 images/s
2022-08-04 10:14:29,290 [dl_trainer.py:731] WARNING [ 59][11640/  196][rank:0] loss: 0.210, average forward (0.010051) and backward (0.018853) time: 0.030649, iotime: 0.001494 
2022-08-04 10:14:30,588 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049267, Speed: 649.526472 images/s
2022-08-04 10:14:31,242 [dl_trainer.py:731] WARNING [ 59][11680/  196][rank:0] loss: 0.108, average forward (0.010068) and backward (0.019335) time: 0.031128, iotime: 0.001484 
2022-08-04 10:14:32,264 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:14:32,264 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:14:33,315 [dl_trainer.py:731] WARNING [ 59][11720/  196][rank:0] loss: 0.247, average forward (0.009668) and backward (0.019470) time: 0.034376, iotime: 0.004992 
2022-08-04 10:14:34,287 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049303, Speed: 649.046795 images/s
2022-08-04 10:14:35,165 [dl_trainer.py:731] WARNING [ 59][11760/  196][rank:0] loss: 0.247, average forward (0.010185) and backward (0.021222) time: 0.033147, iotime: 0.001497 
2022-08-04 10:14:35,173 [dl_trainer.py:634] INFO train iter: 11760, num_batches_per_epoch: 196
2022-08-04 10:14:35,174 [dl_trainer.py:635] INFO Epoch 60, avg train acc: 93.303571, lr: 0.100000, avg loss: 0.195639
2022-08-04 10:14:37,828 [dl_trainer.py:822] INFO Epoch 60, lr: 0.100000, val loss: 0.476939, val top-1 acc: 85.992412, top-5 acc: 99.351038
2022-08-04 10:14:38,848 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114015, Speed: 280.665937 images/s
2022-08-04 10:14:39,780 [dl_trainer.py:731] WARNING [ 60][11800/  196][rank:0] loss: 0.201, average forward (0.009971) and backward (0.022574) time: 0.101245, iotime: 0.001585 
2022-08-04 10:14:40,738 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047249, Speed: 677.260686 images/s
2022-08-04 10:14:41,625 [dl_trainer.py:731] WARNING [ 60][11840/  196][rank:0] loss: 0.187, average forward (0.010646) and backward (0.020764) time: 0.033237, iotime: 0.001585 
2022-08-04 10:14:42,672 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048339, Speed: 661.988450 images/s
2022-08-04 10:14:43,535 [dl_trainer.py:731] WARNING [ 60][11880/  196][rank:0] loss: 0.124, average forward (0.010262) and backward (0.020070) time: 0.032083, iotime: 0.001491 
2022-08-04 10:14:44,285 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:14:44,285 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:14:45,624 [dl_trainer.py:731] WARNING [ 60][11920/  196][rank:0] loss: 0.116, average forward (0.010729) and backward (0.021120) time: 0.037495, iotime: 0.005368 
2022-08-04 10:14:46,404 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049748, Speed: 643.238390 images/s
2022-08-04 10:14:47,352 [dl_trainer.py:634] INFO train iter: 11956, num_batches_per_epoch: 196
2022-08-04 10:14:47,353 [dl_trainer.py:635] INFO Epoch 61, avg train acc: 93.032526, lr: 0.100000, avg loss: 0.191109
2022-08-04 10:14:50,000 [dl_trainer.py:822] INFO Epoch 61, lr: 0.100000, val loss: 0.469257, val top-1 acc: 86.271965, top-5 acc: 99.371006
2022-08-04 10:14:50,176 [dl_trainer.py:731] WARNING [ 61][11960/  196][rank:0] loss: 0.223, average forward (0.010176) and backward (0.018479) time: 0.096666, iotime: 0.001489 
2022-08-04 10:14:50,953 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113699, Speed: 281.445411 images/s
2022-08-04 10:14:52,055 [dl_trainer.py:731] WARNING [ 61][12000/  196][rank:0] loss: 0.261, average forward (0.010699) and backward (0.019710) time: 0.032254, iotime: 0.001580 
2022-08-04 10:14:52,847 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047338, Speed: 675.990756 images/s
2022-08-04 10:14:54,009 [dl_trainer.py:731] WARNING [ 61][12040/  196][rank:0] loss: 0.218, average forward (0.010325) and backward (0.020064) time: 0.032207, iotime: 0.001567 
2022-08-04 10:14:54,762 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047866, Speed: 668.538583 images/s
2022-08-04 10:14:55,911 [dl_trainer.py:731] WARNING [ 61][12080/  196][rank:0] loss: 0.325, average forward (0.009853) and backward (0.019574) time: 0.031182, iotime: 0.001494 
2022-08-04 10:14:56,404 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:14:56,405 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:14:57,959 [dl_trainer.py:731] WARNING [ 61][12120/  196][rank:0] loss: 0.061, average forward (0.009239) and backward (0.020575) time: 0.034917, iotime: 0.004857 
2022-08-04 10:14:58,456 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049232, Speed: 649.986188 images/s
2022-08-04 10:14:59,469 [dl_trainer.py:634] INFO train iter: 12152, num_batches_per_epoch: 196
2022-08-04 10:14:59,470 [dl_trainer.py:635] INFO Epoch 62, avg train acc: 93.223852, lr: 0.100000, avg loss: 0.194988
2022-08-04 10:15:02,096 [dl_trainer.py:822] INFO Epoch 62, lr: 0.100000, val loss: 0.427158, val top-1 acc: 87.200479, top-5 acc: 99.400958
2022-08-04 10:15:02,476 [dl_trainer.py:731] WARNING [ 62][12160/  196][rank:0] loss: 0.026, average forward (0.010297) and backward (0.019679) time: 0.097918, iotime: 0.001531 
2022-08-04 10:15:03,013 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113927, Speed: 280.882233 images/s
2022-08-04 10:15:04,301 [dl_trainer.py:731] WARNING [ 62][12200/  196][rank:0] loss: 0.303, average forward (0.010923) and backward (0.018456) time: 0.031129, iotime: 0.001501 
2022-08-04 10:15:04,848 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045857, Speed: 697.821574 images/s
2022-08-04 10:15:06,237 [dl_trainer.py:731] WARNING [ 62][12240/  196][rank:0] loss: 0.478, average forward (0.009792) and backward (0.020348) time: 0.031860, iotime: 0.001483 
2022-08-04 10:15:06,740 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047297, Speed: 676.572599 images/s
2022-08-04 10:15:08,081 [dl_trainer.py:731] WARNING [ 62][12280/  196][rank:0] loss: 0.368, average forward (0.010357) and backward (0.019686) time: 0.031767, iotime: 0.001469 
2022-08-04 10:15:08,338 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:15:08,338 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:15:10,113 [dl_trainer.py:731] WARNING [ 62][12320/  196][rank:0] loss: 0.156, average forward (0.011674) and backward (0.021728) time: 0.038898, iotime: 0.005209 
2022-08-04 10:15:10,409 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048903, Speed: 654.359120 images/s
2022-08-04 10:15:11,474 [dl_trainer.py:634] INFO train iter: 12348, num_batches_per_epoch: 196
2022-08-04 10:15:11,475 [dl_trainer.py:635] INFO Epoch 63, avg train acc: 93.048469, lr: 0.100000, avg loss: 0.185211
2022-08-04 10:15:14,100 [dl_trainer.py:822] INFO Epoch 63, lr: 0.100000, val loss: 0.406536, val top-1 acc: 87.470048, top-5 acc: 99.530751
2022-08-04 10:15:14,655 [dl_trainer.py:731] WARNING [ 63][12360/  196][rank:0] loss: 0.259, average forward (0.010854) and backward (0.021372) time: 0.099773, iotime: 0.001579 
2022-08-04 10:15:14,931 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113044, Speed: 283.074796 images/s
2022-08-04 10:15:16,497 [dl_trainer.py:731] WARNING [ 63][12400/  196][rank:0] loss: 0.149, average forward (0.009347) and backward (0.020464) time: 0.031525, iotime: 0.001484 
2022-08-04 10:15:16,793 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046532, Speed: 687.704791 images/s
2022-08-04 10:15:18,367 [dl_trainer.py:731] WARNING [ 63][12440/  196][rank:0] loss: 0.284, average forward (0.011972) and backward (0.020568) time: 0.034457, iotime: 0.001651 
2022-08-04 10:15:18,663 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046739, Speed: 684.650628 images/s
2022-08-04 10:15:20,239 [dl_trainer.py:731] WARNING [ 63][12480/  196][rank:0] loss: 0.245, average forward (0.009491) and backward (0.020884) time: 0.032114, iotime: 0.001503 
2022-08-04 10:15:20,255 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:15:20,255 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:15:22,261 [dl_trainer.py:731] WARNING [ 63][12520/  196][rank:0] loss: 0.119, average forward (0.009265) and backward (0.021002) time: 0.035806, iotime: 0.005290 
2022-08-04 10:15:22,324 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048799, Speed: 655.757126 images/s
2022-08-04 10:15:23,418 [dl_trainer.py:634] INFO train iter: 12544, num_batches_per_epoch: 196
2022-08-04 10:15:23,418 [dl_trainer.py:635] INFO Epoch 64, avg train acc: 93.638393, lr: 0.100000, avg loss: 0.172195
2022-08-04 10:15:26,039 [dl_trainer.py:822] INFO Epoch 64, lr: 0.100000, val loss: 0.471126, val top-1 acc: 86.411741, top-5 acc: 99.420927
2022-08-04 10:15:26,801 [dl_trainer.py:731] WARNING [ 64][12560/  196][rank:0] loss: 0.062, average forward (0.010035) and backward (0.020897) time: 0.098864, iotime: 0.001577 
2022-08-04 10:15:26,867 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113553, Speed: 281.805847 images/s
2022-08-04 10:15:28,727 [dl_trainer.py:731] WARNING [ 64][12600/  196][rank:0] loss: 0.459, average forward (0.010777) and backward (0.017483) time: 0.030177, iotime: 0.001659 
2022-08-04 10:15:28,805 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048457, Speed: 660.382600 images/s
2022-08-04 10:15:30,607 [dl_trainer.py:731] WARNING [ 64][12640/  196][rank:0] loss: 0.190, average forward (0.010319) and backward (0.017617) time: 0.029657, iotime: 0.001477 
2022-08-04 10:15:30,686 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047015, Speed: 680.627291 images/s
2022-08-04 10:15:32,317 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:15:32,318 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:15:32,711 [dl_trainer.py:731] WARNING [ 64][12680/  196][rank:0] loss: 0.298, average forward (0.010566) and backward (0.020792) time: 0.036916, iotime: 0.005282 
2022-08-04 10:15:34,460 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050306, Speed: 636.109528 images/s
2022-08-04 10:15:34,652 [dl_trainer.py:731] WARNING [ 64][12720/  196][rank:0] loss: 0.118, average forward (0.010153) and backward (0.021901) time: 0.033805, iotime: 0.001497 
2022-08-04 10:15:35,607 [dl_trainer.py:634] INFO train iter: 12740, num_batches_per_epoch: 196
2022-08-04 10:15:35,608 [dl_trainer.py:635] INFO Epoch 65, avg train acc: 93.287628, lr: 0.100000, avg loss: 0.190717
2022-08-04 10:15:38,248 [dl_trainer.py:822] INFO Epoch 65, lr: 0.100000, val loss: 0.425013, val top-1 acc: 87.280351, top-5 acc: 99.530751
2022-08-04 10:15:38,991 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113255, Speed: 282.547354 images/s
2022-08-04 10:15:39,169 [dl_trainer.py:731] WARNING [ 65][12760/  196][rank:0] loss: 0.377, average forward (0.011828) and backward (0.020941) time: 0.100745, iotime: 0.001646 
2022-08-04 10:15:40,866 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046869, Speed: 682.751226 images/s
2022-08-04 10:15:41,055 [dl_trainer.py:731] WARNING [ 65][12800/  196][rank:0] loss: 0.041, average forward (0.012591) and backward (0.022315) time: 0.036967, iotime: 0.001788 
2022-08-04 10:15:42,728 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046516, Speed: 687.933641 images/s
2022-08-04 10:15:42,909 [dl_trainer.py:731] WARNING [ 65][12840/  196][rank:0] loss: 0.266, average forward (0.010443) and backward (0.021784) time: 0.033996, iotime: 0.001524 
2022-08-04 10:15:44,352 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:15:44,353 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:15:44,935 [dl_trainer.py:731] WARNING [ 65][12880/  196][rank:0] loss: 0.287, average forward (0.010334) and backward (0.019641) time: 0.035401, iotime: 0.005158 
2022-08-04 10:15:46,391 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048832, Speed: 655.307354 images/s
2022-08-04 10:15:46,800 [dl_trainer.py:731] WARNING [ 65][12920/  196][rank:0] loss: 0.175, average forward (0.010714) and backward (0.020157) time: 0.032655, iotime: 0.001541 
2022-08-04 10:15:47,568 [dl_trainer.py:634] INFO train iter: 12936, num_batches_per_epoch: 196
2022-08-04 10:15:47,569 [dl_trainer.py:635] INFO Epoch 66, avg train acc: 93.654337, lr: 0.100000, avg loss: 0.182267
2022-08-04 10:15:50,200 [dl_trainer.py:822] INFO Epoch 66, lr: 0.100000, val loss: 0.480847, val top-1 acc: 86.441693, top-5 acc: 99.450879
2022-08-04 10:15:50,917 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113133, Speed: 282.853146 images/s
2022-08-04 10:15:51,339 [dl_trainer.py:731] WARNING [ 66][12960/  196][rank:0] loss: 0.101, average forward (0.009716) and backward (0.021818) time: 0.099492, iotime: 0.001437 
2022-08-04 10:15:52,822 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047612, Speed: 672.101749 images/s
2022-08-04 10:15:53,238 [dl_trainer.py:731] WARNING [ 66][13000/  196][rank:0] loss: 0.137, average forward (0.011222) and backward (0.021646) time: 0.034681, iotime: 0.001547 
2022-08-04 10:15:54,730 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047678, Speed: 671.175306 images/s
2022-08-04 10:15:55,138 [dl_trainer.py:731] WARNING [ 66][13040/  196][rank:0] loss: 0.100, average forward (0.011494) and backward (0.021653) time: 0.034998, iotime: 0.001575 
2022-08-04 10:15:56,293 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:15:56,293 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:15:57,103 [dl_trainer.py:731] WARNING [ 66][13080/  196][rank:0] loss: 0.172, average forward (0.010290) and backward (0.018542) time: 0.034507, iotime: 0.005422 
2022-08-04 10:15:58,312 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047742, Speed: 670.267205 images/s
2022-08-04 10:15:58,966 [dl_trainer.py:731] WARNING [ 66][13120/  196][rank:0] loss: 0.123, average forward (0.011286) and backward (0.021593) time: 0.034754, iotime: 0.001612 
2022-08-04 10:15:59,540 [dl_trainer.py:634] INFO train iter: 13132, num_batches_per_epoch: 196
2022-08-04 10:15:59,540 [dl_trainer.py:635] INFO Epoch 67, avg train acc: 92.825255, lr: 0.100000, avg loss: 0.200194
2022-08-04 10:16:02,084 [dl_trainer.py:822] INFO Epoch 67, lr: 0.100000, val loss: 0.408641, val top-1 acc: 87.210463, top-5 acc: 99.450879
2022-08-04 10:16:02,790 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111932, Speed: 285.888841 images/s
2022-08-04 10:16:03,456 [dl_trainer.py:731] WARNING [ 67][13160/  196][rank:0] loss: 0.052, average forward (0.010294) and backward (0.020790) time: 0.096506, iotime: 0.001502 
2022-08-04 10:16:04,675 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047134, Speed: 678.908735 images/s
2022-08-04 10:16:05,308 [dl_trainer.py:731] WARNING [ 67][13200/  196][rank:0] loss: 0.067, average forward (0.009987) and backward (0.020205) time: 0.031898, iotime: 0.001464 
2022-08-04 10:16:06,555 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046978, Speed: 681.170992 images/s
2022-08-04 10:16:07,206 [dl_trainer.py:731] WARNING [ 67][13240/  196][rank:0] loss: 0.188, average forward (0.009335) and backward (0.019704) time: 0.030746, iotime: 0.001468 
2022-08-04 10:16:08,173 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:16:08,173 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:16:09,240 [dl_trainer.py:731] WARNING [ 67][13280/  196][rank:0] loss: 0.106, average forward (0.009491) and backward (0.018708) time: 0.033619, iotime: 0.005159 
2022-08-04 10:16:10,209 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048692, Speed: 657.191665 images/s
2022-08-04 10:16:11,136 [dl_trainer.py:731] WARNING [ 67][13320/  196][rank:0] loss: 0.128, average forward (0.011315) and backward (0.023042) time: 0.036239, iotime: 0.001608 
2022-08-04 10:16:11,513 [dl_trainer.py:634] INFO train iter: 13328, num_batches_per_epoch: 196
2022-08-04 10:16:11,514 [dl_trainer.py:635] INFO Epoch 68, avg train acc: 93.415179, lr: 0.100000, avg loss: 0.200300
2022-08-04 10:16:14,130 [dl_trainer.py:822] INFO Epoch 68, lr: 0.100000, val loss: 0.454390, val top-1 acc: 86.301917, top-5 acc: 99.450879
2022-08-04 10:16:14,755 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113656, Speed: 281.551519 images/s
2022-08-04 10:16:15,686 [dl_trainer.py:731] WARNING [ 68][13360/  196][rank:0] loss: 0.162, average forward (0.011140) and backward (0.021693) time: 0.100906, iotime: 0.001569 
2022-08-04 10:16:16,653 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047436, Speed: 674.592728 images/s
2022-08-04 10:16:17,543 [dl_trainer.py:731] WARNING [ 68][13400/  196][rank:0] loss: 0.053, average forward (0.009321) and backward (0.015357) time: 0.026341, iotime: 0.001416 
2022-08-04 10:16:18,590 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048415, Speed: 660.955124 images/s
2022-08-04 10:16:19,460 [dl_trainer.py:731] WARNING [ 68][13440/  196][rank:0] loss: 0.248, average forward (0.010032) and backward (0.020774) time: 0.032540, iotime: 0.001465 
2022-08-04 10:16:20,178 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:16:20,178 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:16:21,519 [dl_trainer.py:731] WARNING [ 68][13480/  196][rank:0] loss: 0.223, average forward (0.009125) and backward (0.018619) time: 0.033193, iotime: 0.005196 
2022-08-04 10:16:22,306 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049527, Speed: 646.111312 images/s
2022-08-04 10:16:23,358 [dl_trainer.py:731] WARNING [ 68][13520/  196][rank:0] loss: 0.265, average forward (0.009053) and backward (0.019871) time: 0.030544, iotime: 0.001387 
2022-08-04 10:16:23,564 [dl_trainer.py:634] INFO train iter: 13524, num_batches_per_epoch: 196
2022-08-04 10:16:23,564 [dl_trainer.py:635] INFO Epoch 69, avg train acc: 92.904974, lr: 0.100000, avg loss: 0.200605
2022-08-04 10:16:26,179 [dl_trainer.py:822] INFO Epoch 69, lr: 0.100000, val loss: 0.452547, val top-1 acc: 87.020767, top-5 acc: 99.430911
2022-08-04 10:16:26,749 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111043, Speed: 288.175523 images/s
2022-08-04 10:16:27,822 [dl_trainer.py:731] WARNING [ 69][13560/  196][rank:0] loss: 0.216, average forward (0.010937) and backward (0.019128) time: 0.097332, iotime: 0.001572 
2022-08-04 10:16:28,627 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046929, Speed: 681.888388 images/s
2022-08-04 10:16:29,730 [dl_trainer.py:731] WARNING [ 69][13600/  196][rank:0] loss: 0.045, average forward (0.010879) and backward (0.019552) time: 0.032256, iotime: 0.001572 
2022-08-04 10:16:30,473 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046155, Speed: 693.320750 images/s
2022-08-04 10:16:31,570 [dl_trainer.py:731] WARNING [ 69][13640/  196][rank:0] loss: 0.247, average forward (0.010082) and backward (0.020359) time: 0.032263, iotime: 0.001574 
2022-08-04 10:16:32,062 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:16:32,062 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:16:33,641 [dl_trainer.py:731] WARNING [ 69][13680/  196][rank:0] loss: 0.103, average forward (0.010281) and backward (0.020999) time: 0.036649, iotime: 0.005113 
2022-08-04 10:16:34,132 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048770, Speed: 656.147077 images/s
2022-08-04 10:16:35,478 [dl_trainer.py:731] WARNING [ 69][13720/  196][rank:0] loss: 0.159, average forward (0.010594) and backward (0.020625) time: 0.033041, iotime: 0.001560 
2022-08-04 10:16:35,492 [dl_trainer.py:634] INFO train iter: 13720, num_batches_per_epoch: 196
2022-08-04 10:16:35,492 [dl_trainer.py:635] INFO Epoch 70, avg train acc: 92.904974, lr: 0.100000, avg loss: 0.203931
2022-08-04 10:16:38,138 [dl_trainer.py:822] INFO Epoch 70, lr: 0.100000, val loss: 0.449678, val top-1 acc: 87.440096, top-5 acc: 99.261182
2022-08-04 10:16:38,683 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113754, Speed: 281.308440 images/s
2022-08-04 10:16:40,042 [dl_trainer.py:731] WARNING [ 70][13760/  196][rank:0] loss: 0.234, average forward (0.010371) and backward (0.020797) time: 0.099572, iotime: 0.001515 
2022-08-04 10:16:40,577 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047335, Speed: 676.025655 images/s
2022-08-04 10:16:41,928 [dl_trainer.py:731] WARNING [ 70][13800/  196][rank:0] loss: 0.103, average forward (0.009825) and backward (0.018718) time: 0.030263, iotime: 0.001468 
2022-08-04 10:16:42,445 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046702, Speed: 685.194657 images/s
2022-08-04 10:16:43,767 [dl_trainer.py:731] WARNING [ 70][13840/  196][rank:0] loss: 0.207, average forward (0.010185) and backward (0.018726) time: 0.030655, iotime: 0.001490 
2022-08-04 10:16:44,010 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:16:44,010 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:16:45,797 [dl_trainer.py:731] WARNING [ 70][13880/  196][rank:0] loss: 0.079, average forward (0.009785) and backward (0.021151) time: 0.036175, iotime: 0.004990 
2022-08-04 10:16:46,078 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048417, Speed: 660.923461 images/s
2022-08-04 10:16:47,486 [dl_trainer.py:634] INFO train iter: 13916, num_batches_per_epoch: 196
2022-08-04 10:16:47,486 [dl_trainer.py:635] INFO Epoch 71, avg train acc: 93.574617, lr: 0.100000, avg loss: 0.177449
2022-08-04 10:16:50,067 [dl_trainer.py:822] INFO Epoch 71, lr: 0.100000, val loss: 0.447769, val top-1 acc: 87.430112, top-5 acc: 99.450879
2022-08-04 10:16:50,239 [dl_trainer.py:731] WARNING [ 71][13920/  196][rank:0] loss: 0.207, average forward (0.009782) and backward (0.019658) time: 0.095730, iotime: 0.001466 
2022-08-04 10:16:50,540 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111541, Speed: 286.889555 images/s
2022-08-04 10:16:52,126 [dl_trainer.py:731] WARNING [ 71][13960/  196][rank:0] loss: 0.140, average forward (0.010235) and backward (0.019615) time: 0.031648, iotime: 0.001555 
2022-08-04 10:16:52,408 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046700, Speed: 685.228939 images/s
2022-08-04 10:16:53,983 [dl_trainer.py:731] WARNING [ 71][14000/  196][rank:0] loss: 0.336, average forward (0.008505) and backward (0.019362) time: 0.029453, iotime: 0.001366 
2022-08-04 10:16:54,278 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046740, Speed: 684.639714 images/s
2022-08-04 10:16:55,877 [dl_trainer.py:731] WARNING [ 71][14040/  196][rank:0] loss: 0.698, average forward (0.010341) and backward (0.020846) time: 0.032982, iotime: 0.001538 
2022-08-04 10:16:55,888 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:16:55,889 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:16:57,887 [dl_trainer.py:731] WARNING [ 71][14080/  196][rank:0] loss: 0.122, average forward (0.009697) and backward (0.021319) time: 0.036505, iotime: 0.005237 
2022-08-04 10:16:57,941 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048822, Speed: 655.437663 images/s
2022-08-04 10:16:59,325 [dl_trainer.py:634] INFO train iter: 14112, num_batches_per_epoch: 196
2022-08-04 10:16:59,326 [dl_trainer.py:635] INFO Epoch 72, avg train acc: 93.718112, lr: 0.100000, avg loss: 0.172038
2022-08-04 10:17:01,934 [dl_trainer.py:822] INFO Epoch 72, lr: 0.100000, val loss: 0.490662, val top-1 acc: 86.311901, top-5 acc: 99.420927
2022-08-04 10:17:02,331 [dl_trainer.py:731] WARNING [ 72][14120/  196][rank:0] loss: 0.058, average forward (0.009943) and backward (0.021060) time: 0.098502, iotime: 0.001536 
2022-08-04 10:17:02,391 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111231, Speed: 287.690494 images/s
2022-08-04 10:17:04,175 [dl_trainer.py:731] WARNING [ 72][14160/  196][rank:0] loss: 0.124, average forward (0.010424) and backward (0.020724) time: 0.032908, iotime: 0.001512 
2022-08-04 10:17:04,252 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046526, Speed: 687.780999 images/s
2022-08-04 10:17:06,127 [dl_trainer.py:731] WARNING [ 72][14200/  196][rank:0] loss: 0.345, average forward (0.008885) and backward (0.023121) time: 0.033645, iotime: 0.001414 
2022-08-04 10:17:06,183 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048264, Speed: 663.024358 images/s
2022-08-04 10:17:07,750 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:17:07,750 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:17:08,128 [dl_trainer.py:731] WARNING [ 72][14240/  196][rank:0] loss: 0.262, average forward (0.010442) and backward (0.020054) time: 0.035928, iotime: 0.005164 
2022-08-04 10:17:09,859 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048997, Speed: 653.107417 images/s
2022-08-04 10:17:10,025 [dl_trainer.py:731] WARNING [ 72][14280/  196][rank:0] loss: 0.113, average forward (0.009936) and backward (0.018124) time: 0.029818, iotime: 0.001501 
2022-08-04 10:17:11,375 [dl_trainer.py:634] INFO train iter: 14308, num_batches_per_epoch: 196
2022-08-04 10:17:11,376 [dl_trainer.py:635] INFO Epoch 73, avg train acc: 93.207908, lr: 0.100000, avg loss: 0.188851
2022-08-04 10:17:14,016 [dl_trainer.py:822] INFO Epoch 73, lr: 0.100000, val loss: 0.477076, val top-1 acc: 86.801118, top-5 acc: 99.490815
2022-08-04 10:17:14,395 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113371, Speed: 282.260060 images/s
2022-08-04 10:17:14,579 [dl_trainer.py:731] WARNING [ 73][14320/  196][rank:0] loss: 0.239, average forward (0.009882) and backward (0.021056) time: 0.098740, iotime: 0.001473 
2022-08-04 10:17:16,326 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048285, Speed: 662.728077 images/s
2022-08-04 10:17:16,492 [dl_trainer.py:731] WARNING [ 73][14360/  196][rank:0] loss: 0.082, average forward (0.010184) and backward (0.020710) time: 0.032609, iotime: 0.001460 
2022-08-04 10:17:18,220 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047336, Speed: 676.024804 images/s
2022-08-04 10:17:18,396 [dl_trainer.py:731] WARNING [ 73][14400/  196][rank:0] loss: 0.117, average forward (0.009857) and backward (0.018794) time: 0.030410, iotime: 0.001500 
2022-08-04 10:17:19,816 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:17:19,816 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:17:20,440 [dl_trainer.py:731] WARNING [ 73][14440/  196][rank:0] loss: 0.077, average forward (0.010235) and backward (0.018707) time: 0.034336, iotime: 0.005124 
2022-08-04 10:17:21,888 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048894, Speed: 654.480457 images/s
2022-08-04 10:17:22,308 [dl_trainer.py:731] WARNING [ 73][14480/  196][rank:0] loss: 0.530, average forward (0.010802) and backward (0.020853) time: 0.033466, iotime: 0.001558 
2022-08-04 10:17:23,489 [dl_trainer.py:634] INFO train iter: 14504, num_batches_per_epoch: 196
2022-08-04 10:17:23,489 [dl_trainer.py:635] INFO Epoch 74, avg train acc: 93.415179, lr: 0.100000, avg loss: 0.190465
2022-08-04 10:17:26,116 [dl_trainer.py:822] INFO Epoch 74, lr: 0.100000, val loss: 0.425167, val top-1 acc: 87.579872, top-5 acc: 99.540735
2022-08-04 10:17:26,459 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114261, Speed: 280.061290 images/s
2022-08-04 10:17:26,891 [dl_trainer.py:731] WARNING [ 74][14520/  196][rank:0] loss: 0.086, average forward (0.009811) and backward (0.021055) time: 0.098714, iotime: 0.001447 
2022-08-04 10:17:28,340 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047020, Speed: 680.558958 images/s
2022-08-04 10:17:28,762 [dl_trainer.py:731] WARNING [ 74][14560/  196][rank:0] loss: 0.113, average forward (0.010011) and backward (0.022054) time: 0.033775, iotime: 0.001473 
2022-08-04 10:17:30,259 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047944, Speed: 667.445638 images/s
2022-08-04 10:17:30,669 [dl_trainer.py:731] WARNING [ 74][14600/  196][rank:0] loss: 0.343, average forward (0.010476) and backward (0.022341) time: 0.034616, iotime: 0.001548 
2022-08-04 10:17:31,853 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:17:31,853 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:17:32,690 [dl_trainer.py:731] WARNING [ 74][14640/  196][rank:0] loss: 0.065, average forward (0.010357) and backward (0.020510) time: 0.036248, iotime: 0.005118 
2022-08-04 10:17:33,900 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048541, Speed: 659.233253 images/s
2022-08-04 10:17:34,532 [dl_trainer.py:731] WARNING [ 74][14680/  196][rank:0] loss: 0.375, average forward (0.009145) and backward (0.019555) time: 0.030323, iotime: 0.001384 
2022-08-04 10:17:35,469 [dl_trainer.py:634] INFO train iter: 14700, num_batches_per_epoch: 196
2022-08-04 10:17:35,470 [dl_trainer.py:635] INFO Epoch 75, avg train acc: 93.542730, lr: 0.100000, avg loss: 0.185061
2022-08-04 10:17:38,094 [dl_trainer.py:822] INFO Epoch 75, lr: 0.100000, val loss: 0.509829, val top-1 acc: 85.573083, top-5 acc: 99.550719
2022-08-04 10:17:38,377 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111897, Speed: 285.976451 images/s
2022-08-04 10:17:39,031 [dl_trainer.py:731] WARNING [ 75][14720/  196][rank:0] loss: 0.110, average forward (0.009962) and backward (0.020761) time: 0.098151, iotime: 0.001489 
2022-08-04 10:17:40,246 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046722, Speed: 684.906194 images/s
2022-08-04 10:17:40,894 [dl_trainer.py:731] WARNING [ 75][14760/  196][rank:0] loss: 0.158, average forward (0.012319) and backward (0.021613) time: 0.035894, iotime: 0.001694 
2022-08-04 10:17:42,135 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047230, Speed: 677.539579 images/s
2022-08-04 10:17:42,785 [dl_trainer.py:731] WARNING [ 75][14800/  196][rank:0] loss: 0.259, average forward (0.010392) and backward (0.020603) time: 0.032744, iotime: 0.001499 
2022-08-04 10:17:43,788 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:17:43,789 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:17:44,878 [dl_trainer.py:731] WARNING [ 75][14840/  196][rank:0] loss: 0.106, average forward (0.009503) and backward (0.022004) time: 0.036659, iotime: 0.004893 
2022-08-04 10:17:45,916 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050384, Speed: 635.121899 images/s
2022-08-04 10:17:46,815 [dl_trainer.py:731] WARNING [ 75][14880/  196][rank:0] loss: 0.069, average forward (0.010024) and backward (0.022283) time: 0.034074, iotime: 0.001502 
2022-08-04 10:17:47,601 [dl_trainer.py:634] INFO train iter: 14896, num_batches_per_epoch: 196
2022-08-04 10:17:47,601 [dl_trainer.py:635] INFO Epoch 76, avg train acc: 94.228316, lr: 0.100000, avg loss: 0.168267
2022-08-04 10:17:50,263 [dl_trainer.py:822] INFO Epoch 76, lr: 0.100000, val loss: 0.421728, val top-1 acc: 88.009185, top-5 acc: 99.470847
2022-08-04 10:17:50,533 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115405, Speed: 277.284277 images/s
2022-08-04 10:17:51,413 [dl_trainer.py:731] WARNING [ 76][14920/  196][rank:0] loss: 0.288, average forward (0.009702) and backward (0.020828) time: 0.099545, iotime: 0.001493 
2022-08-04 10:17:52,440 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047685, Speed: 671.073709 images/s
2022-08-04 10:17:53,302 [dl_trainer.py:731] WARNING [ 76][14960/  196][rank:0] loss: 0.269, average forward (0.009694) and backward (0.019882) time: 0.031384, iotime: 0.001568 
2022-08-04 10:17:54,344 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047572, Speed: 672.665283 images/s
2022-08-04 10:17:55,217 [dl_trainer.py:731] WARNING [ 76][15000/  196][rank:0] loss: 0.376, average forward (0.011957) and backward (0.021793) time: 0.035692, iotime: 0.001675 
2022-08-04 10:17:55,911 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:17:55,911 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:17:57,215 [dl_trainer.py:731] WARNING [ 76][15040/  196][rank:0] loss: 0.169, average forward (0.010787) and backward (0.019433) time: 0.035554, iotime: 0.005068 
2022-08-04 10:17:58,015 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048938, Speed: 653.889515 images/s
2022-08-04 10:17:59,143 [dl_trainer.py:731] WARNING [ 76][15080/  196][rank:0] loss: 0.130, average forward (0.009160) and backward (0.020585) time: 0.031368, iotime: 0.001384 
2022-08-04 10:17:59,726 [dl_trainer.py:634] INFO train iter: 15092, num_batches_per_epoch: 196
2022-08-04 10:17:59,726 [dl_trainer.py:635] INFO Epoch 77, avg train acc: 93.574617, lr: 0.100000, avg loss: 0.181063
2022-08-04 10:18:02,334 [dl_trainer.py:822] INFO Epoch 77, lr: 0.100000, val loss: 0.460371, val top-1 acc: 86.761182, top-5 acc: 99.500799
2022-08-04 10:18:02,536 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113010, Speed: 283.159988 images/s
2022-08-04 10:18:03,666 [dl_trainer.py:731] WARNING [ 77][15120/  196][rank:0] loss: 0.147, average forward (0.009702) and backward (0.020934) time: 0.097578, iotime: 0.001456 
2022-08-04 10:18:04,460 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048099, Speed: 665.293765 images/s
2022-08-04 10:18:05,600 [dl_trainer.py:731] WARNING [ 77][15160/  196][rank:0] loss: 0.314, average forward (0.009145) and backward (0.018618) time: 0.029393, iotime: 0.001388 
2022-08-04 10:18:06,389 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048213, Speed: 663.719364 images/s
2022-08-04 10:18:07,485 [dl_trainer.py:731] WARNING [ 77][15200/  196][rank:0] loss: 0.066, average forward (0.008732) and backward (0.020766) time: 0.031098, iotime: 0.001376 
2022-08-04 10:18:07,997 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:18:07,997 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:18:09,510 [dl_trainer.py:731] WARNING [ 77][15240/  196][rank:0] loss: 0.124, average forward (0.011476) and backward (0.020240) time: 0.037218, iotime: 0.005219 
2022-08-04 10:18:10,012 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048281, Speed: 662.781033 images/s
2022-08-04 10:18:11,383 [dl_trainer.py:731] WARNING [ 77][15280/  196][rank:0] loss: 0.251, average forward (0.009472) and backward (0.020872) time: 0.032062, iotime: 0.001481 
2022-08-04 10:18:11,780 [dl_trainer.py:634] INFO train iter: 15288, num_batches_per_epoch: 196
2022-08-04 10:18:11,780 [dl_trainer.py:635] INFO Epoch 78, avg train acc: 93.893495, lr: 0.100000, avg loss: 0.170801
2022-08-04 10:18:14,398 [dl_trainer.py:822] INFO Epoch 78, lr: 0.100000, val loss: 0.485290, val top-1 acc: 86.970847, top-5 acc: 99.231230
2022-08-04 10:18:14,561 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113705, Speed: 281.429728 images/s
2022-08-04 10:18:15,924 [dl_trainer.py:731] WARNING [ 78][15320/  196][rank:0] loss: 0.269, average forward (0.009873) and backward (0.021762) time: 0.099369, iotime: 0.001574 
2022-08-04 10:18:16,450 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047220, Speed: 677.683432 images/s
2022-08-04 10:18:17,798 [dl_trainer.py:731] WARNING [ 78][15360/  196][rank:0] loss: 0.086, average forward (0.009506) and backward (0.021218) time: 0.032421, iotime: 0.001455 
2022-08-04 10:18:18,316 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046638, Speed: 686.129631 images/s
2022-08-04 10:18:19,661 [dl_trainer.py:731] WARNING [ 78][15400/  196][rank:0] loss: 0.205, average forward (0.011275) and backward (0.021406) time: 0.034557, iotime: 0.001625 
2022-08-04 10:18:19,908 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:18:19,908 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:18:21,676 [dl_trainer.py:731] WARNING [ 78][15440/  196][rank:0] loss: 0.378, average forward (0.010714) and backward (0.019232) time: 0.035534, iotime: 0.005321 
2022-08-04 10:18:21,978 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048808, Speed: 655.625409 images/s
2022-08-04 10:18:23,567 [dl_trainer.py:731] WARNING [ 78][15480/  196][rank:0] loss: 0.132, average forward (0.009489) and backward (0.019990) time: 0.031107, iotime: 0.001383 
2022-08-04 10:18:23,752 [dl_trainer.py:634] INFO train iter: 15484, num_batches_per_epoch: 196
2022-08-04 10:18:23,753 [dl_trainer.py:635] INFO Epoch 79, avg train acc: 93.686224, lr: 0.100000, avg loss: 0.175144
2022-08-04 10:18:26,382 [dl_trainer.py:822] INFO Epoch 79, lr: 0.100000, val loss: 0.474933, val top-1 acc: 86.970847, top-5 acc: 99.201278
2022-08-04 10:18:26,479 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112533, Speed: 284.359774 images/s
2022-08-04 10:18:28,062 [dl_trainer.py:731] WARNING [ 79][15520/  196][rank:0] loss: 0.203, average forward (0.009914) and backward (0.019467) time: 0.096885, iotime: 0.001452 
2022-08-04 10:18:28,347 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046683, Speed: 685.474610 images/s
2022-08-04 10:18:29,902 [dl_trainer.py:731] WARNING [ 79][15560/  196][rank:0] loss: 0.286, average forward (0.009749) and backward (0.018960) time: 0.030367, iotime: 0.001422 
2022-08-04 10:18:30,185 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045939, Speed: 696.576731 images/s
2022-08-04 10:18:31,758 [dl_trainer.py:731] WARNING [ 79][15600/  196][rank:0] loss: 0.109, average forward (0.008695) and backward (0.019465) time: 0.029802, iotime: 0.001408 
2022-08-04 10:18:31,772 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:18:31,772 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:18:33,780 [dl_trainer.py:731] WARNING [ 79][15640/  196][rank:0] loss: 0.084, average forward (0.010716) and backward (0.021543) time: 0.037797, iotime: 0.005261 
2022-08-04 10:18:33,841 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048726, Speed: 656.736581 images/s
2022-08-04 10:18:35,639 [dl_trainer.py:731] WARNING [ 79][15680/  196][rank:0] loss: 0.251, average forward (0.009964) and backward (0.018686) time: 0.030408, iotime: 0.001499 
2022-08-04 10:18:35,666 [dl_trainer.py:634] INFO train iter: 15680, num_batches_per_epoch: 196
2022-08-04 10:18:35,666 [dl_trainer.py:635] INFO Epoch 80, avg train acc: 93.797832, lr: 0.100000, avg loss: 0.186025
2022-08-04 10:18:38,291 [dl_trainer.py:822] INFO Epoch 80, lr: 0.100000, val loss: 0.441212, val top-1 acc: 87.609824, top-5 acc: 99.450879
2022-08-04 10:18:38,359 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112933, Speed: 283.354331 images/s
2022-08-04 10:18:40,191 [dl_trainer.py:731] WARNING [ 80][15720/  196][rank:0] loss: 0.217, average forward (0.010838) and backward (0.018055) time: 0.096815, iotime: 0.001518 
2022-08-04 10:18:40,264 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047627, Speed: 671.881292 images/s
2022-08-04 10:18:42,094 [dl_trainer.py:731] WARNING [ 80][15760/  196][rank:0] loss: 0.090, average forward (0.009874) and backward (0.020229) time: 0.031789, iotime: 0.001453 
2022-08-04 10:18:42,151 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047151, Speed: 678.666031 images/s
2022-08-04 10:18:43,777 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:18:43,777 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:18:44,159 [dl_trainer.py:731] WARNING [ 80][15800/  196][rank:0] loss: 0.059, average forward (0.009708) and backward (0.019188) time: 0.034306, iotime: 0.005160 
2022-08-04 10:18:45,883 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049749, Speed: 643.225566 images/s
2022-08-04 10:18:46,039 [dl_trainer.py:731] WARNING [ 80][15840/  196][rank:0] loss: 0.121, average forward (0.009898) and backward (0.021295) time: 0.032922, iotime: 0.001495 
2022-08-04 10:18:47,802 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047956, Speed: 667.278480 images/s
2022-08-04 10:18:47,803 [dl_trainer.py:634] INFO train iter: 15876, num_batches_per_epoch: 196
2022-08-04 10:18:47,803 [dl_trainer.py:635] INFO Epoch 81, avg train acc: 93.750000, lr: 0.100000, avg loss: 0.181151
2022-08-04 10:18:50,397 [dl_trainer.py:822] INFO Epoch 81, lr: 0.100000, val loss: 0.455236, val top-1 acc: 86.431709, top-5 acc: 99.520767
2022-08-04 10:18:50,565 [dl_trainer.py:731] WARNING [ 81][15880/  196][rank:0] loss: 0.144, average forward (0.010166) and backward (0.018415) time: 0.095243, iotime: 0.001514 
2022-08-04 10:18:52,281 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111961, Speed: 285.814598 images/s
2022-08-04 10:18:52,460 [dl_trainer.py:731] WARNING [ 81][15920/  196][rank:0] loss: 0.111, average forward (0.010298) and backward (0.019738) time: 0.031787, iotime: 0.001499 
2022-08-04 10:18:54,187 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047631, Speed: 671.836562 images/s
2022-08-04 10:18:54,348 [dl_trainer.py:731] WARNING [ 81][15960/  196][rank:0] loss: 0.104, average forward (0.009706) and backward (0.018357) time: 0.029784, iotime: 0.001467 
2022-08-04 10:18:55,795 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:18:55,795 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:18:56,393 [dl_trainer.py:731] WARNING [ 81][16000/  196][rank:0] loss: 0.152, average forward (0.009344) and backward (0.021315) time: 0.036046, iotime: 0.005136 
2022-08-04 10:18:57,881 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049240, Speed: 649.871631 images/s
2022-08-04 10:18:58,292 [dl_trainer.py:731] WARNING [ 81][16040/  196][rank:0] loss: 0.211, average forward (0.009092) and backward (0.019007) time: 0.029797, iotime: 0.001468 
2022-08-04 10:18:59,810 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048205, Speed: 663.826872 images/s
2022-08-04 10:18:59,863 [dl_trainer.py:634] INFO train iter: 16072, num_batches_per_epoch: 196
2022-08-04 10:18:59,863 [dl_trainer.py:635] INFO Epoch 82, avg train acc: 95.998087, lr: 0.010000, avg loss: 0.114576
2022-08-04 10:19:02,479 [dl_trainer.py:822] INFO Epoch 82, lr: 0.010000, val loss: 0.316769, val top-1 acc: 90.345447, top-5 acc: 99.740415
2022-08-04 10:19:02,853 [dl_trainer.py:731] WARNING [ 82][16080/  196][rank:0] loss: 0.055, average forward (0.009550) and backward (0.019229) time: 0.096366, iotime: 0.001411 
2022-08-04 10:19:04,387 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114419, Speed: 279.674949 images/s
2022-08-04 10:19:04,769 [dl_trainer.py:731] WARNING [ 82][16120/  196][rank:0] loss: 0.049, average forward (0.010167) and backward (0.016976) time: 0.028799, iotime: 0.001407 
2022-08-04 10:19:06,305 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047929, Speed: 667.654393 images/s
2022-08-04 10:19:06,721 [dl_trainer.py:731] WARNING [ 82][16160/  196][rank:0] loss: 0.211, average forward (0.008770) and backward (0.019835) time: 0.030225, iotime: 0.001376 
2022-08-04 10:19:07,960 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:19:07,960 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:19:08,799 [dl_trainer.py:731] WARNING [ 82][16200/  196][rank:0] loss: 0.122, average forward (0.008721) and backward (0.019674) time: 0.033561, iotime: 0.004926 
2022-08-04 10:19:10,076 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050260, Speed: 636.690059 images/s
2022-08-04 10:19:10,731 [dl_trainer.py:731] WARNING [ 82][16240/  196][rank:0] loss: 0.051, average forward (0.009083) and backward (0.021221) time: 0.031962, iotime: 0.001426 
2022-08-04 10:19:11,988 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047788, Speed: 669.629601 images/s
2022-08-04 10:19:12,076 [dl_trainer.py:634] INFO train iter: 16268, num_batches_per_epoch: 196
2022-08-04 10:19:12,076 [dl_trainer.py:635] INFO Epoch 83, avg train acc: 96.859056, lr: 0.010000, avg loss: 0.093629
2022-08-04 10:19:14,742 [dl_trainer.py:822] INFO Epoch 83, lr: 0.010000, val loss: 0.308156, val top-1 acc: 90.804712, top-5 acc: 99.720447
2022-08-04 10:19:15,294 [dl_trainer.py:731] WARNING [ 83][16280/  196][rank:0] loss: 0.200, average forward (0.010273) and backward (0.017864) time: 0.096610, iotime: 0.001487 
2022-08-04 10:19:16,536 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113682, Speed: 281.487806 images/s
2022-08-04 10:19:17,164 [dl_trainer.py:731] WARNING [ 83][16320/  196][rank:0] loss: 0.024, average forward (0.009190) and backward (0.018508) time: 0.029396, iotime: 0.001463 
2022-08-04 10:19:18,398 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046558, Speed: 687.308520 images/s
2022-08-04 10:19:19,039 [dl_trainer.py:731] WARNING [ 83][16360/  196][rank:0] loss: 0.092, average forward (0.009671) and backward (0.018695) time: 0.030204, iotime: 0.001561 
2022-08-04 10:19:19,993 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:19:19,993 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:19:21,070 [dl_trainer.py:731] WARNING [ 83][16400/  196][rank:0] loss: 0.078, average forward (0.010291) and backward (0.021290) time: 0.037284, iotime: 0.005438 
2022-08-04 10:19:22,086 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049151, Speed: 651.058352 images/s
2022-08-04 10:19:22,948 [dl_trainer.py:731] WARNING [ 83][16440/  196][rank:0] loss: 0.087, average forward (0.010876) and backward (0.021405) time: 0.034170, iotime: 0.001633 
2022-08-04 10:19:23,962 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046863, Speed: 682.846836 images/s
2022-08-04 10:19:24,114 [dl_trainer.py:634] INFO train iter: 16464, num_batches_per_epoch: 196
2022-08-04 10:19:24,114 [dl_trainer.py:635] INFO Epoch 84, avg train acc: 96.890944, lr: 0.010000, avg loss: 0.097039
2022-08-04 10:19:27,000 [dl_trainer.py:822] INFO Epoch 84, lr: 0.010000, val loss: 0.306333, val top-1 acc: 91.084265, top-5 acc: 99.730431
2022-08-04 10:19:27,802 [dl_trainer.py:731] WARNING [ 84][16480/  196][rank:0] loss: 0.282, average forward (0.010968) and backward (0.021492) time: 0.107080, iotime: 0.001587 
2022-08-04 10:19:28,779 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.120404, Speed: 265.771916 images/s
2022-08-04 10:19:29,666 [dl_trainer.py:731] WARNING [ 84][16520/  196][rank:0] loss: 0.064, average forward (0.010126) and backward (0.021039) time: 0.032883, iotime: 0.001472 
2022-08-04 10:19:30,685 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047654, Speed: 671.510432 images/s
2022-08-04 10:19:31,571 [dl_trainer.py:731] WARNING [ 84][16560/  196][rank:0] loss: 0.249, average forward (0.009220) and backward (0.021641) time: 0.032514, iotime: 0.001420 
2022-08-04 10:19:32,290 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:19:32,290 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:19:33,629 [dl_trainer.py:731] WARNING [ 84][16600/  196][rank:0] loss: 0.110, average forward (0.009508) and backward (0.022279) time: 0.037195, iotime: 0.005156 
2022-08-04 10:19:34,419 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049760, Speed: 643.083428 images/s
2022-08-04 10:19:35,504 [dl_trainer.py:731] WARNING [ 84][16640/  196][rank:0] loss: 0.021, average forward (0.009115) and backward (0.019153) time: 0.029894, iotime: 0.001389 
2022-08-04 10:19:36,266 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046169, Speed: 693.106198 images/s
2022-08-04 10:19:36,460 [dl_trainer.py:634] INFO train iter: 16660, num_batches_per_epoch: 196
2022-08-04 10:19:36,460 [dl_trainer.py:635] INFO Epoch 85, avg train acc: 97.193878, lr: 0.010000, avg loss: 0.084602
2022-08-04 10:19:39,064 [dl_trainer.py:822] INFO Epoch 85, lr: 0.010000, val loss: 0.318452, val top-1 acc: 90.974441, top-5 acc: 99.680511
2022-08-04 10:19:39,970 [dl_trainer.py:731] WARNING [ 85][16680/  196][rank:0] loss: 0.043, average forward (0.009396) and backward (0.019594) time: 0.095875, iotime: 0.001491 
2022-08-04 10:19:40,752 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112148, Speed: 285.338464 images/s
2022-08-04 10:19:41,928 [dl_trainer.py:731] WARNING [ 85][16720/  196][rank:0] loss: 0.147, average forward (0.009754) and backward (0.019392) time: 0.030822, iotime: 0.001428 
2022-08-04 10:19:42,665 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047805, Speed: 669.382050 images/s
2022-08-04 10:19:43,768 [dl_trainer.py:731] WARNING [ 85][16760/  196][rank:0] loss: 0.102, average forward (0.010371) and backward (0.019426) time: 0.031629, iotime: 0.001578 
2022-08-04 10:19:44,277 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:19:44,277 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:19:45,828 [dl_trainer.py:731] WARNING [ 85][16800/  196][rank:0] loss: 0.063, average forward (0.009051) and backward (0.021010) time: 0.035594, iotime: 0.005282 
2022-08-04 10:19:46,357 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049206, Speed: 650.332624 images/s
2022-08-04 10:19:47,721 [dl_trainer.py:731] WARNING [ 85][16840/  196][rank:0] loss: 0.097, average forward (0.009369) and backward (0.021837) time: 0.032846, iotime: 0.001403 
2022-08-04 10:19:48,238 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046999, Speed: 680.866651 images/s
2022-08-04 10:19:48,455 [dl_trainer.py:634] INFO train iter: 16856, num_batches_per_epoch: 196
2022-08-04 10:19:48,455 [dl_trainer.py:635] INFO Epoch 86, avg train acc: 97.353316, lr: 0.010000, avg loss: 0.077486
2022-08-04 10:19:51,059 [dl_trainer.py:822] INFO Epoch 86, lr: 0.010000, val loss: 0.321124, val top-1 acc: 90.784744, top-5 acc: 99.710463
2022-08-04 10:19:52,206 [dl_trainer.py:731] WARNING [ 86][16880/  196][rank:0] loss: 0.144, average forward (0.010298) and backward (0.019317) time: 0.096962, iotime: 0.001507 
2022-08-04 10:19:52,729 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112274, Speed: 285.016565 images/s
2022-08-04 10:19:54,032 [dl_trainer.py:731] WARNING [ 86][16920/  196][rank:0] loss: 0.045, average forward (0.008797) and backward (0.018077) time: 0.028473, iotime: 0.001369 
2022-08-04 10:19:54,570 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046017, Speed: 695.394774 images/s
2022-08-04 10:19:55,901 [dl_trainer.py:731] WARNING [ 86][16960/  196][rank:0] loss: 0.021, average forward (0.010084) and backward (0.021209) time: 0.033038, iotime: 0.001492 
2022-08-04 10:19:56,156 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:19:56,156 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:19:57,958 [dl_trainer.py:731] WARNING [ 86][17000/  196][rank:0] loss: 0.045, average forward (0.010438) and backward (0.020799) time: 0.036776, iotime: 0.005279 
2022-08-04 10:19:58,282 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049463, Speed: 646.943958 images/s
2022-08-04 10:19:59,845 [dl_trainer.py:731] WARNING [ 86][17040/  196][rank:0] loss: 0.161, average forward (0.009896) and backward (0.017990) time: 0.029550, iotime: 0.001415 
2022-08-04 10:20:00,147 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046603, Speed: 686.651511 images/s
2022-08-04 10:20:00,439 [dl_trainer.py:634] INFO train iter: 17052, num_batches_per_epoch: 196
2022-08-04 10:20:00,439 [dl_trainer.py:635] INFO Epoch 87, avg train acc: 97.528699, lr: 0.010000, avg loss: 0.077763
2022-08-04 10:20:03,142 [dl_trainer.py:822] INFO Epoch 87, lr: 0.010000, val loss: 0.320263, val top-1 acc: 90.744808, top-5 acc: 99.670527
2022-08-04 10:20:04,417 [dl_trainer.py:731] WARNING [ 87][17080/  196][rank:0] loss: 0.012, average forward (0.011632) and backward (0.018235) time: 0.099460, iotime: 0.001661 
2022-08-04 10:20:04,710 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114072, Speed: 280.523699 images/s
2022-08-04 10:20:06,356 [dl_trainer.py:731] WARNING [ 87][17120/  196][rank:0] loss: 0.088, average forward (0.010643) and backward (0.016689) time: 0.029064, iotime: 0.001485 
2022-08-04 10:20:06,661 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048771, Speed: 656.126736 images/s
2022-08-04 10:20:08,268 [dl_trainer.py:731] WARNING [ 87][17160/  196][rank:0] loss: 0.047, average forward (0.008594) and backward (0.017743) time: 0.027945, iotime: 0.001371 
2022-08-04 10:20:08,283 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:20:08,284 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:20:10,347 [dl_trainer.py:731] WARNING [ 87][17200/  196][rank:0] loss: 0.013, average forward (0.009592) and backward (0.022262) time: 0.037429, iotime: 0.005318 
2022-08-04 10:20:10,405 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049906, Speed: 641.210456 images/s
2022-08-04 10:20:12,222 [dl_trainer.py:731] WARNING [ 87][17240/  196][rank:0] loss: 0.173, average forward (0.009667) and backward (0.021466) time: 0.032836, iotime: 0.001463 
2022-08-04 10:20:12,281 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046869, Speed: 682.758693 images/s
2022-08-04 10:20:12,615 [dl_trainer.py:634] INFO train iter: 17248, num_batches_per_epoch: 196
2022-08-04 10:20:12,616 [dl_trainer.py:635] INFO Epoch 88, avg train acc: 97.433036, lr: 0.010000, avg loss: 0.076157
2022-08-04 10:20:15,241 [dl_trainer.py:822] INFO Epoch 88, lr: 0.010000, val loss: 0.314638, val top-1 acc: 90.984425, top-5 acc: 99.720447
2022-08-04 10:20:16,797 [dl_trainer.py:731] WARNING [ 88][17280/  196][rank:0] loss: 0.099, average forward (0.011125) and backward (0.022583) time: 0.101694, iotime: 0.001597 
2022-08-04 10:20:16,857 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114397, Speed: 279.727598 images/s
2022-08-04 10:20:18,730 [dl_trainer.py:731] WARNING [ 88][17320/  196][rank:0] loss: 0.017, average forward (0.009313) and backward (0.021933) time: 0.032935, iotime: 0.001446 
2022-08-04 10:20:18,788 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048263, Speed: 663.027715 images/s
2022-08-04 10:20:20,437 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:20:20,438 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:20:20,813 [dl_trainer.py:731] WARNING [ 88][17360/  196][rank:0] loss: 0.068, average forward (0.010408) and backward (0.022266) time: 0.038368, iotime: 0.005436 
2022-08-04 10:20:22,530 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049874, Speed: 641.611551 images/s
2022-08-04 10:20:22,697 [dl_trainer.py:731] WARNING [ 88][17400/  196][rank:0] loss: 0.024, average forward (0.009179) and backward (0.017598) time: 0.028516, iotime: 0.001486 
2022-08-04 10:20:24,349 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045453, Speed: 704.023474 images/s
2022-08-04 10:20:24,519 [dl_trainer.py:731] WARNING [ 88][17440/  196][rank:0] loss: 0.173, average forward (0.009587) and backward (0.019949) time: 0.031226, iotime: 0.001442 
2022-08-04 10:20:24,715 [dl_trainer.py:634] INFO train iter: 17444, num_batches_per_epoch: 196
2022-08-04 10:20:24,716 [dl_trainer.py:635] INFO Epoch 89, avg train acc: 97.704082, lr: 0.010000, avg loss: 0.070621
2022-08-04 10:20:27,377 [dl_trainer.py:822] INFO Epoch 89, lr: 0.010000, val loss: 0.319719, val top-1 acc: 90.974441, top-5 acc: 99.690495
2022-08-04 10:20:28,908 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113966, Speed: 280.785762 images/s
2022-08-04 10:20:29,066 [dl_trainer.py:731] WARNING [ 89][17480/  196][rank:0] loss: 0.093, average forward (0.011429) and backward (0.021128) time: 0.100953, iotime: 0.001551 
2022-08-04 10:20:30,823 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047851, Speed: 668.745190 images/s
2022-08-04 10:20:30,985 [dl_trainer.py:731] WARNING [ 89][17520/  196][rank:0] loss: 0.020, average forward (0.010544) and backward (0.021966) time: 0.034310, iotime: 0.001544 
2022-08-04 10:20:32,364 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:20:32,364 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:20:32,979 [dl_trainer.py:731] WARNING [ 89][17560/  196][rank:0] loss: 0.017, average forward (0.010888) and backward (0.021271) time: 0.037481, iotime: 0.005058 
2022-08-04 10:20:34,421 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047944, Speed: 667.446075 images/s
2022-08-04 10:20:34,839 [dl_trainer.py:731] WARNING [ 89][17600/  196][rank:0] loss: 0.047, average forward (0.009400) and backward (0.020950) time: 0.031980, iotime: 0.001397 
2022-08-04 10:20:36,322 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047505, Speed: 673.613174 images/s
2022-08-04 10:20:36,733 [dl_trainer.py:731] WARNING [ 89][17640/  196][rank:0] loss: 0.021, average forward (0.010336) and backward (0.020772) time: 0.032866, iotime: 0.001500 
2022-08-04 10:20:36,741 [dl_trainer.py:634] INFO train iter: 17640, num_batches_per_epoch: 196
2022-08-04 10:20:36,741 [dl_trainer.py:635] INFO Epoch 90, avg train acc: 98.118622, lr: 0.010000, avg loss: 0.060010
2022-08-04 10:20:39,392 [dl_trainer.py:822] INFO Epoch 90, lr: 0.010000, val loss: 0.325170, val top-1 acc: 90.914537, top-5 acc: 99.710463
2022-08-04 10:20:40,812 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112236, Speed: 285.114497 images/s
2022-08-04 10:20:41,215 [dl_trainer.py:731] WARNING [ 90][17680/  196][rank:0] loss: 0.062, average forward (0.009122) and backward (0.020247) time: 0.097816, iotime: 0.001423 
2022-08-04 10:20:42,671 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046470, Speed: 688.613068 images/s
2022-08-04 10:20:43,077 [dl_trainer.py:731] WARNING [ 90][17720/  196][rank:0] loss: 0.060, average forward (0.009448) and backward (0.018926) time: 0.029998, iotime: 0.001396 
2022-08-04 10:20:44,312 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:20:44,312 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:20:45,134 [dl_trainer.py:731] WARNING [ 90][17760/  196][rank:0] loss: 0.077, average forward (0.010407) and backward (0.021184) time: 0.037402, iotime: 0.005542 
2022-08-04 10:20:46,354 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049082, Speed: 651.975458 images/s
2022-08-04 10:20:47,014 [dl_trainer.py:731] WARNING [ 90][17800/  196][rank:0] loss: 0.053, average forward (0.010707) and backward (0.021204) time: 0.033714, iotime: 0.001539 
2022-08-04 10:20:48,297 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048567, Speed: 658.885342 images/s
2022-08-04 10:20:48,753 [dl_trainer.py:634] INFO train iter: 17836, num_batches_per_epoch: 196
2022-08-04 10:20:48,753 [dl_trainer.py:635] INFO Epoch 91, avg train acc: 97.544643, lr: 0.010000, avg loss: 0.071881
2022-08-04 10:20:51,383 [dl_trainer.py:822] INFO Epoch 91, lr: 0.010000, val loss: 0.325455, val top-1 acc: 90.954473, top-5 acc: 99.660543
2022-08-04 10:20:51,566 [dl_trainer.py:731] WARNING [ 91][17840/  196][rank:0] loss: 0.022, average forward (0.009751) and backward (0.022044) time: 0.099337, iotime: 0.001465 
2022-08-04 10:20:52,863 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114125, Speed: 280.394433 images/s
2022-08-04 10:20:53,480 [dl_trainer.py:731] WARNING [ 91][17880/  196][rank:0] loss: 0.108, average forward (0.011554) and backward (0.021962) time: 0.035394, iotime: 0.001609 
2022-08-04 10:20:54,732 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046715, Speed: 685.010188 images/s
2022-08-04 10:20:55,394 [dl_trainer.py:731] WARNING [ 91][17920/  196][rank:0] loss: 0.068, average forward (0.010484) and backward (0.020214) time: 0.032496, iotime: 0.001543 
2022-08-04 10:20:56,370 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:20:56,370 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:20:57,466 [dl_trainer.py:731] WARNING [ 91][17960/  196][rank:0] loss: 0.094, average forward (0.009473) and backward (0.022089) time: 0.037028, iotime: 0.005222 
2022-08-04 10:20:58,452 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049589, Speed: 645.305833 images/s
2022-08-04 10:20:59,314 [dl_trainer.py:731] WARNING [ 91][18000/  196][rank:0] loss: 0.170, average forward (0.010590) and backward (0.020171) time: 0.032605, iotime: 0.001583 
2022-08-04 10:21:00,315 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046551, Speed: 687.415532 images/s
2022-08-04 10:21:00,830 [dl_trainer.py:634] INFO train iter: 18032, num_batches_per_epoch: 196
2022-08-04 10:21:00,830 [dl_trainer.py:635] INFO Epoch 92, avg train acc: 97.608418, lr: 0.010000, avg loss: 0.069650
2022-08-04 10:21:03,460 [dl_trainer.py:822] INFO Epoch 92, lr: 0.010000, val loss: 0.323804, val top-1 acc: 91.004393, top-5 acc: 99.630591
2022-08-04 10:21:03,878 [dl_trainer.py:731] WARNING [ 92][18040/  196][rank:0] loss: 0.020, average forward (0.010092) and backward (0.019945) time: 0.098652, iotime: 0.001481 
2022-08-04 10:21:04,906 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114773, Speed: 278.810598 images/s
2022-08-04 10:21:05,767 [dl_trainer.py:731] WARNING [ 92][18080/  196][rank:0] loss: 0.104, average forward (0.008991) and backward (0.021500) time: 0.032160, iotime: 0.001439 
2022-08-04 10:21:06,802 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047389, Speed: 675.264730 images/s
2022-08-04 10:21:07,674 [dl_trainer.py:731] WARNING [ 92][18120/  196][rank:0] loss: 0.036, average forward (0.010040) and backward (0.020354) time: 0.032204, iotime: 0.001549 
2022-08-04 10:21:08,427 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:21:08,427 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:21:09,735 [dl_trainer.py:731] WARNING [ 92][18160/  196][rank:0] loss: 0.033, average forward (0.009533) and backward (0.019330) time: 0.034289, iotime: 0.005165 
2022-08-04 10:21:10,509 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049401, Speed: 647.759662 images/s
2022-08-04 10:21:11,604 [dl_trainer.py:731] WARNING [ 92][18200/  196][rank:0] loss: 0.019, average forward (0.010449) and backward (0.021764) time: 0.034020, iotime: 0.001566 
2022-08-04 10:21:12,383 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046826, Speed: 683.383391 images/s
2022-08-04 10:21:12,948 [dl_trainer.py:634] INFO train iter: 18228, num_batches_per_epoch: 196
2022-08-04 10:21:12,948 [dl_trainer.py:635] INFO Epoch 93, avg train acc: 97.975128, lr: 0.010000, avg loss: 0.061079
2022-08-04 10:21:15,556 [dl_trainer.py:822] INFO Epoch 93, lr: 0.010000, val loss: 0.323961, val top-1 acc: 91.004393, top-5 acc: 99.660543
2022-08-04 10:21:16,110 [dl_trainer.py:731] WARNING [ 93][18240/  196][rank:0] loss: 0.085, average forward (0.011255) and backward (0.021728) time: 0.100118, iotime: 0.001589 
2022-08-04 10:21:16,897 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112821, Speed: 283.636126 images/s
2022-08-04 10:21:18,025 [dl_trainer.py:731] WARNING [ 93][18280/  196][rank:0] loss: 0.023, average forward (0.009253) and backward (0.021010) time: 0.031882, iotime: 0.001383 
2022-08-04 10:21:18,791 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047360, Speed: 675.679630 images/s
2022-08-04 10:21:19,901 [dl_trainer.py:731] WARNING [ 93][18320/  196][rank:0] loss: 0.041, average forward (0.010497) and backward (0.021042) time: 0.033363, iotime: 0.001566 
2022-08-04 10:21:20,376 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:21:20,376 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:21:21,975 [dl_trainer.py:731] WARNING [ 93][18360/  196][rank:0] loss: 0.059, average forward (0.010605) and backward (0.020306) time: 0.036554, iotime: 0.005346 
2022-08-04 10:21:22,498 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049403, Speed: 647.728693 images/s
2022-08-04 10:21:23,833 [dl_trainer.py:731] WARNING [ 93][18400/  196][rank:0] loss: 0.040, average forward (0.009271) and backward (0.018920) time: 0.029883, iotime: 0.001452 
2022-08-04 10:21:24,325 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045654, Speed: 700.931225 images/s
2022-08-04 10:21:24,914 [dl_trainer.py:634] INFO train iter: 18424, num_batches_per_epoch: 196
2022-08-04 10:21:24,914 [dl_trainer.py:635] INFO Epoch 94, avg train acc: 97.831633, lr: 0.010000, avg loss: 0.063665
2022-08-04 10:21:27,575 [dl_trainer.py:822] INFO Epoch 94, lr: 0.010000, val loss: 0.334847, val top-1 acc: 91.104233, top-5 acc: 99.650559
2022-08-04 10:21:28,306 [dl_trainer.py:731] WARNING [ 94][18440/  196][rank:0] loss: 0.057, average forward (0.010492) and backward (0.016296) time: 0.095395, iotime: 0.001494 
2022-08-04 10:21:28,851 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113144, Speed: 282.825758 images/s
2022-08-04 10:21:30,190 [dl_trainer.py:731] WARNING [ 94][18480/  196][rank:0] loss: 0.057, average forward (0.009301) and backward (0.020333) time: 0.031326, iotime: 0.001436 
2022-08-04 10:21:30,738 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047152, Speed: 678.655565 images/s
2022-08-04 10:21:32,095 [dl_trainer.py:731] WARNING [ 94][18520/  196][rank:0] loss: 0.009, average forward (0.009802) and backward (0.021043) time: 0.032599, iotime: 0.001511 
2022-08-04 10:21:32,343 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:21:32,343 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:21:34,123 [dl_trainer.py:731] WARNING [ 94][18560/  196][rank:0] loss: 0.044, average forward (0.009996) and backward (0.021308) time: 0.037051, iotime: 0.005491 
2022-08-04 10:21:34,433 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049255, Speed: 649.677940 images/s
2022-08-04 10:21:36,013 [dl_trainer.py:731] WARNING [ 94][18600/  196][rank:0] loss: 0.052, average forward (0.008837) and backward (0.017508) time: 0.027987, iotime: 0.001413 
2022-08-04 10:21:36,341 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047652, Speed: 671.528659 images/s
2022-08-04 10:21:37,002 [dl_trainer.py:634] INFO train iter: 18620, num_batches_per_epoch: 196
2022-08-04 10:21:37,003 [dl_trainer.py:635] INFO Epoch 95, avg train acc: 97.991071, lr: 0.010000, avg loss: 0.059416
2022-08-04 10:21:39,648 [dl_trainer.py:822] INFO Epoch 95, lr: 0.010000, val loss: 0.335115, val top-1 acc: 90.874601, top-5 acc: 99.680511
2022-08-04 10:21:40,567 [dl_trainer.py:731] WARNING [ 95][18640/  196][rank:0] loss: 0.011, average forward (0.009682) and backward (0.020083) time: 0.097669, iotime: 0.001459 
2022-08-04 10:21:40,859 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112955, Speed: 283.297722 images/s
2022-08-04 10:21:42,461 [dl_trainer.py:731] WARNING [ 95][18680/  196][rank:0] loss: 0.027, average forward (0.011182) and backward (0.021797) time: 0.034831, iotime: 0.001596 
2022-08-04 10:21:42,751 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047282, Speed: 676.785994 images/s
2022-08-04 10:21:44,314 [dl_trainer.py:731] WARNING [ 95][18720/  196][rank:0] loss: 0.033, average forward (0.009495) and backward (0.020903) time: 0.032029, iotime: 0.001397 
2022-08-04 10:21:44,330 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:21:44,330 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:21:46,340 [dl_trainer.py:731] WARNING [ 95][18760/  196][rank:0] loss: 0.033, average forward (0.010414) and backward (0.020900) time: 0.036811, iotime: 0.005222 
2022-08-04 10:21:46,400 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048634, Speed: 657.979839 images/s
2022-08-04 10:21:48,217 [dl_trainer.py:731] WARNING [ 95][18800/  196][rank:0] loss: 0.041, average forward (0.009275) and backward (0.021177) time: 0.032126, iotime: 0.001439 
2022-08-04 10:21:48,280 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046982, Speed: 681.104883 images/s
2022-08-04 10:21:48,994 [dl_trainer.py:634] INFO train iter: 18816, num_batches_per_epoch: 196
2022-08-04 10:21:48,994 [dl_trainer.py:635] INFO Epoch 96, avg train acc: 97.991071, lr: 0.010000, avg loss: 0.061714
2022-08-04 10:21:51,648 [dl_trainer.py:822] INFO Epoch 96, lr: 0.010000, val loss: 0.327283, val top-1 acc: 91.144169, top-5 acc: 99.700479
2022-08-04 10:21:52,797 [dl_trainer.py:731] WARNING [ 96][18840/  196][rank:0] loss: 0.036, average forward (0.011083) and backward (0.021254) time: 0.101084, iotime: 0.001635 
2022-08-04 10:21:52,871 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114779, Speed: 278.797553 images/s
2022-08-04 10:21:54,703 [dl_trainer.py:731] WARNING [ 96][18880/  196][rank:0] loss: 0.037, average forward (0.012698) and backward (0.021468) time: 0.036195, iotime: 0.001748 
2022-08-04 10:21:54,756 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047110, Speed: 679.256702 images/s
2022-08-04 10:21:56,373 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:21:56,373 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:21:56,738 [dl_trainer.py:731] WARNING [ 96][18920/  196][rank:0] loss: 0.129, average forward (0.011621) and backward (0.021854) time: 0.039033, iotime: 0.005267 
2022-08-04 10:21:58,454 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049272, Speed: 649.456667 images/s
2022-08-04 10:21:58,644 [dl_trainer.py:731] WARNING [ 96][18960/  196][rank:0] loss: 0.056, average forward (0.009726) and backward (0.020024) time: 0.031487, iotime: 0.001488 
2022-08-04 10:22:00,391 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048402, Speed: 661.126049 images/s
2022-08-04 10:22:00,553 [dl_trainer.py:731] WARNING [ 96][19000/  196][rank:0] loss: 0.071, average forward (0.011025) and backward (0.021343) time: 0.034231, iotime: 0.001605 
2022-08-04 10:22:01,145 [dl_trainer.py:634] INFO train iter: 19012, num_batches_per_epoch: 196
2022-08-04 10:22:01,145 [dl_trainer.py:635] INFO Epoch 97, avg train acc: 97.975128, lr: 0.010000, avg loss: 0.058042
2022-08-04 10:22:03,750 [dl_trainer.py:822] INFO Epoch 97, lr: 0.010000, val loss: 0.328506, val top-1 acc: 91.034345, top-5 acc: 99.720447
2022-08-04 10:22:04,869 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111948, Speed: 285.846753 images/s
2022-08-04 10:22:05,038 [dl_trainer.py:731] WARNING [ 97][19040/  196][rank:0] loss: 0.036, average forward (0.009519) and backward (0.020804) time: 0.097152, iotime: 0.001428 
2022-08-04 10:22:06,734 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046604, Speed: 686.638513 images/s
2022-08-04 10:22:06,916 [dl_trainer.py:731] WARNING [ 97][19080/  196][rank:0] loss: 0.022, average forward (0.011337) and backward (0.019247) time: 0.032482, iotime: 0.001622 
2022-08-04 10:22:08,334 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:22:08,335 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:22:08,907 [dl_trainer.py:731] WARNING [ 97][19120/  196][rank:0] loss: 0.045, average forward (0.010722) and backward (0.019800) time: 0.036243, iotime: 0.005461 
2022-08-04 10:22:10,398 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048846, Speed: 655.122987 images/s
2022-08-04 10:22:10,790 [dl_trainer.py:731] WARNING [ 97][19160/  196][rank:0] loss: 0.045, average forward (0.010513) and backward (0.018118) time: 0.030426, iotime: 0.001560 
2022-08-04 10:22:12,298 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047472, Speed: 674.076399 images/s
2022-08-04 10:22:12,724 [dl_trainer.py:731] WARNING [ 97][19200/  196][rank:0] loss: 0.036, average forward (0.010497) and backward (0.022420) time: 0.034800, iotime: 0.001627 
2022-08-04 10:22:13,112 [dl_trainer.py:634] INFO train iter: 19208, num_batches_per_epoch: 196
2022-08-04 10:22:13,112 [dl_trainer.py:635] INFO Epoch 98, avg train acc: 98.086735, lr: 0.010000, avg loss: 0.057314
2022-08-04 10:22:15,766 [dl_trainer.py:822] INFO Epoch 98, lr: 0.010000, val loss: 0.332567, val top-1 acc: 91.064297, top-5 acc: 99.680511
2022-08-04 10:22:16,868 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114236, Speed: 280.122781 images/s
2022-08-04 10:22:17,278 [dl_trainer.py:731] WARNING [ 98][19240/  196][rank:0] loss: 0.175, average forward (0.010307) and backward (0.020544) time: 0.099498, iotime: 0.001553 
2022-08-04 10:22:18,739 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046767, Speed: 684.238245 images/s
2022-08-04 10:22:19,164 [dl_trainer.py:731] WARNING [ 98][19280/  196][rank:0] loss: 0.008, average forward (0.011029) and backward (0.021547) time: 0.034486, iotime: 0.001644 
2022-08-04 10:22:20,380 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:22:20,381 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:22:21,203 [dl_trainer.py:731] WARNING [ 98][19320/  196][rank:0] loss: 0.004, average forward (0.011158) and backward (0.020655) time: 0.037623, iotime: 0.005536 
2022-08-04 10:22:22,445 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049391, Speed: 647.886152 images/s
2022-08-04 10:22:23,078 [dl_trainer.py:731] WARNING [ 98][19360/  196][rank:0] loss: 0.009, average forward (0.010268) and backward (0.021310) time: 0.033399, iotime: 0.001563 
2022-08-04 10:22:24,291 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046132, Speed: 693.660975 images/s
2022-08-04 10:22:24,948 [dl_trainer.py:731] WARNING [ 98][19400/  196][rank:0] loss: 0.030, average forward (0.010361) and backward (0.019317) time: 0.031431, iotime: 0.001483 
2022-08-04 10:22:25,141 [dl_trainer.py:634] INFO train iter: 19404, num_batches_per_epoch: 196
2022-08-04 10:22:25,141 [dl_trainer.py:635] INFO Epoch 99, avg train acc: 98.182398, lr: 0.010000, avg loss: 0.053921
2022-08-04 10:22:27,763 [dl_trainer.py:822] INFO Epoch 99, lr: 0.010000, val loss: 0.337248, val top-1 acc: 90.794728, top-5 acc: 99.700479
2022-08-04 10:22:28,819 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113176, Speed: 282.745413 images/s
2022-08-04 10:22:29,438 [dl_trainer.py:731] WARNING [ 99][19440/  196][rank:0] loss: 0.030, average forward (0.010222) and backward (0.021088) time: 0.098772, iotime: 0.001579 
2022-08-04 10:22:30,568 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043721, Speed: 731.920571 images/s
2022-08-04 10:22:31,227 [dl_trainer.py:731] WARNING [ 99][19480/  196][rank:0] loss: 0.054, average forward (0.009786) and backward (0.018581) time: 0.030117, iotime: 0.001523 
2022-08-04 10:22:32,178 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:22:32,178 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:22:33,260 [dl_trainer.py:731] WARNING [ 99][19520/  196][rank:0] loss: 0.009, average forward (0.009870) and backward (0.020726) time: 0.036252, iotime: 0.005402 
2022-08-04 10:22:34,242 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048957, Speed: 653.636120 images/s
2022-08-04 10:22:35,116 [dl_trainer.py:731] WARNING [ 99][19560/  196][rank:0] loss: 0.026, average forward (0.009143) and backward (0.021419) time: 0.032164, iotime: 0.001365 
2022-08-04 10:22:36,163 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048015, Speed: 666.452215 images/s
2022-08-04 10:22:37,027 [dl_trainer.py:731] WARNING [ 99][19600/  196][rank:0] loss: 0.068, average forward (0.010993) and backward (0.022158) time: 0.035047, iotime: 0.001619 
2022-08-04 10:22:37,039 [dl_trainer.py:634] INFO train iter: 19600, num_batches_per_epoch: 196
2022-08-04 10:22:37,039 [dl_trainer.py:635] INFO Epoch 100, avg train acc: 98.166454, lr: 0.010000, avg loss: 0.054343
2022-08-04 10:22:39,651 [dl_trainer.py:822] INFO Epoch 100, lr: 0.010000, val loss: 0.333415, val top-1 acc: 90.954473, top-5 acc: 99.750399
2022-08-04 10:22:40,657 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112317, Speed: 284.907875 images/s
2022-08-04 10:22:41,516 [dl_trainer.py:731] WARNING [100][19640/  196][rank:0] loss: 0.040, average forward (0.009661) and backward (0.021367) time: 0.098482, iotime: 0.001446 
2022-08-04 10:22:42,548 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047269, Speed: 676.981681 images/s
2022-08-04 10:22:43,458 [dl_trainer.py:731] WARNING [100][19680/  196][rank:0] loss: 0.018, average forward (0.011024) and backward (0.021951) time: 0.034799, iotime: 0.001555 
2022-08-04 10:22:44,176 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:22:44,176 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:22:45,472 [dl_trainer.py:731] WARNING [100][19720/  196][rank:0] loss: 0.064, average forward (0.009992) and backward (0.019913) time: 0.035559, iotime: 0.005401 
2022-08-04 10:22:46,254 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049395, Speed: 647.845373 images/s
2022-08-04 10:22:47,376 [dl_trainer.py:731] WARNING [100][19760/  196][rank:0] loss: 0.007, average forward (0.009667) and backward (0.019046) time: 0.030422, iotime: 0.001449 
2022-08-04 10:22:48,195 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048494, Speed: 659.872133 images/s
2022-08-04 10:22:49,179 [dl_trainer.py:634] INFO train iter: 19796, num_batches_per_epoch: 196
2022-08-04 10:22:49,180 [dl_trainer.py:635] INFO Epoch 101, avg train acc: 98.437500, lr: 0.010000, avg loss: 0.049735
2022-08-04 10:22:51,836 [dl_trainer.py:822] INFO Epoch 101, lr: 0.010000, val loss: 0.345677, val top-1 acc: 91.034345, top-5 acc: 99.650559
2022-08-04 10:22:52,011 [dl_trainer.py:731] WARNING [101][19800/  196][rank:0] loss: 0.038, average forward (0.011577) and backward (0.017433) time: 0.097284, iotime: 0.001539 
2022-08-04 10:22:52,791 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114890, Speed: 278.526716 images/s
2022-08-04 10:22:53,926 [dl_trainer.py:731] WARNING [101][19840/  196][rank:0] loss: 0.017, average forward (0.009822) and backward (0.017266) time: 0.028868, iotime: 0.001542 
2022-08-04 10:22:54,713 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048052, Speed: 665.945460 images/s
2022-08-04 10:22:55,845 [dl_trainer.py:731] WARNING [101][19880/  196][rank:0] loss: 0.023, average forward (0.008720) and backward (0.020681) time: 0.031037, iotime: 0.001399 
2022-08-04 10:22:56,343 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:22:56,344 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:22:57,876 [dl_trainer.py:731] WARNING [101][19920/  196][rank:0] loss: 0.002, average forward (0.009319) and backward (0.018854) time: 0.033179, iotime: 0.004753 
2022-08-04 10:22:58,407 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049228, Speed: 650.031477 images/s
2022-08-04 10:22:59,746 [dl_trainer.py:731] WARNING [101][19960/  196][rank:0] loss: 0.127, average forward (0.009986) and backward (0.019264) time: 0.030928, iotime: 0.001444 
2022-08-04 10:23:00,292 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047114, Speed: 679.207204 images/s
2022-08-04 10:23:01,276 [dl_trainer.py:634] INFO train iter: 19992, num_batches_per_epoch: 196
2022-08-04 10:23:01,276 [dl_trainer.py:635] INFO Epoch 102, avg train acc: 98.357781, lr: 0.010000, avg loss: 0.051766
2022-08-04 10:23:03,946 [dl_trainer.py:822] INFO Epoch 102, lr: 0.010000, val loss: 0.340391, val top-1 acc: 90.874601, top-5 acc: 99.650559
2022-08-04 10:23:04,309 [dl_trainer.py:731] WARNING [102][20000/  196][rank:0] loss: 0.034, average forward (0.009461) and backward (0.020146) time: 0.098558, iotime: 0.001455 
2022-08-04 10:23:04,842 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113723, Speed: 281.386229 images/s
2022-08-04 10:23:06,153 [dl_trainer.py:731] WARNING [102][20040/  196][rank:0] loss: 0.060, average forward (0.008740) and backward (0.019818) time: 0.030116, iotime: 0.001330 
2022-08-04 10:23:06,708 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046651, Speed: 685.946148 images/s
2022-08-04 10:23:08,110 [dl_trainer.py:731] WARNING [102][20080/  196][rank:0] loss: 0.010, average forward (0.009443) and backward (0.019521) time: 0.030670, iotime: 0.001457 
2022-08-04 10:23:08,368 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:23:08,368 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:23:10,083 [dl_trainer.py:731] WARNING [102][20120/  196][rank:0] loss: 0.016, average forward (0.009391) and backward (0.019237) time: 0.034006, iotime: 0.005119 
2022-08-04 10:23:10,387 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049034, Speed: 652.605165 images/s
2022-08-04 10:23:11,974 [dl_trainer.py:731] WARNING [102][20160/  196][rank:0] loss: 0.062, average forward (0.009971) and backward (0.018120) time: 0.029809, iotime: 0.001472 
2022-08-04 10:23:12,274 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047148, Speed: 678.709702 images/s
2022-08-04 10:23:13,324 [dl_trainer.py:634] INFO train iter: 20188, num_batches_per_epoch: 196
2022-08-04 10:23:13,325 [dl_trainer.py:635] INFO Epoch 103, avg train acc: 98.038903, lr: 0.010000, avg loss: 0.056637
2022-08-04 10:23:15,948 [dl_trainer.py:822] INFO Epoch 103, lr: 0.010000, val loss: 0.344987, val top-1 acc: 90.934505, top-5 acc: 99.720447
2022-08-04 10:23:16,509 [dl_trainer.py:731] WARNING [103][20200/  196][rank:0] loss: 0.020, average forward (0.009520) and backward (0.019906) time: 0.096740, iotime: 0.001430 
2022-08-04 10:23:16,824 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113750, Speed: 281.318773 images/s
2022-08-04 10:23:18,397 [dl_trainer.py:731] WARNING [103][20240/  196][rank:0] loss: 0.038, average forward (0.010441) and backward (0.019962) time: 0.032252, iotime: 0.001586 
2022-08-04 10:23:18,698 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046823, Speed: 683.421928 images/s
2022-08-04 10:23:20,285 [dl_trainer.py:731] WARNING [103][20280/  196][rank:0] loss: 0.032, average forward (0.008667) and backward (0.021582) time: 0.031849, iotime: 0.001381 
2022-08-04 10:23:20,299 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:23:20,299 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:23:22,336 [dl_trainer.py:731] WARNING [103][20320/  196][rank:0] loss: 0.006, average forward (0.009046) and backward (0.020058) time: 0.034451, iotime: 0.005103 
2022-08-04 10:23:22,402 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049379, Speed: 648.047401 images/s
2022-08-04 10:23:24,206 [dl_trainer.py:731] WARNING [103][20360/  196][rank:0] loss: 0.061, average forward (0.009415) and backward (0.021431) time: 0.032553, iotime: 0.001476 
2022-08-04 10:23:24,271 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046693, Speed: 685.325331 images/s
2022-08-04 10:23:25,376 [dl_trainer.py:634] INFO train iter: 20384, num_batches_per_epoch: 196
2022-08-04 10:23:25,377 [dl_trainer.py:635] INFO Epoch 104, avg train acc: 98.517219, lr: 0.010000, avg loss: 0.045897
2022-08-04 10:23:28,036 [dl_trainer.py:822] INFO Epoch 104, lr: 0.010000, val loss: 0.350066, val top-1 acc: 91.074281, top-5 acc: 99.640575
2022-08-04 10:23:28,803 [dl_trainer.py:731] WARNING [104][20400/  196][rank:0] loss: 0.063, average forward (0.010300) and backward (0.018415) time: 0.097657, iotime: 0.001552 
2022-08-04 10:23:28,876 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115114, Speed: 277.984746 images/s
2022-08-04 10:23:30,682 [dl_trainer.py:731] WARNING [104][20440/  196][rank:0] loss: 0.005, average forward (0.011253) and backward (0.019190) time: 0.032424, iotime: 0.001708 
2022-08-04 10:23:30,748 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046788, Speed: 683.929502 images/s
2022-08-04 10:23:32,404 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:23:32,404 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:23:32,781 [dl_trainer.py:731] WARNING [104][20480/  196][rank:0] loss: 0.025, average forward (0.010161) and backward (0.019819) time: 0.035344, iotime: 0.005110 
2022-08-04 10:23:34,484 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049793, Speed: 642.663176 images/s
2022-08-04 10:23:34,653 [dl_trainer.py:731] WARNING [104][20520/  196][rank:0] loss: 0.025, average forward (0.009123) and backward (0.020396) time: 0.031115, iotime: 0.001372 
2022-08-04 10:23:36,317 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045804, Speed: 698.634397 images/s
2022-08-04 10:23:36,484 [dl_trainer.py:731] WARNING [104][20560/  196][rank:0] loss: 0.031, average forward (0.010372) and backward (0.019956) time: 0.032084, iotime: 0.001508 
2022-08-04 10:23:37,433 [dl_trainer.py:634] INFO train iter: 20580, num_batches_per_epoch: 196
2022-08-04 10:23:37,434 [dl_trainer.py:635] INFO Epoch 105, avg train acc: 98.294005, lr: 0.010000, avg loss: 0.051081
2022-08-04 10:23:40,089 [dl_trainer.py:822] INFO Epoch 105, lr: 0.010000, val loss: 0.347217, val top-1 acc: 91.114217, top-5 acc: 99.720447
2022-08-04 10:23:40,844 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113163, Speed: 282.776762 images/s
2022-08-04 10:23:41,018 [dl_trainer.py:731] WARNING [105][20600/  196][rank:0] loss: 0.001, average forward (0.010251) and backward (0.020509) time: 0.098929, iotime: 0.001487 
2022-08-04 10:23:42,703 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046465, Speed: 688.693276 images/s
2022-08-04 10:23:42,870 [dl_trainer.py:731] WARNING [105][20640/  196][rank:0] loss: 0.077, average forward (0.009886) and backward (0.020169) time: 0.031826, iotime: 0.001533 
2022-08-04 10:23:44,288 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:23:44,288 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:23:44,911 [dl_trainer.py:731] WARNING [105][20680/  196][rank:0] loss: 0.021, average forward (0.010106) and backward (0.019425) time: 0.035073, iotime: 0.005280 
2022-08-04 10:23:46,399 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049263, Speed: 649.580971 images/s
2022-08-04 10:23:46,816 [dl_trainer.py:731] WARNING [105][20720/  196][rank:0] loss: 0.025, average forward (0.009608) and backward (0.021144) time: 0.032412, iotime: 0.001412 
2022-08-04 10:23:48,311 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047759, Speed: 670.030076 images/s
2022-08-04 10:23:48,739 [dl_trainer.py:731] WARNING [105][20760/  196][rank:0] loss: 0.029, average forward (0.009617) and backward (0.021781) time: 0.033125, iotime: 0.001459 
2022-08-04 10:23:49,542 [dl_trainer.py:634] INFO train iter: 20776, num_batches_per_epoch: 196
2022-08-04 10:23:49,543 [dl_trainer.py:635] INFO Epoch 106, avg train acc: 98.596939, lr: 0.010000, avg loss: 0.045583
2022-08-04 10:23:52,226 [dl_trainer.py:822] INFO Epoch 106, lr: 0.010000, val loss: 0.348943, val top-1 acc: 90.934505, top-5 acc: 99.720447
2022-08-04 10:23:52,983 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.116783, Speed: 274.012487 images/s
2022-08-04 10:23:53,397 [dl_trainer.py:731] WARNING [106][20800/  196][rank:0] loss: 0.021, average forward (0.010319) and backward (0.023322) time: 0.103038, iotime: 0.001542 
2022-08-04 10:23:54,869 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047148, Speed: 678.720599 images/s
2022-08-04 10:23:55,305 [dl_trainer.py:731] WARNING [106][20840/  196][rank:0] loss: 0.050, average forward (0.010508) and backward (0.021152) time: 0.033463, iotime: 0.001533 
2022-08-04 10:23:56,501 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:23:56,502 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:23:57,335 [dl_trainer.py:731] WARNING [106][20880/  196][rank:0] loss: 0.069, average forward (0.011006) and backward (0.021158) time: 0.037800, iotime: 0.005363 
2022-08-04 10:23:58,584 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049516, Speed: 646.259729 images/s
2022-08-04 10:23:59,226 [dl_trainer.py:731] WARNING [106][20920/  196][rank:0] loss: 0.016, average forward (0.010569) and backward (0.019481) time: 0.031912, iotime: 0.001597 
2022-08-04 10:24:00,457 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046806, Speed: 683.676492 images/s
2022-08-04 10:24:01,127 [dl_trainer.py:731] WARNING [106][20960/  196][rank:0] loss: 0.028, average forward (0.010092) and backward (0.018859) time: 0.030710, iotime: 0.001492 
2022-08-04 10:24:01,689 [dl_trainer.py:634] INFO train iter: 20972, num_batches_per_epoch: 196
2022-08-04 10:24:01,690 [dl_trainer.py:635] INFO Epoch 107, avg train acc: 98.549107, lr: 0.010000, avg loss: 0.044834
2022-08-04 10:24:04,293 [dl_trainer.py:822] INFO Epoch 107, lr: 0.010000, val loss: 0.357364, val top-1 acc: 90.804712, top-5 acc: 99.700479
2022-08-04 10:24:04,942 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112098, Speed: 285.464756 images/s
2022-08-04 10:24:05,602 [dl_trainer.py:731] WARNING [107][21000/  196][rank:0] loss: 0.034, average forward (0.011237) and backward (0.021428) time: 0.099741, iotime: 0.001653 
2022-08-04 10:24:06,870 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048203, Speed: 663.856504 images/s
2022-08-04 10:24:07,542 [dl_trainer.py:731] WARNING [107][21040/  196][rank:0] loss: 0.012, average forward (0.010132) and backward (0.020901) time: 0.032808, iotime: 0.001515 
2022-08-04 10:24:08,497 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:24:08,497 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:24:09,592 [dl_trainer.py:731] WARNING [107][21080/  196][rank:0] loss: 0.056, average forward (0.010245) and backward (0.019915) time: 0.035420, iotime: 0.005008 
2022-08-04 10:24:10,597 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049675, Speed: 644.186633 images/s
2022-08-04 10:24:11,491 [dl_trainer.py:731] WARNING [107][21120/  196][rank:0] loss: 0.017, average forward (0.010313) and backward (0.018895) time: 0.030971, iotime: 0.001513 
2022-08-04 10:24:12,474 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046902, Speed: 682.268201 images/s
2022-08-04 10:24:13,331 [dl_trainer.py:731] WARNING [107][21160/  196][rank:0] loss: 0.023, average forward (0.010784) and backward (0.020361) time: 0.032970, iotime: 0.001573 
2022-08-04 10:24:13,751 [dl_trainer.py:634] INFO train iter: 21168, num_batches_per_epoch: 196
2022-08-04 10:24:13,752 [dl_trainer.py:635] INFO Epoch 108, avg train acc: 98.102679, lr: 0.010000, avg loss: 0.052923
2022-08-04 10:24:16,407 [dl_trainer.py:822] INFO Epoch 108, lr: 0.010000, val loss: 0.351362, val top-1 acc: 90.804712, top-5 acc: 99.700479
2022-08-04 10:24:17,011 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113411, Speed: 282.159318 images/s
2022-08-04 10:24:17,876 [dl_trainer.py:731] WARNING [108][21200/  196][rank:0] loss: 0.054, average forward (0.010502) and backward (0.019688) time: 0.098907, iotime: 0.001600 
2022-08-04 10:24:18,876 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046620, Speed: 686.401485 images/s
2022-08-04 10:24:19,748 [dl_trainer.py:731] WARNING [108][21240/  196][rank:0] loss: 0.013, average forward (0.009340) and backward (0.019382) time: 0.030423, iotime: 0.001463 
2022-08-04 10:24:20,493 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:24:20,494 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:24:21,811 [dl_trainer.py:731] WARNING [108][21280/  196][rank:0] loss: 0.017, average forward (0.010809) and backward (0.021388) time: 0.037605, iotime: 0.005143 
2022-08-04 10:24:22,545 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048905, Speed: 654.328113 images/s
2022-08-04 10:24:23,586 [dl_trainer.py:731] WARNING [108][21320/  196][rank:0] loss: 0.016, average forward (0.009491) and backward (0.015693) time: 0.026825, iotime: 0.001393 
2022-08-04 10:24:24,350 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045098, Speed: 709.559070 images/s
2022-08-04 10:24:25,497 [dl_trainer.py:731] WARNING [108][21360/  196][rank:0] loss: 0.064, average forward (0.008900) and backward (0.018284) time: 0.028811, iotime: 0.001387 
2022-08-04 10:24:25,692 [dl_trainer.py:634] INFO train iter: 21364, num_batches_per_epoch: 196
2022-08-04 10:24:25,693 [dl_trainer.py:635] INFO Epoch 109, avg train acc: 98.437500, lr: 0.010000, avg loss: 0.048813
2022-08-04 10:24:28,366 [dl_trainer.py:822] INFO Epoch 109, lr: 0.010000, val loss: 0.361057, val top-1 acc: 90.994409, top-5 acc: 99.690495
2022-08-04 10:24:28,941 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114755, Speed: 278.854057 images/s
2022-08-04 10:24:30,026 [dl_trainer.py:731] WARNING [109][21400/  196][rank:0] loss: 0.086, average forward (0.010528) and backward (0.019971) time: 0.099227, iotime: 0.001551 
2022-08-04 10:24:30,776 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045865, Speed: 697.697424 images/s
2022-08-04 10:24:31,891 [dl_trainer.py:731] WARNING [109][21440/  196][rank:0] loss: 0.070, average forward (0.009641) and backward (0.019576) time: 0.030870, iotime: 0.001409 
2022-08-04 10:24:32,378 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:24:32,378 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:24:33,948 [dl_trainer.py:731] WARNING [109][21480/  196][rank:0] loss: 0.005, average forward (0.009844) and backward (0.019462) time: 0.034654, iotime: 0.005091 
2022-08-04 10:24:34,491 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049514, Speed: 646.283296 images/s
2022-08-04 10:24:35,858 [dl_trainer.py:731] WARNING [109][21520/  196][rank:0] loss: 0.015, average forward (0.009829) and backward (0.019860) time: 0.031410, iotime: 0.001476 
2022-08-04 10:24:36,414 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048048, Speed: 665.998001 images/s
2022-08-04 10:24:37,692 [dl_trainer.py:731] WARNING [109][21560/  196][rank:0] loss: 0.061, average forward (0.010573) and backward (0.020157) time: 0.032600, iotime: 0.001591 
2022-08-04 10:24:37,710 [dl_trainer.py:634] INFO train iter: 21560, num_batches_per_epoch: 196
2022-08-04 10:24:37,711 [dl_trainer.py:635] INFO Epoch 110, avg train acc: 98.341837, lr: 0.010000, avg loss: 0.051732
2022-08-04 10:24:40,371 [dl_trainer.py:822] INFO Epoch 110, lr: 0.010000, val loss: 0.358677, val top-1 acc: 90.924521, top-5 acc: 99.690495
2022-08-04 10:24:40,894 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111984, Speed: 285.755831 images/s
2022-08-04 10:24:42,209 [dl_trainer.py:731] WARNING [110][21600/  196][rank:0] loss: 0.027, average forward (0.009649) and backward (0.022109) time: 0.100531, iotime: 0.001516 
2022-08-04 10:24:42,750 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046405, Speed: 689.582909 images/s
2022-08-04 10:24:44,060 [dl_trainer.py:731] WARNING [110][21640/  196][rank:0] loss: 0.037, average forward (0.010330) and backward (0.020063) time: 0.032241, iotime: 0.001589 
2022-08-04 10:24:44,318 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:24:44,318 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:24:46,115 [dl_trainer.py:731] WARNING [110][21680/  196][rank:0] loss: 0.020, average forward (0.009352) and backward (0.020112) time: 0.034873, iotime: 0.005160 
2022-08-04 10:24:46,410 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048755, Speed: 656.346871 images/s
2022-08-04 10:24:48,060 [dl_trainer.py:731] WARNING [110][21720/  196][rank:0] loss: 0.011, average forward (0.012574) and backward (0.021615) time: 0.036230, iotime: 0.001751 
2022-08-04 10:24:48,357 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048642, Speed: 657.866429 images/s
2022-08-04 10:24:49,743 [dl_trainer.py:634] INFO train iter: 21756, num_batches_per_epoch: 196
2022-08-04 10:24:49,743 [dl_trainer.py:635] INFO Epoch 111, avg train acc: 98.580995, lr: 0.010000, avg loss: 0.044391
2022-08-04 10:24:52,453 [dl_trainer.py:822] INFO Epoch 111, lr: 0.010000, val loss: 0.369487, val top-1 acc: 90.814696, top-5 acc: 99.700479
2022-08-04 10:24:52,632 [dl_trainer.py:731] WARNING [111][21760/  196][rank:0] loss: 0.027, average forward (0.011222) and backward (0.020775) time: 0.101678, iotime: 0.001587 
2022-08-04 10:24:52,896 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113462, Speed: 282.032437 images/s
2022-08-04 10:24:54,527 [dl_trainer.py:731] WARNING [111][21800/  196][rank:0] loss: 0.015, average forward (0.010217) and backward (0.022054) time: 0.034080, iotime: 0.001533 
2022-08-04 10:24:54,826 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048243, Speed: 663.309348 images/s
2022-08-04 10:24:56,462 [dl_trainer.py:731] WARNING [111][21840/  196][rank:0] loss: 0.142, average forward (0.010592) and backward (0.022019) time: 0.034449, iotime: 0.001570 
2022-08-04 10:24:56,470 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:24:56,470 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:24:58,518 [dl_trainer.py:731] WARNING [111][21880/  196][rank:0] loss: 0.033, average forward (0.009796) and backward (0.020601) time: 0.036416, iotime: 0.005756 
2022-08-04 10:24:58,568 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049868, Speed: 641.690243 images/s
2022-08-04 10:25:00,340 [dl_trainer.py:731] WARNING [111][21920/  196][rank:0] loss: 0.009, average forward (0.011009) and backward (0.018649) time: 0.031688, iotime: 0.001774 
2022-08-04 10:25:00,415 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046167, Speed: 693.130717 images/s
2022-08-04 10:25:01,837 [dl_trainer.py:634] INFO train iter: 21952, num_batches_per_epoch: 196
2022-08-04 10:25:01,838 [dl_trainer.py:635] INFO Epoch 112, avg train acc: 98.262117, lr: 0.010000, avg loss: 0.049689
2022-08-04 10:25:04,478 [dl_trainer.py:822] INFO Epoch 112, lr: 0.010000, val loss: 0.358149, val top-1 acc: 91.014377, top-5 acc: 99.700479
2022-08-04 10:25:04,859 [dl_trainer.py:731] WARNING [112][21960/  196][rank:0] loss: 0.011, average forward (0.009058) and backward (0.019882) time: 0.097069, iotime: 0.001397 
2022-08-04 10:25:04,929 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112842, Speed: 283.581786 images/s
2022-08-04 10:25:06,763 [dl_trainer.py:731] WARNING [112][22000/  196][rank:0] loss: 0.074, average forward (0.010366) and backward (0.018134) time: 0.030286, iotime: 0.001532 
2022-08-04 10:25:06,826 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047417, Speed: 674.859162 images/s
2022-08-04 10:25:08,474 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:25:08,474 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:25:08,860 [dl_trainer.py:731] WARNING [112][22040/  196][rank:0] loss: 0.081, average forward (0.010837) and backward (0.021289) time: 0.037642, iotime: 0.005242 
2022-08-04 10:25:10,524 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049279, Speed: 649.362067 images/s
2022-08-04 10:25:10,705 [dl_trainer.py:731] WARNING [112][22080/  196][rank:0] loss: 0.089, average forward (0.010278) and backward (0.021278) time: 0.033319, iotime: 0.001500 
2022-08-04 10:25:12,420 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047370, Speed: 675.534671 images/s
2022-08-04 10:25:12,587 [dl_trainer.py:731] WARNING [112][22120/  196][rank:0] loss: 0.037, average forward (0.010031) and backward (0.019704) time: 0.031517, iotime: 0.001526 
2022-08-04 10:25:13,910 [dl_trainer.py:634] INFO train iter: 22148, num_batches_per_epoch: 196
2022-08-04 10:25:13,911 [dl_trainer.py:635] INFO Epoch 113, avg train acc: 98.421556, lr: 0.010000, avg loss: 0.047057
2022-08-04 10:25:16,544 [dl_trainer.py:822] INFO Epoch 113, lr: 0.010000, val loss: 0.360032, val top-1 acc: 90.814696, top-5 acc: 99.710463
2022-08-04 10:25:16,897 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111923, Speed: 285.911922 images/s
2022-08-04 10:25:17,073 [dl_trainer.py:731] WARNING [113][22160/  196][rank:0] loss: 0.022, average forward (0.010856) and backward (0.020498) time: 0.099040, iotime: 0.001536 
2022-08-04 10:25:18,823 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048142, Speed: 664.700782 images/s
2022-08-04 10:25:18,975 [dl_trainer.py:731] WARNING [113][22200/  196][rank:0] loss: 0.056, average forward (0.008942) and backward (0.017782) time: 0.028354, iotime: 0.001386 
2022-08-04 10:25:20,446 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:25:20,446 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:25:21,043 [dl_trainer.py:731] WARNING [113][22240/  196][rank:0] loss: 0.029, average forward (0.009403) and backward (0.019678) time: 0.034561, iotime: 0.005237 
2022-08-04 10:25:22,556 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049752, Speed: 643.189482 images/s
2022-08-04 10:25:22,941 [dl_trainer.py:731] WARNING [113][22280/  196][rank:0] loss: 0.038, average forward (0.010535) and backward (0.021286) time: 0.033713, iotime: 0.001636 
2022-08-04 10:25:24,472 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047891, Speed: 668.186372 images/s
2022-08-04 10:25:24,886 [dl_trainer.py:731] WARNING [113][22320/  196][rank:0] loss: 0.007, average forward (0.009394) and backward (0.021890) time: 0.032951, iotime: 0.001427 
2022-08-04 10:25:26,063 [dl_trainer.py:634] INFO train iter: 22344, num_batches_per_epoch: 196
2022-08-04 10:25:26,064 [dl_trainer.py:635] INFO Epoch 114, avg train acc: 98.278061, lr: 0.010000, avg loss: 0.050805
2022-08-04 10:25:28,691 [dl_trainer.py:822] INFO Epoch 114, lr: 0.010000, val loss: 0.366301, val top-1 acc: 91.094249, top-5 acc: 99.660543
2022-08-04 10:25:29,029 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113904, Speed: 280.939350 images/s
2022-08-04 10:25:29,436 [dl_trainer.py:731] WARNING [114][22360/  196][rank:0] loss: 0.008, average forward (0.010883) and backward (0.020473) time: 0.099453, iotime: 0.001608 
2022-08-04 10:25:30,878 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046223, Speed: 692.292075 images/s
2022-08-04 10:25:31,281 [dl_trainer.py:731] WARNING [114][22400/  196][rank:0] loss: 0.081, average forward (0.009442) and backward (0.019635) time: 0.030805, iotime: 0.001486 
2022-08-04 10:25:32,476 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:25:32,477 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:25:33,332 [dl_trainer.py:731] WARNING [114][22440/  196][rank:0] loss: 0.011, average forward (0.009224) and backward (0.020091) time: 0.034697, iotime: 0.005123 
2022-08-04 10:25:34,532 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048700, Speed: 657.080559 images/s
2022-08-04 10:25:35,194 [dl_trainer.py:731] WARNING [114][22480/  196][rank:0] loss: 0.036, average forward (0.009992) and backward (0.019096) time: 0.030829, iotime: 0.001489 
2022-08-04 10:25:36,437 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047615, Speed: 672.050681 images/s
2022-08-04 10:25:37,091 [dl_trainer.py:731] WARNING [114][22520/  196][rank:0] loss: 0.007, average forward (0.010303) and backward (0.022132) time: 0.034201, iotime: 0.001505 
2022-08-04 10:25:38,056 [dl_trainer.py:634] INFO train iter: 22540, num_batches_per_epoch: 196
2022-08-04 10:25:38,057 [dl_trainer.py:635] INFO Epoch 115, avg train acc: 98.485332, lr: 0.010000, avg loss: 0.045493
2022-08-04 10:25:40,658 [dl_trainer.py:822] INFO Epoch 115, lr: 0.010000, val loss: 0.366306, val top-1 acc: 90.854633, top-5 acc: 99.720447
2022-08-04 10:25:40,954 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112895, Speed: 283.448968 images/s
2022-08-04 10:25:41,611 [dl_trainer.py:731] WARNING [115][22560/  196][rank:0] loss: 0.008, average forward (0.009209) and backward (0.021428) time: 0.097450, iotime: 0.001472 
2022-08-04 10:25:42,812 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046437, Speed: 689.099195 images/s
2022-08-04 10:25:43,438 [dl_trainer.py:731] WARNING [115][22600/  196][rank:0] loss: 0.007, average forward (0.010454) and backward (0.018835) time: 0.031008, iotime: 0.001471 
2022-08-04 10:25:44,395 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:25:44,395 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:25:45,481 [dl_trainer.py:731] WARNING [115][22640/  196][rank:0] loss: 0.010, average forward (0.009453) and backward (0.019495) time: 0.034226, iotime: 0.005038 
2022-08-04 10:25:46,487 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048982, Speed: 653.297350 images/s
2022-08-04 10:25:47,399 [dl_trainer.py:731] WARNING [115][22680/  196][rank:0] loss: 0.127, average forward (0.011522) and backward (0.019673) time: 0.033002, iotime: 0.001534 
2022-08-04 10:25:48,405 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047936, Speed: 667.554689 images/s
2022-08-04 10:25:49,298 [dl_trainer.py:731] WARNING [115][22720/  196][rank:0] loss: 0.056, average forward (0.010234) and backward (0.021174) time: 0.033152, iotime: 0.001487 
2022-08-04 10:25:50,073 [dl_trainer.py:634] INFO train iter: 22736, num_batches_per_epoch: 196
2022-08-04 10:25:50,073 [dl_trainer.py:635] INFO Epoch 116, avg train acc: 98.852041, lr: 0.010000, avg loss: 0.038212
2022-08-04 10:25:52,692 [dl_trainer.py:822] INFO Epoch 116, lr: 0.010000, val loss: 0.362347, val top-1 acc: 90.914537, top-5 acc: 99.660543
2022-08-04 10:25:52,926 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113007, Speed: 283.168426 images/s
2022-08-04 10:25:53,807 [dl_trainer.py:731] WARNING [116][22760/  196][rank:0] loss: 0.020, average forward (0.009467) and backward (0.019645) time: 0.096654, iotime: 0.001403 
2022-08-04 10:25:54,813 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047169, Speed: 678.411156 images/s
2022-08-04 10:25:55,664 [dl_trainer.py:731] WARNING [116][22800/  196][rank:0] loss: 0.052, average forward (0.010557) and backward (0.020944) time: 0.033345, iotime: 0.001580 
2022-08-04 10:25:56,402 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:25:56,402 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:25:57,719 [dl_trainer.py:731] WARNING [116][22840/  196][rank:0] loss: 0.097, average forward (0.010018) and backward (0.021860) time: 0.037478, iotime: 0.005329 
2022-08-04 10:25:58,488 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048986, Speed: 653.253428 images/s
2022-08-04 10:25:59,641 [dl_trainer.py:731] WARNING [116][22880/  196][rank:0] loss: 0.030, average forward (0.008385) and backward (0.020113) time: 0.030008, iotime: 0.001288 
2022-08-04 10:26:00,421 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048292, Speed: 662.630984 images/s
2022-08-04 10:26:01,534 [dl_trainer.py:731] WARNING [116][22920/  196][rank:0] loss: 0.010, average forward (0.009614) and backward (0.020424) time: 0.031737, iotime: 0.001450 
2022-08-04 10:26:02,119 [dl_trainer.py:634] INFO train iter: 22932, num_batches_per_epoch: 196
2022-08-04 10:26:02,119 [dl_trainer.py:635] INFO Epoch 117, avg train acc: 98.820153, lr: 0.010000, avg loss: 0.038542
2022-08-04 10:26:04,716 [dl_trainer.py:822] INFO Epoch 117, lr: 0.010000, val loss: 0.369923, val top-1 acc: 91.014377, top-5 acc: 99.670527
2022-08-04 10:26:04,893 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111795, Speed: 286.238625 images/s
2022-08-04 10:26:05,982 [dl_trainer.py:731] WARNING [117][22960/  196][rank:0] loss: 0.027, average forward (0.009619) and backward (0.020958) time: 0.097279, iotime: 0.001482 
2022-08-04 10:26:06,782 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047212, Speed: 677.799448 images/s
2022-08-04 10:26:07,926 [dl_trainer.py:731] WARNING [117][23000/  196][rank:0] loss: 0.087, average forward (0.010756) and backward (0.022067) time: 0.034697, iotime: 0.001596 
2022-08-04 10:26:08,410 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:26:08,411 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:26:09,961 [dl_trainer.py:731] WARNING [117][23040/  196][rank:0] loss: 0.021, average forward (0.010669) and backward (0.020759) time: 0.037112, iotime: 0.005431 
2022-08-04 10:26:10,444 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048821, Speed: 655.453368 images/s
2022-08-04 10:26:11,734 [dl_trainer.py:731] WARNING [117][23080/  196][rank:0] loss: 0.035, average forward (0.010249) and backward (0.019485) time: 0.031527, iotime: 0.001553 
2022-08-04 10:26:12,247 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045046, Speed: 710.378334 images/s
2022-08-04 10:26:13,629 [dl_trainer.py:731] WARNING [117][23120/  196][rank:0] loss: 0.007, average forward (0.009525) and backward (0.020450) time: 0.031686, iotime: 0.001478 
2022-08-04 10:26:14,026 [dl_trainer.py:634] INFO train iter: 23128, num_batches_per_epoch: 196
2022-08-04 10:26:14,027 [dl_trainer.py:635] INFO Epoch 118, avg train acc: 98.836097, lr: 0.010000, avg loss: 0.038158
2022-08-04 10:26:16,687 [dl_trainer.py:822] INFO Epoch 118, lr: 0.010000, val loss: 0.366038, val top-1 acc: 91.303914, top-5 acc: 99.690495
2022-08-04 10:26:16,847 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114985, Speed: 278.297758 images/s
2022-08-04 10:26:18,219 [dl_trainer.py:731] WARNING [118][23160/  196][rank:0] loss: 0.054, average forward (0.009326) and backward (0.020221) time: 0.098238, iotime: 0.001475 
2022-08-04 10:26:18,760 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047797, Speed: 669.495074 images/s
2022-08-04 10:26:20,084 [dl_trainer.py:731] WARNING [118][23200/  196][rank:0] loss: 0.019, average forward (0.009846) and backward (0.020934) time: 0.032496, iotime: 0.001489 
2022-08-04 10:26:20,342 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:26:20,342 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:26:22,125 [dl_trainer.py:731] WARNING [118][23240/  196][rank:0] loss: 0.125, average forward (0.010123) and backward (0.021225) time: 0.036679, iotime: 0.005065 
2022-08-04 10:26:22,418 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048750, Speed: 656.414879 images/s
2022-08-04 10:26:24,006 [dl_trainer.py:731] WARNING [118][23280/  196][rank:0] loss: 0.015, average forward (0.009853) and backward (0.020360) time: 0.031861, iotime: 0.001414 
2022-08-04 10:26:24,307 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047223, Speed: 677.640406 images/s
2022-08-04 10:26:25,905 [dl_trainer.py:731] WARNING [118][23320/  196][rank:0] loss: 0.034, average forward (0.009317) and backward (0.021293) time: 0.032224, iotime: 0.001363 
2022-08-04 10:26:26,110 [dl_trainer.py:634] INFO train iter: 23324, num_batches_per_epoch: 196
2022-08-04 10:26:26,110 [dl_trainer.py:635] INFO Epoch 119, avg train acc: 98.469388, lr: 0.010000, avg loss: 0.045626
2022-08-04 10:26:28,790 [dl_trainer.py:822] INFO Epoch 119, lr: 0.010000, val loss: 0.380502, val top-1 acc: 90.864617, top-5 acc: 99.680511
2022-08-04 10:26:28,891 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114578, Speed: 279.286882 images/s
2022-08-04 10:26:30,454 [dl_trainer.py:731] WARNING [119][23360/  196][rank:0] loss: 0.031, average forward (0.010030) and backward (0.021315) time: 0.100196, iotime: 0.001508 
2022-08-04 10:26:30,745 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046336, Speed: 690.607895 images/s
2022-08-04 10:26:32,364 [dl_trainer.py:731] WARNING [119][23400/  196][rank:0] loss: 0.095, average forward (0.010320) and backward (0.020509) time: 0.032515, iotime: 0.001438 
2022-08-04 10:26:32,373 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:26:32,374 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:26:34,391 [dl_trainer.py:731] WARNING [119][23440/  196][rank:0] loss: 0.066, average forward (0.009141) and backward (0.018389) time: 0.033006, iotime: 0.005217 
2022-08-04 10:26:34,453 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049426, Speed: 647.430702 images/s
2022-08-04 10:26:36,283 [dl_trainer.py:731] WARNING [119][23480/  196][rank:0] loss: 0.090, average forward (0.010535) and backward (0.019949) time: 0.032271, iotime: 0.001528 
2022-08-04 10:26:36,346 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047305, Speed: 676.457685 images/s
2022-08-04 10:26:38,171 [dl_trainer.py:731] WARNING [119][23520/  196][rank:0] loss: 0.039, average forward (0.009187) and backward (0.021129) time: 0.032020, iotime: 0.001465 
2022-08-04 10:26:38,195 [dl_trainer.py:634] INFO train iter: 23520, num_batches_per_epoch: 196
2022-08-04 10:26:38,195 [dl_trainer.py:635] INFO Epoch 120, avg train acc: 98.580995, lr: 0.010000, avg loss: 0.046055
2022-08-04 10:26:40,848 [dl_trainer.py:822] INFO Epoch 120, lr: 0.010000, val loss: 0.367819, val top-1 acc: 91.184105, top-5 acc: 99.660543
2022-08-04 10:26:40,917 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114252, Speed: 280.082125 images/s
2022-08-04 10:26:42,767 [dl_trainer.py:731] WARNING [120][23560/  196][rank:0] loss: 0.028, average forward (0.011478) and backward (0.021671) time: 0.102002, iotime: 0.001774 
2022-08-04 10:26:42,823 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047652, Speed: 671.531011 images/s
2022-08-04 10:26:44,457 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:26:44,457 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:26:44,841 [dl_trainer.py:731] WARNING [120][23600/  196][rank:0] loss: 0.011, average forward (0.012458) and backward (0.022285) time: 0.040374, iotime: 0.005327 
2022-08-04 10:26:46,559 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049784, Speed: 642.775945 images/s
2022-08-04 10:26:46,735 [dl_trainer.py:731] WARNING [120][23640/  196][rank:0] loss: 0.007, average forward (0.009373) and backward (0.018963) time: 0.029967, iotime: 0.001396 
2022-08-04 10:26:48,471 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047781, Speed: 669.717978 images/s
2022-08-04 10:26:48,637 [dl_trainer.py:731] WARNING [120][23680/  196][rank:0] loss: 0.042, average forward (0.009018) and backward (0.018450) time: 0.029145, iotime: 0.001437 
2022-08-04 10:26:50,336 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046604, Speed: 686.637020 images/s
2022-08-04 10:26:50,337 [dl_trainer.py:634] INFO train iter: 23716, num_batches_per_epoch: 196
2022-08-04 10:26:50,337 [dl_trainer.py:635] INFO Epoch 121, avg train acc: 98.772321, lr: 0.010000, avg loss: 0.041155
2022-08-04 10:26:52,980 [dl_trainer.py:822] INFO Epoch 121, lr: 0.010000, val loss: 0.374956, val top-1 acc: 90.894569, top-5 acc: 99.610623
2022-08-04 10:26:53,157 [dl_trainer.py:731] WARNING [121][23720/  196][rank:0] loss: 0.119, average forward (0.010116) and backward (0.020741) time: 0.098703, iotime: 0.001451 
2022-08-04 10:26:54,893 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113918, Speed: 280.902910 images/s
2022-08-04 10:26:55,068 [dl_trainer.py:731] WARNING [121][23760/  196][rank:0] loss: 0.053, average forward (0.009753) and backward (0.021075) time: 0.032557, iotime: 0.001490 
2022-08-04 10:26:56,511 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:26:56,511 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:26:57,127 [dl_trainer.py:731] WARNING [121][23800/  196][rank:0] loss: 0.022, average forward (0.009494) and backward (0.021081) time: 0.036096, iotime: 0.005260 
2022-08-04 10:26:58,602 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049430, Speed: 647.376324 images/s
2022-08-04 10:26:59,008 [dl_trainer.py:731] WARNING [121][23840/  196][rank:0] loss: 0.043, average forward (0.010410) and backward (0.020463) time: 0.032653, iotime: 0.001523 
2022-08-04 10:27:00,472 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046710, Speed: 685.084400 images/s
2022-08-04 10:27:00,872 [dl_trainer.py:731] WARNING [121][23880/  196][rank:0] loss: 0.046, average forward (0.009598) and backward (0.021153) time: 0.032405, iotime: 0.001409 
2022-08-04 10:27:02,321 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046232, Speed: 692.155072 images/s
2022-08-04 10:27:02,373 [dl_trainer.py:634] INFO train iter: 23912, num_batches_per_epoch: 196
2022-08-04 10:27:02,373 [dl_trainer.py:635] INFO Epoch 122, avg train acc: 98.708546, lr: 0.010000, avg loss: 0.041678
2022-08-04 10:27:05,021 [dl_trainer.py:822] INFO Epoch 122, lr: 0.010000, val loss: 0.376042, val top-1 acc: 90.924521, top-5 acc: 99.650559
2022-08-04 10:27:05,399 [dl_trainer.py:731] WARNING [122][23920/  196][rank:0] loss: 0.008, average forward (0.011486) and backward (0.021697) time: 0.101849, iotime: 0.001698 
2022-08-04 10:27:06,887 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114137, Speed: 280.365440 images/s
2022-08-04 10:27:07,303 [dl_trainer.py:731] WARNING [122][23960/  196][rank:0] loss: 0.144, average forward (0.011345) and backward (0.020711) time: 0.033941, iotime: 0.001620 
2022-08-04 10:27:08,559 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:27:08,559 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:27:09,397 [dl_trainer.py:731] WARNING [122][24000/  196][rank:0] loss: 0.004, average forward (0.009067) and backward (0.021339) time: 0.035805, iotime: 0.005163 
2022-08-04 10:27:10,636 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049962, Speed: 640.492933 images/s
2022-08-04 10:27:11,275 [dl_trainer.py:731] WARNING [122][24040/  196][rank:0] loss: 0.010, average forward (0.009556) and backward (0.020582) time: 0.031799, iotime: 0.001426 
2022-08-04 10:27:12,517 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047009, Speed: 680.713935 images/s
2022-08-04 10:27:13,141 [dl_trainer.py:731] WARNING [122][24080/  196][rank:0] loss: 0.010, average forward (0.010649) and backward (0.021176) time: 0.033662, iotime: 0.001559 
2022-08-04 10:27:14,395 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046941, Speed: 681.710802 images/s
2022-08-04 10:27:14,486 [dl_trainer.py:634] INFO train iter: 24108, num_batches_per_epoch: 196
2022-08-04 10:27:14,486 [dl_trainer.py:635] INFO Epoch 123, avg train acc: 98.612883, lr: 0.001000, avg loss: 0.040436
2022-08-04 10:27:17,262 [dl_trainer.py:822] INFO Epoch 123, lr: 0.001000, val loss: 0.368887, val top-1 acc: 91.044329, top-5 acc: 99.710463
2022-08-04 10:27:17,817 [dl_trainer.py:731] WARNING [123][24120/  196][rank:0] loss: 0.019, average forward (0.009929) and backward (0.021470) time: 0.102669, iotime: 0.001517 
2022-08-04 10:27:19,101 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.117621, Speed: 272.060637 images/s
2022-08-04 10:27:19,769 [dl_trainer.py:731] WARNING [123][24160/  196][rank:0] loss: 0.027, average forward (0.011807) and backward (0.022852) time: 0.036589, iotime: 0.001636 
2022-08-04 10:27:20,697 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:27:20,697 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:27:21,767 [dl_trainer.py:731] WARNING [123][24200/  196][rank:0] loss: 0.197, average forward (0.010075) and backward (0.021080) time: 0.036865, iotime: 0.005457 
2022-08-04 10:27:22,742 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048542, Speed: 659.220086 images/s
2022-08-04 10:27:23,596 [dl_trainer.py:731] WARNING [123][24240/  196][rank:0] loss: 0.010, average forward (0.010194) and backward (0.020757) time: 0.032731, iotime: 0.001533 
2022-08-04 10:27:24,592 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046201, Speed: 692.632542 images/s
2022-08-04 10:27:25,532 [dl_trainer.py:731] WARNING [123][24280/  196][rank:0] loss: 0.005, average forward (0.010516) and backward (0.022412) time: 0.034785, iotime: 0.001589 
2022-08-04 10:27:26,554 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049055, Speed: 652.335067 images/s
2022-08-04 10:27:26,681 [dl_trainer.py:634] INFO train iter: 24304, num_batches_per_epoch: 196
2022-08-04 10:27:26,682 [dl_trainer.py:635] INFO Epoch 124, avg train acc: 98.644770, lr: 0.001000, avg loss: 0.038544
2022-08-04 10:27:29,289 [dl_trainer.py:822] INFO Epoch 124, lr: 0.001000, val loss: 0.364492, val top-1 acc: 91.084265, top-5 acc: 99.700479
2022-08-04 10:27:30,060 [dl_trainer.py:731] WARNING [124][24320/  196][rank:0] loss: 0.022, average forward (0.009908) and backward (0.022406) time: 0.099746, iotime: 0.001494 
2022-08-04 10:27:31,079 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113111, Speed: 282.907206 images/s
2022-08-04 10:27:31,932 [dl_trainer.py:731] WARNING [124][24360/  196][rank:0] loss: 0.034, average forward (0.010760) and backward (0.021401) time: 0.034031, iotime: 0.001599 
2022-08-04 10:27:32,668 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:27:32,668 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:27:34,016 [dl_trainer.py:731] WARNING [124][24400/  196][rank:0] loss: 0.128, average forward (0.011133) and backward (0.020159) time: 0.036754, iotime: 0.005183 
2022-08-04 10:27:34,796 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049530, Speed: 646.074446 images/s
2022-08-04 10:27:35,949 [dl_trainer.py:731] WARNING [124][24440/  196][rank:0] loss: 0.025, average forward (0.009850) and backward (0.023362) time: 0.034945, iotime: 0.001486 
2022-08-04 10:27:36,731 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048350, Speed: 661.835110 images/s
2022-08-04 10:27:37,893 [dl_trainer.py:731] WARNING [124][24480/  196][rank:0] loss: 0.004, average forward (0.009723) and backward (0.021533) time: 0.032934, iotime: 0.001446 
2022-08-04 10:27:38,663 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048278, Speed: 662.824707 images/s
2022-08-04 10:27:38,851 [dl_trainer.py:634] INFO train iter: 24500, num_batches_per_epoch: 196
2022-08-04 10:27:38,851 [dl_trainer.py:635] INFO Epoch 125, avg train acc: 99.043367, lr: 0.001000, avg loss: 0.033288
2022-08-04 10:27:41,465 [dl_trainer.py:822] INFO Epoch 125, lr: 0.001000, val loss: 0.366639, val top-1 acc: 91.074281, top-5 acc: 99.700479
2022-08-04 10:27:42,416 [dl_trainer.py:731] WARNING [125][24520/  196][rank:0] loss: 0.051, average forward (0.010831) and backward (0.021007) time: 0.099141, iotime: 0.001616 
2022-08-04 10:27:43,224 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114015, Speed: 280.664573 images/s
2022-08-04 10:27:44,331 [dl_trainer.py:731] WARNING [125][24560/  196][rank:0] loss: 0.069, average forward (0.010258) and backward (0.021017) time: 0.032981, iotime: 0.001459 
2022-08-04 10:27:44,810 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:27:44,810 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:27:46,359 [dl_trainer.py:731] WARNING [125][24600/  196][rank:0] loss: 0.006, average forward (0.011419) and backward (0.019908) time: 0.036891, iotime: 0.005265 
2022-08-04 10:27:46,901 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048992, Speed: 653.167085 images/s
2022-08-04 10:27:48,258 [dl_trainer.py:731] WARNING [125][24640/  196][rank:0] loss: 0.015, average forward (0.010234) and backward (0.019755) time: 0.031742, iotime: 0.001506 
2022-08-04 10:27:48,800 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047451, Speed: 674.375885 images/s
2022-08-04 10:27:50,105 [dl_trainer.py:731] WARNING [125][24680/  196][rank:0] loss: 0.093, average forward (0.010892) and backward (0.019991) time: 0.032727, iotime: 0.001589 
2022-08-04 10:27:50,619 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045461, Speed: 703.893324 images/s
2022-08-04 10:27:50,858 [dl_trainer.py:634] INFO train iter: 24696, num_batches_per_epoch: 196
2022-08-04 10:27:50,859 [dl_trainer.py:635] INFO Epoch 126, avg train acc: 98.979592, lr: 0.001000, avg loss: 0.032854
2022-08-04 10:27:53,500 [dl_trainer.py:822] INFO Epoch 126, lr: 0.001000, val loss: 0.367229, val top-1 acc: 91.014377, top-5 acc: 99.670527
2022-08-04 10:27:54,645 [dl_trainer.py:731] WARNING [126][24720/  196][rank:0] loss: 0.007, average forward (0.009984) and backward (0.019444) time: 0.097684, iotime: 0.001486 
2022-08-04 10:27:55,153 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113344, Speed: 282.325415 images/s
2022-08-04 10:27:56,518 [dl_trainer.py:731] WARNING [126][24760/  196][rank:0] loss: 0.010, average forward (0.010016) and backward (0.019339) time: 0.031045, iotime: 0.001442 
2022-08-04 10:27:56,767 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:27:56,767 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:27:58,531 [dl_trainer.py:731] WARNING [126][24800/  196][rank:0] loss: 0.009, average forward (0.009820) and backward (0.019730) time: 0.035441, iotime: 0.005639 
2022-08-04 10:27:58,834 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049069, Speed: 652.141326 images/s
2022-08-04 10:28:00,419 [dl_trainer.py:731] WARNING [126][24840/  196][rank:0] loss: 0.053, average forward (0.011469) and backward (0.021531) time: 0.034863, iotime: 0.001587 
2022-08-04 10:28:00,729 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047347, Speed: 675.856214 images/s
2022-08-04 10:28:02,308 [dl_trainer.py:731] WARNING [126][24880/  196][rank:0] loss: 0.004, average forward (0.010852) and backward (0.022016) time: 0.034816, iotime: 0.001691 
2022-08-04 10:28:02,612 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047063, Speed: 679.938034 images/s
2022-08-04 10:28:02,914 [dl_trainer.py:634] INFO train iter: 24892, num_batches_per_epoch: 196
2022-08-04 10:28:02,915 [dl_trainer.py:635] INFO Epoch 127, avg train acc: 98.867985, lr: 0.001000, avg loss: 0.036299
2022-08-04 10:28:05,592 [dl_trainer.py:822] INFO Epoch 127, lr: 0.001000, val loss: 0.368172, val top-1 acc: 90.884585, top-5 acc: 99.650559
2022-08-04 10:28:06,895 [dl_trainer.py:731] WARNING [127][24920/  196][rank:0] loss: 0.004, average forward (0.011350) and backward (0.020518) time: 0.100790, iotime: 0.001638 
2022-08-04 10:28:07,205 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114808, Speed: 278.726021 images/s
2022-08-04 10:28:08,813 [dl_trainer.py:731] WARNING [127][24960/  196][rank:0] loss: 0.007, average forward (0.010426) and backward (0.021023) time: 0.033198, iotime: 0.001495 
2022-08-04 10:28:08,834 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:28:08,834 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:28:10,859 [dl_trainer.py:731] WARNING [127][25000/  196][rank:0] loss: 0.029, average forward (0.009929) and backward (0.019637) time: 0.035135, iotime: 0.005306 
2022-08-04 10:28:10,923 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049562, Speed: 645.654336 images/s
2022-08-04 10:28:12,762 [dl_trainer.py:731] WARNING [127][25040/  196][rank:0] loss: 0.022, average forward (0.011603) and backward (0.021506) time: 0.035017, iotime: 0.001643 
2022-08-04 10:28:12,822 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047430, Speed: 674.674535 images/s
2022-08-04 10:28:14,675 [dl_trainer.py:731] WARNING [127][25080/  196][rank:0] loss: 0.029, average forward (0.010142) and backward (0.021723) time: 0.033642, iotime: 0.001505 
2022-08-04 10:28:14,732 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047741, Speed: 670.280533 images/s
2022-08-04 10:28:15,062 [dl_trainer.py:634] INFO train iter: 25088, num_batches_per_epoch: 196
2022-08-04 10:28:15,063 [dl_trainer.py:635] INFO Epoch 128, avg train acc: 98.756378, lr: 0.001000, avg loss: 0.039622
2022-08-04 10:28:17,736 [dl_trainer.py:822] INFO Epoch 128, lr: 0.001000, val loss: 0.366741, val top-1 acc: 91.034345, top-5 acc: 99.680511
2022-08-04 10:28:19,231 [dl_trainer.py:731] WARNING [128][25120/  196][rank:0] loss: 0.077, average forward (0.011992) and backward (0.020677) time: 0.102076, iotime: 0.001716 
2022-08-04 10:28:19,290 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113927, Speed: 280.880454 images/s
2022-08-04 10:28:20,926 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:28:20,927 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:28:21,310 [dl_trainer.py:731] WARNING [128][25160/  196][rank:0] loss: 0.032, average forward (0.011385) and backward (0.020910) time: 0.038286, iotime: 0.005688 
2022-08-04 10:28:23,059 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050231, Speed: 637.062737 images/s
2022-08-04 10:28:23,229 [dl_trainer.py:731] WARNING [128][25200/  196][rank:0] loss: 0.076, average forward (0.009918) and backward (0.022258) time: 0.033910, iotime: 0.001473 
2022-08-04 10:28:24,978 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047934, Speed: 667.587394 images/s
2022-08-04 10:28:25,150 [dl_trainer.py:731] WARNING [128][25240/  196][rank:0] loss: 0.014, average forward (0.009718) and backward (0.022398) time: 0.033825, iotime: 0.001456 
2022-08-04 10:28:26,858 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046988, Speed: 681.031098 images/s
2022-08-04 10:28:27,038 [dl_trainer.py:731] WARNING [128][25280/  196][rank:0] loss: 0.019, average forward (0.011535) and backward (0.019871) time: 0.033285, iotime: 0.001601 
2022-08-04 10:28:27,233 [dl_trainer.py:634] INFO train iter: 25284, num_batches_per_epoch: 196
2022-08-04 10:28:27,233 [dl_trainer.py:635] INFO Epoch 129, avg train acc: 98.660714, lr: 0.001000, avg loss: 0.036045
2022-08-04 10:28:29,903 [dl_trainer.py:822] INFO Epoch 129, lr: 0.001000, val loss: 0.369790, val top-1 acc: 91.014377, top-5 acc: 99.690495
2022-08-04 10:28:31,424 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114156, Speed: 280.317835 images/s
2022-08-04 10:28:31,604 [dl_trainer.py:731] WARNING [129][25320/  196][rank:0] loss: 0.025, average forward (0.009753) and backward (0.021474) time: 0.099727, iotime: 0.001452 
2022-08-04 10:28:33,010 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:28:33,010 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:28:33,627 [dl_trainer.py:731] WARNING [129][25360/  196][rank:0] loss: 0.012, average forward (0.010563) and backward (0.019098) time: 0.035520, iotime: 0.005550 
2022-08-04 10:28:35,075 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048659, Speed: 657.636338 images/s
2022-08-04 10:28:35,477 [dl_trainer.py:731] WARNING [129][25400/  196][rank:0] loss: 0.053, average forward (0.009780) and backward (0.020441) time: 0.031959, iotime: 0.001478 
2022-08-04 10:28:36,930 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046353, Speed: 690.356933 images/s
2022-08-04 10:28:37,329 [dl_trainer.py:731] WARNING [129][25440/  196][rank:0] loss: 0.039, average forward (0.010054) and backward (0.018527) time: 0.030384, iotime: 0.001537 
2022-08-04 10:28:38,821 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047263, Speed: 677.062105 images/s
2022-08-04 10:28:39,211 [dl_trainer.py:731] WARNING [129][25480/  196][rank:0] loss: 0.012, average forward (0.009526) and backward (0.019078) time: 0.030282, iotime: 0.001435 
2022-08-04 10:28:39,225 [dl_trainer.py:634] INFO train iter: 25480, num_batches_per_epoch: 196
2022-08-04 10:28:39,226 [dl_trainer.py:635] INFO Epoch 130, avg train acc: 98.995536, lr: 0.001000, avg loss: 0.033974
2022-08-04 10:28:41,854 [dl_trainer.py:822] INFO Epoch 130, lr: 0.001000, val loss: 0.365220, val top-1 acc: 91.054313, top-5 acc: 99.710463
2022-08-04 10:28:43,346 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113112, Speed: 282.905880 images/s
2022-08-04 10:28:43,779 [dl_trainer.py:731] WARNING [130][25520/  196][rank:0] loss: 0.005, average forward (0.013055) and backward (0.022344) time: 0.104448, iotime: 0.001814 
2022-08-04 10:28:44,972 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:28:44,972 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:28:45,816 [dl_trainer.py:731] WARNING [130][25560/  196][rank:0] loss: 0.010, average forward (0.010200) and backward (0.021679) time: 0.037401, iotime: 0.005260 
2022-08-04 10:28:47,029 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049076, Speed: 652.051053 images/s
2022-08-04 10:28:47,671 [dl_trainer.py:731] WARNING [130][25600/  196][rank:0] loss: 0.069, average forward (0.009956) and backward (0.021037) time: 0.032710, iotime: 0.001467 
2022-08-04 10:28:48,843 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045319, Speed: 706.104634 images/s
2022-08-04 10:28:49,455 [dl_trainer.py:731] WARNING [130][25640/  196][rank:0] loss: 0.095, average forward (0.009353) and backward (0.019727) time: 0.030800, iotime: 0.001477 
2022-08-04 10:28:50,725 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047025, Speed: 680.485291 images/s
2022-08-04 10:28:51,181 [dl_trainer.py:634] INFO train iter: 25676, num_batches_per_epoch: 196
2022-08-04 10:28:51,182 [dl_trainer.py:635] INFO Epoch 131, avg train acc: 98.628827, lr: 0.001000, avg loss: 0.037792
2022-08-04 10:28:53,844 [dl_trainer.py:822] INFO Epoch 131, lr: 0.001000, val loss: 0.364690, val top-1 acc: 91.124201, top-5 acc: 99.660543
2022-08-04 10:28:54,021 [dl_trainer.py:731] WARNING [131][25680/  196][rank:0] loss: 0.020, average forward (0.011011) and backward (0.021987) time: 0.101564, iotime: 0.001662 
2022-08-04 10:28:55,268 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113564, Speed: 281.779919 images/s
2022-08-04 10:28:55,923 [dl_trainer.py:731] WARNING [131][25720/  196][rank:0] loss: 0.027, average forward (0.010427) and backward (0.021068) time: 0.033279, iotime: 0.001495 
2022-08-04 10:28:56,910 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:28:56,910 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:28:58,026 [dl_trainer.py:731] WARNING [131][25760/  196][rank:0] loss: 0.007, average forward (0.010518) and backward (0.020802) time: 0.036739, iotime: 0.005152 
2022-08-04 10:28:59,026 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050080, Speed: 638.980265 images/s
2022-08-04 10:28:59,895 [dl_trainer.py:731] WARNING [131][25800/  196][rank:0] loss: 0.044, average forward (0.010522) and backward (0.021745) time: 0.034161, iotime: 0.001637 
2022-08-04 10:29:00,912 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047137, Speed: 678.870447 images/s
2022-08-04 10:29:01,841 [dl_trainer.py:731] WARNING [131][25840/  196][rank:0] loss: 0.018, average forward (0.010532) and backward (0.021742) time: 0.034134, iotime: 0.001579 
2022-08-04 10:29:02,846 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048344, Speed: 661.927236 images/s
2022-08-04 10:29:03,351 [dl_trainer.py:634] INFO train iter: 25872, num_batches_per_epoch: 196
2022-08-04 10:29:03,352 [dl_trainer.py:635] INFO Epoch 132, avg train acc: 98.867985, lr: 0.001000, avg loss: 0.037665
2022-08-04 10:29:05,977 [dl_trainer.py:822] INFO Epoch 132, lr: 0.001000, val loss: 0.366476, val top-1 acc: 91.014377, top-5 acc: 99.660543
2022-08-04 10:29:06,356 [dl_trainer.py:731] WARNING [132][25880/  196][rank:0] loss: 0.114, average forward (0.011416) and backward (0.020324) time: 0.099821, iotime: 0.001672 
2022-08-04 10:29:07,409 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114057, Speed: 280.561859 images/s
2022-08-04 10:29:08,270 [dl_trainer.py:731] WARNING [132][25920/  196][rank:0] loss: 0.047, average forward (0.012794) and backward (0.020853) time: 0.035706, iotime: 0.001774 
2022-08-04 10:29:08,978 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:29:08,979 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:29:10,299 [dl_trainer.py:731] WARNING [132][25960/  196][rank:0] loss: 0.059, average forward (0.010394) and backward (0.019274) time: 0.035530, iotime: 0.005577 
2022-08-04 10:29:11,077 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048876, Speed: 654.723137 images/s
2022-08-04 10:29:12,218 [dl_trainer.py:731] WARNING [132][26000/  196][rank:0] loss: 0.014, average forward (0.011316) and backward (0.021694) time: 0.034874, iotime: 0.001585 
2022-08-04 10:29:13,018 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048499, Speed: 659.812689 images/s
2022-08-04 10:29:14,162 [dl_trainer.py:731] WARNING [132][26040/  196][rank:0] loss: 0.007, average forward (0.010594) and backward (0.021745) time: 0.034229, iotime: 0.001626 
2022-08-04 10:29:14,955 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048406, Speed: 661.073948 images/s
2022-08-04 10:29:15,520 [dl_trainer.py:634] INFO train iter: 26068, num_batches_per_epoch: 196
2022-08-04 10:29:15,520 [dl_trainer.py:635] INFO Epoch 133, avg train acc: 98.867985, lr: 0.001000, avg loss: 0.036278
2022-08-04 10:29:18,207 [dl_trainer.py:822] INFO Epoch 133, lr: 0.001000, val loss: 0.364870, val top-1 acc: 91.204073, top-5 acc: 99.720447
2022-08-04 10:29:18,754 [dl_trainer.py:731] WARNING [133][26080/  196][rank:0] loss: 0.020, average forward (0.009426) and backward (0.019946) time: 0.098402, iotime: 0.001505 
2022-08-04 10:29:19,529 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114326, Speed: 279.900765 images/s
2022-08-04 10:29:20,683 [dl_trainer.py:731] WARNING [133][26120/  196][rank:0] loss: 0.045, average forward (0.010442) and backward (0.022372) time: 0.034686, iotime: 0.001613 
2022-08-04 10:29:21,163 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:29:21,163 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:29:22,767 [dl_trainer.py:731] WARNING [133][26160/  196][rank:0] loss: 0.062, average forward (0.009559) and backward (0.019966) time: 0.034992, iotime: 0.005202 
2022-08-04 10:29:23,290 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050131, Speed: 638.331833 images/s
2022-08-04 10:29:24,679 [dl_trainer.py:731] WARNING [133][26200/  196][rank:0] loss: 0.066, average forward (0.009871) and backward (0.019829) time: 0.031388, iotime: 0.001453 
2022-08-04 10:29:25,215 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048108, Speed: 665.168474 images/s
2022-08-04 10:29:26,579 [dl_trainer.py:731] WARNING [133][26240/  196][rank:0] loss: 0.001, average forward (0.010249) and backward (0.021386) time: 0.033333, iotime: 0.001455 
2022-08-04 10:29:27,107 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047287, Speed: 676.712800 images/s
2022-08-04 10:29:27,740 [dl_trainer.py:634] INFO train iter: 26264, num_batches_per_epoch: 196
2022-08-04 10:29:27,740 [dl_trainer.py:635] INFO Epoch 134, avg train acc: 98.804209, lr: 0.001000, avg loss: 0.034158
2022-08-04 10:29:30,366 [dl_trainer.py:822] INFO Epoch 134, lr: 0.001000, val loss: 0.367965, val top-1 acc: 91.034345, top-5 acc: 99.650559
2022-08-04 10:29:31,111 [dl_trainer.py:731] WARNING [134][26280/  196][rank:0] loss: 0.139, average forward (0.010772) and backward (0.021622) time: 0.100308, iotime: 0.001523 
2022-08-04 10:29:31,658 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113777, Speed: 281.251246 images/s
2022-08-04 10:29:33,009 [dl_trainer.py:731] WARNING [134][26320/  196][rank:0] loss: 0.057, average forward (0.009167) and backward (0.021549) time: 0.032409, iotime: 0.001457 
2022-08-04 10:29:33,242 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:29:33,243 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:29:35,020 [dl_trainer.py:731] WARNING [134][26360/  196][rank:0] loss: 0.042, average forward (0.010385) and backward (0.019493) time: 0.035141, iotime: 0.005002 
2022-08-04 10:29:35,321 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048806, Speed: 655.655258 images/s
2022-08-04 10:29:36,894 [dl_trainer.py:731] WARNING [134][26400/  196][rank:0] loss: 0.033, average forward (0.009512) and backward (0.017469) time: 0.028732, iotime: 0.001503 
2022-08-04 10:29:37,216 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047364, Speed: 675.624785 images/s
2022-08-04 10:29:38,750 [dl_trainer.py:731] WARNING [134][26440/  196][rank:0] loss: 0.035, average forward (0.010175) and backward (0.018556) time: 0.030534, iotime: 0.001534 
2022-08-04 10:29:39,043 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045648, Speed: 701.016342 images/s
2022-08-04 10:29:39,745 [dl_trainer.py:634] INFO train iter: 26460, num_batches_per_epoch: 196
2022-08-04 10:29:39,745 [dl_trainer.py:635] INFO Epoch 135, avg train acc: 98.867985, lr: 0.001000, avg loss: 0.037517
2022-08-04 10:29:42,378 [dl_trainer.py:822] INFO Epoch 135, lr: 0.001000, val loss: 0.371947, val top-1 acc: 91.054313, top-5 acc: 99.670527
2022-08-04 10:29:43,340 [dl_trainer.py:731] WARNING [135][26480/  196][rank:0] loss: 0.010, average forward (0.009567) and backward (0.020086) time: 0.097358, iotime: 0.001531 
2022-08-04 10:29:43,637 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114845, Speed: 278.636607 images/s
2022-08-04 10:29:45,242 [dl_trainer.py:731] WARNING [135][26520/  196][rank:0] loss: 0.055, average forward (0.008973) and backward (0.020249) time: 0.030831, iotime: 0.001376 
2022-08-04 10:29:45,255 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:29:45,255 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:29:47,260 [dl_trainer.py:731] WARNING [135][26560/  196][rank:0] loss: 0.010, average forward (0.010865) and backward (0.020125) time: 0.036678, iotime: 0.005408 
2022-08-04 10:29:47,308 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048931, Speed: 653.979703 images/s
2022-08-04 10:29:49,132 [dl_trainer.py:731] WARNING [135][26600/  196][rank:0] loss: 0.009, average forward (0.010219) and backward (0.021628) time: 0.033595, iotime: 0.001487 
2022-08-04 10:29:49,198 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047233, Speed: 677.495717 images/s
2022-08-04 10:29:51,044 [dl_trainer.py:731] WARNING [135][26640/  196][rank:0] loss: 0.008, average forward (0.012052) and backward (0.021559) time: 0.035697, iotime: 0.001769 
2022-08-04 10:29:51,117 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047963, Speed: 667.186350 images/s
2022-08-04 10:29:51,842 [dl_trainer.py:634] INFO train iter: 26656, num_batches_per_epoch: 196
2022-08-04 10:29:51,842 [dl_trainer.py:635] INFO Epoch 136, avg train acc: 98.931760, lr: 0.001000, avg loss: 0.032364
2022-08-04 10:29:54,476 [dl_trainer.py:822] INFO Epoch 136, lr: 0.001000, val loss: 0.372043, val top-1 acc: 91.024361, top-5 acc: 99.630591
2022-08-04 10:29:55,652 [dl_trainer.py:731] WARNING [136][26680/  196][rank:0] loss: 0.004, average forward (0.011285) and backward (0.023013) time: 0.102320, iotime: 0.001578 
2022-08-04 10:29:55,720 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115061, Speed: 278.112448 images/s
2022-08-04 10:29:57,332 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:29:57,332 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:29:57,707 [dl_trainer.py:731] WARNING [136][26720/  196][rank:0] loss: 0.018, average forward (0.009823) and backward (0.021092) time: 0.036921, iotime: 0.005730 
2022-08-04 10:29:59,397 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049018, Speed: 652.815380 images/s
2022-08-04 10:29:59,579 [dl_trainer.py:731] WARNING [136][26760/  196][rank:0] loss: 0.012, average forward (0.009305) and backward (0.020009) time: 0.030962, iotime: 0.001407 
2022-08-04 10:30:01,309 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047768, Speed: 669.905838 images/s
2022-08-04 10:30:01,487 [dl_trainer.py:731] WARNING [136][26800/  196][rank:0] loss: 0.023, average forward (0.012183) and backward (0.020534) time: 0.034727, iotime: 0.001730 
2022-08-04 10:30:03,179 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046732, Speed: 684.753233 images/s
2022-08-04 10:30:03,357 [dl_trainer.py:731] WARNING [136][26840/  196][rank:0] loss: 0.033, average forward (0.009953) and backward (0.021973) time: 0.033768, iotime: 0.001516 
2022-08-04 10:30:03,957 [dl_trainer.py:634] INFO train iter: 26852, num_batches_per_epoch: 196
2022-08-04 10:30:03,957 [dl_trainer.py:635] INFO Epoch 137, avg train acc: 98.915816, lr: 0.001000, avg loss: 0.037158
2022-08-04 10:30:06,574 [dl_trainer.py:822] INFO Epoch 137, lr: 0.001000, val loss: 0.365044, val top-1 acc: 91.244010, top-5 acc: 99.710463
2022-08-04 10:30:07,725 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113630, Speed: 281.616798 images/s
2022-08-04 10:30:07,897 [dl_trainer.py:731] WARNING [137][26880/  196][rank:0] loss: 0.020, average forward (0.009461) and backward (0.021326) time: 0.097997, iotime: 0.001460 
2022-08-04 10:30:09,348 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:30:09,349 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:30:09,937 [dl_trainer.py:731] WARNING [137][26920/  196][rank:0] loss: 0.017, average forward (0.011144) and backward (0.020117) time: 0.037177, iotime: 0.005620 
2022-08-04 10:30:11,350 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048306, Speed: 662.437166 images/s
2022-08-04 10:30:11,755 [dl_trainer.py:731] WARNING [137][26960/  196][rank:0] loss: 0.023, average forward (0.009047) and backward (0.020637) time: 0.031327, iotime: 0.001409 
2022-08-04 10:30:13,255 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047590, Speed: 672.412620 images/s
2022-08-04 10:30:13,670 [dl_trainer.py:731] WARNING [137][27000/  196][rank:0] loss: 0.114, average forward (0.010005) and backward (0.017763) time: 0.029554, iotime: 0.001520 
2022-08-04 10:30:15,169 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047855, Speed: 668.682803 images/s
2022-08-04 10:30:15,570 [dl_trainer.py:731] WARNING [137][27040/  196][rank:0] loss: 0.011, average forward (0.009177) and backward (0.018897) time: 0.029755, iotime: 0.001433 
2022-08-04 10:30:15,977 [dl_trainer.py:634] INFO train iter: 27048, num_batches_per_epoch: 196
2022-08-04 10:30:15,977 [dl_trainer.py:635] INFO Epoch 138, avg train acc: 98.756378, lr: 0.001000, avg loss: 0.037057
2022-08-04 10:30:18,634 [dl_trainer.py:822] INFO Epoch 138, lr: 0.001000, val loss: 0.367203, val top-1 acc: 91.104233, top-5 acc: 99.730431
2022-08-04 10:30:19,687 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112932, Speed: 283.357337 images/s
2022-08-04 10:30:20,119 [dl_trainer.py:731] WARNING [138][27080/  196][rank:0] loss: 0.024, average forward (0.009526) and backward (0.021334) time: 0.099298, iotime: 0.001458 
2022-08-04 10:30:21,291 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:30:21,291 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:30:22,145 [dl_trainer.py:731] WARNING [138][27120/  196][rank:0] loss: 0.003, average forward (0.010948) and backward (0.019409) time: 0.036102, iotime: 0.005463 
2022-08-04 10:30:23,423 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049791, Speed: 642.682379 images/s
2022-08-04 10:30:24,090 [dl_trainer.py:731] WARNING [138][27160/  196][rank:0] loss: 0.052, average forward (0.011174) and backward (0.022797) time: 0.035877, iotime: 0.001633 
2022-08-04 10:30:25,347 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048069, Speed: 665.706569 images/s
2022-08-04 10:30:25,974 [dl_trainer.py:731] WARNING [138][27200/  196][rank:0] loss: 0.003, average forward (0.009753) and backward (0.022191) time: 0.033654, iotime: 0.001476 
2022-08-04 10:30:27,261 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047841, Speed: 668.883582 images/s
2022-08-04 10:30:27,926 [dl_trainer.py:731] WARNING [138][27240/  196][rank:0] loss: 0.111, average forward (0.010315) and backward (0.020886) time: 0.033041, iotime: 0.001570 
2022-08-04 10:30:28,116 [dl_trainer.py:634] INFO train iter: 27244, num_batches_per_epoch: 196
2022-08-04 10:30:28,116 [dl_trainer.py:635] INFO Epoch 139, avg train acc: 98.963648, lr: 0.001000, avg loss: 0.031561
2022-08-04 10:30:30,738 [dl_trainer.py:822] INFO Epoch 139, lr: 0.001000, val loss: 0.370111, val top-1 acc: 91.154153, top-5 acc: 99.680511
2022-08-04 10:30:31,766 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112612, Speed: 284.162380 images/s
2022-08-04 10:30:32,428 [dl_trainer.py:731] WARNING [139][27280/  196][rank:0] loss: 0.024, average forward (0.011692) and backward (0.021168) time: 0.100415, iotime: 0.001658 
2022-08-04 10:30:33,414 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:30:33,415 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:30:34,537 [dl_trainer.py:731] WARNING [139][27320/  196][rank:0] loss: 0.012, average forward (0.011041) and backward (0.021019) time: 0.037658, iotime: 0.005293 
2022-08-04 10:30:35,538 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.050280, Speed: 636.437946 images/s
2022-08-04 10:30:36,422 [dl_trainer.py:731] WARNING [139][27360/  196][rank:0] loss: 0.033, average forward (0.011253) and backward (0.016922) time: 0.029988, iotime: 0.001542 
2022-08-04 10:30:37,393 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046333, Speed: 690.647163 images/s
2022-08-04 10:30:38,305 [dl_trainer.py:731] WARNING [139][27400/  196][rank:0] loss: 0.024, average forward (0.009519) and backward (0.019403) time: 0.030643, iotime: 0.001463 
2022-08-04 10:30:39,319 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048156, Speed: 664.505385 images/s
2022-08-04 10:30:40,197 [dl_trainer.py:731] WARNING [139][27440/  196][rank:0] loss: 0.062, average forward (0.010712) and backward (0.017876) time: 0.030383, iotime: 0.001538 
2022-08-04 10:30:40,215 [dl_trainer.py:634] INFO train iter: 27440, num_batches_per_epoch: 196
2022-08-04 10:30:40,215 [dl_trainer.py:635] INFO Epoch 140, avg train acc: 99.091199, lr: 0.001000, avg loss: 0.031292
2022-08-04 10:30:42,864 [dl_trainer.py:822] INFO Epoch 140, lr: 0.001000, val loss: 0.371911, val top-1 acc: 91.094249, top-5 acc: 99.680511
2022-08-04 10:30:43,916 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114919, Speed: 278.457735 images/s
2022-08-04 10:30:44,804 [dl_trainer.py:731] WARNING [140][27480/  196][rank:0] loss: 0.021, average forward (0.008984) and backward (0.018821) time: 0.096430, iotime: 0.001353 
2022-08-04 10:30:45,554 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:30:45,554 [distributed_optimizer.py:143] INFO The number of selected gradients: []
