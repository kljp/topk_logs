2022-08-04 09:34:04,259 [dist_trainer.py:135] INFO Configurations: Namespace(batch_size=32, compressor='topk', data_dir='./data', dataset='cifar10', density=1.0, dnn='resnet20', lr=0.01, max_epochs=141, nsteps_update=1, num_steps=35, nworkers=8, nwpernode=8, pretrain=None, saved_dir='./logs/iclr', threshold=524288000)
2022-08-04 09:34:36,966 [dl_trainer.py:254] INFO num_batches_per_epoch: 196
2022-08-04 09:34:37,154 [distributed_optimizer.py:63] INFO _dynamic_densities: [0.015625, 0.004, 0.001]
2022-08-04 09:34:37,158 [distributed_optimizer.py:323] INFO # of parameters: 269722
2022-08-04 09:34:37,158 [distributed_optimizer.py:324] INFO Total number of tensors: 59
2022-08-04 09:34:37,158 [distributed_optimizer.py:325] INFO Merged Number of groups: 1
2022-08-04 09:34:38,005 [dist_trainer.py:62] INFO max_epochs: 141
2022-08-04 09:34:42,378 [dl_trainer.py:731] WARNING [  0][   40/  196][rank:0] loss: 2.419, average forward (0.068381) and backward (0.023184) time: 0.093624, iotime: 0.001467 
2022-08-04 09:34:42,444 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.108238, Speed: 295.645261 images/s
2022-08-04 09:34:44,150 [dl_trainer.py:731] WARNING [  0][   80/  196][rank:0] loss: 2.139, average forward (0.008558) and backward (0.020112) time: 0.030240, iotime: 0.001352 
2022-08-04 09:34:44,206 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044058, Speed: 726.312543 images/s
2022-08-04 09:34:45,971 [dl_trainer.py:731] WARNING [  0][  120/  196][rank:0] loss: 2.179, average forward (0.009062) and backward (0.020887) time: 0.031564, iotime: 0.001382 
2022-08-04 09:34:46,046 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045973, Speed: 696.055182 images/s
2022-08-04 09:34:47,768 [dl_trainer.py:731] WARNING [  0][  160/  196][rank:0] loss: 1.875, average forward (0.009270) and backward (0.019965) time: 0.030880, iotime: 0.001411 
2022-08-04 09:34:47,844 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044955, Speed: 711.816653 images/s
2022-08-04 09:34:49,349 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 1078
2022-08-04 09:34:49,350 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:34:49,522 [dl_trainer.py:634] INFO train iter: 196, num_batches_per_epoch: 196
2022-08-04 09:34:49,523 [dl_trainer.py:635] INFO Epoch 1, avg train acc: 25.127551, lr: 0.002008, avg loss: 2.179628
2022-08-04 09:34:52,188 [dl_trainer.py:822] INFO Epoch 1, lr: 0.002008, val loss: 1.704798, val top-1 acc: 36.970847, top-5 acc: 88.508387
2022-08-04 09:34:52,363 [dl_trainer.py:731] WARNING [  1][  200/  196][rank:0] loss: 1.765, average forward (0.009391) and backward (0.018025) time: 0.098815, iotime: 0.004432 
2022-08-04 09:34:53,815 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.079528, Speed: 402.371540 images/s
2022-08-04 09:34:53,981 [dl_trainer.py:731] WARNING [  1][  240/  196][rank:0] loss: 1.700, average forward (0.009605) and backward (0.016585) time: 0.027742, iotime: 0.001319 
2022-08-04 09:34:55,545 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043251, Speed: 739.868988 images/s
2022-08-04 09:34:55,703 [dl_trainer.py:731] WARNING [  1][  280/  196][rank:0] loss: 1.686, average forward (0.009517) and backward (0.016243) time: 0.027337, iotime: 0.001349 
2022-08-04 09:34:57,206 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041504, Speed: 771.011654 images/s
2022-08-04 09:34:57,370 [dl_trainer.py:731] WARNING [  1][  320/  196][rank:0] loss: 1.562, average forward (0.008826) and backward (0.016686) time: 0.027022, iotime: 0.001281 
2022-08-04 09:34:58,967 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044019, Speed: 726.953666 images/s
2022-08-04 09:34:59,119 [dl_trainer.py:731] WARNING [  1][  360/  196][rank:0] loss: 1.692, average forward (0.010184) and backward (0.020316) time: 0.032220, iotime: 0.001468 
2022-08-04 09:35:00,506 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:35:00,506 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:35:00,756 [dl_trainer.py:634] INFO train iter: 392, num_batches_per_epoch: 196
2022-08-04 09:35:00,757 [dl_trainer.py:635] INFO Epoch 2, avg train acc: 41.693240, lr: 0.004006, avg loss: 1.577291
2022-08-04 09:35:03,414 [dl_trainer.py:822] INFO Epoch 2, lr: 0.004006, val loss: 1.477231, val top-1 acc: 46.305911, top-5 acc: 92.961262
2022-08-04 09:35:03,824 [dl_trainer.py:731] WARNING [  2][  400/  196][rank:0] loss: 1.407, average forward (0.009720) and backward (0.019171) time: 0.101995, iotime: 0.005271 
2022-08-04 09:35:05,241 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083637, Speed: 382.606617 images/s
2022-08-04 09:35:05,643 [dl_trainer.py:731] WARNING [  2][  440/  196][rank:0] loss: 1.204, average forward (0.009585) and backward (0.018333) time: 0.029585, iotime: 0.001421 
2022-08-04 09:35:06,996 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043867, Speed: 729.483522 images/s
2022-08-04 09:35:07,376 [dl_trainer.py:731] WARNING [  2][  480/  196][rank:0] loss: 1.720, average forward (0.009540) and backward (0.019437) time: 0.030636, iotime: 0.001421 
2022-08-04 09:35:08,721 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043099, Speed: 742.470291 images/s
2022-08-04 09:35:09,084 [dl_trainer.py:731] WARNING [  2][  520/  196][rank:0] loss: 1.346, average forward (0.008723) and backward (0.017749) time: 0.027957, iotime: 0.001264 
2022-08-04 09:35:10,519 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044960, Speed: 711.750124 images/s
2022-08-04 09:35:10,928 [dl_trainer.py:731] WARNING [  2][  560/  196][rank:0] loss: 1.306, average forward (0.010572) and backward (0.019792) time: 0.032098, iotime: 0.001457 
2022-08-04 09:35:12,067 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:35:12,067 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:35:12,369 [dl_trainer.py:634] INFO train iter: 588, num_batches_per_epoch: 196
2022-08-04 09:35:12,370 [dl_trainer.py:635] INFO Epoch 3, avg train acc: 52.710459, lr: 0.006004, avg loss: 1.299129
2022-08-04 09:35:15,041 [dl_trainer.py:822] INFO Epoch 3, lr: 0.006004, val loss: 1.266517, val top-1 acc: 55.191693, top-5 acc: 95.167732
2022-08-04 09:35:15,573 [dl_trainer.py:731] WARNING [  3][  600/  196][rank:0] loss: 1.228, average forward (0.009423) and backward (0.018757) time: 0.100517, iotime: 0.005199 
2022-08-04 09:35:16,749 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083035, Speed: 385.380256 images/s
2022-08-04 09:35:17,335 [dl_trainer.py:731] WARNING [  3][  640/  196][rank:0] loss: 1.121, average forward (0.009639) and backward (0.019338) time: 0.030592, iotime: 0.001361 
2022-08-04 09:35:18,562 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045321, Speed: 706.073710 images/s
2022-08-04 09:35:19,231 [dl_trainer.py:731] WARNING [  3][  680/  196][rank:0] loss: 1.127, average forward (0.010413) and backward (0.018713) time: 0.030849, iotime: 0.001478 
2022-08-04 09:35:20,496 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048334, Speed: 662.054248 images/s
2022-08-04 09:35:21,115 [dl_trainer.py:731] WARNING [  3][  720/  196][rank:0] loss: 1.116, average forward (0.010607) and backward (0.019059) time: 0.031432, iotime: 0.001514 
2022-08-04 09:35:22,300 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045107, Speed: 709.427897 images/s
2022-08-04 09:35:22,878 [dl_trainer.py:731] WARNING [  3][  760/  196][rank:0] loss: 1.173, average forward (0.009407) and backward (0.019647) time: 0.030626, iotime: 0.001337 
2022-08-04 09:35:23,682 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:35:23,683 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:35:24,001 [dl_trainer.py:634] INFO train iter: 784, num_batches_per_epoch: 196
2022-08-04 09:35:24,002 [dl_trainer.py:635] INFO Epoch 4, avg train acc: 61.320153, lr: 0.008002, avg loss: 1.082059
2022-08-04 09:35:26,626 [dl_trainer.py:822] INFO Epoch 4, lr: 0.008002, val loss: 1.393154, val top-1 acc: 56.529553, top-5 acc: 93.350639
2022-08-04 09:35:27,281 [dl_trainer.py:731] WARNING [  4][  800/  196][rank:0] loss: 1.037, average forward (0.010343) and backward (0.017155) time: 0.098969, iotime: 0.005247 
2022-08-04 09:35:28,197 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.078612, Speed: 407.063900 images/s
2022-08-04 09:35:28,960 [dl_trainer.py:731] WARNING [  4][  840/  196][rank:0] loss: 0.801, average forward (0.009487) and backward (0.016940) time: 0.028046, iotime: 0.001390 
2022-08-04 09:35:29,833 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040891, Speed: 782.568793 images/s
2022-08-04 09:35:30,648 [dl_trainer.py:731] WARNING [  4][  880/  196][rank:0] loss: 0.824, average forward (0.011094) and backward (0.016441) time: 0.029498, iotime: 0.001702 
2022-08-04 09:35:31,558 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043109, Speed: 742.302138 images/s
2022-08-04 09:35:32,431 [dl_trainer.py:731] WARNING [  4][  920/  196][rank:0] loss: 0.916, average forward (0.009991) and backward (0.018871) time: 0.030618, iotime: 0.001506 
2022-08-04 09:35:33,387 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045714, Speed: 700.002415 images/s
2022-08-04 09:35:34,170 [dl_trainer.py:731] WARNING [  4][  960/  196][rank:0] loss: 1.075, average forward (0.009567) and backward (0.019523) time: 0.030723, iotime: 0.001399 
2022-08-04 09:35:34,828 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:35:34,829 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:35:35,213 [dl_trainer.py:634] INFO train iter: 980, num_batches_per_epoch: 196
2022-08-04 09:35:35,214 [dl_trainer.py:635] INFO Epoch 5, avg train acc: 65.640944, lr: 0.010000, avg loss: 0.951485
2022-08-04 09:35:37,892 [dl_trainer.py:822] INFO Epoch 5, lr: 0.010000, val loss: 1.071929, val top-1 acc: 64.327077, top-5 acc: 95.936502
2022-08-04 09:35:38,739 [dl_trainer.py:731] WARNING [  5][ 1000/  196][rank:0] loss: 1.081, average forward (0.009503) and backward (0.017972) time: 0.099881, iotime: 0.005096 
2022-08-04 09:35:39,409 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.080283, Speed: 398.588948 images/s
2022-08-04 09:35:40,444 [dl_trainer.py:731] WARNING [  5][ 1040/  196][rank:0] loss: 0.952, average forward (0.009163) and backward (0.018128) time: 0.028902, iotime: 0.001385 
2022-08-04 09:35:41,179 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044222, Speed: 723.620016 images/s
2022-08-04 09:35:42,195 [dl_trainer.py:731] WARNING [  5][ 1080/  196][rank:0] loss: 0.899, average forward (0.009295) and backward (0.017342) time: 0.028255, iotime: 0.001374 
2022-08-04 09:35:42,921 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043553, Speed: 734.742707 images/s
2022-08-04 09:35:43,999 [dl_trainer.py:731] WARNING [  5][ 1120/  196][rank:0] loss: 0.791, average forward (0.010608) and backward (0.018634) time: 0.030991, iotime: 0.001501 
2022-08-04 09:35:44,754 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045800, Speed: 698.687677 images/s
2022-08-04 09:35:45,867 [dl_trainer.py:731] WARNING [  5][ 1160/  196][rank:0] loss: 0.636, average forward (0.009363) and backward (0.019009) time: 0.030003, iotime: 0.001398 
2022-08-04 09:35:46,379 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:35:46,379 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:35:46,803 [dl_trainer.py:634] INFO train iter: 1176, num_batches_per_epoch: 196
2022-08-04 09:35:46,804 [dl_trainer.py:635] INFO Epoch 6, avg train acc: 70.838648, lr: 0.010000, avg loss: 0.838168
2022-08-04 09:35:49,431 [dl_trainer.py:822] INFO Epoch 6, lr: 0.010000, val loss: 0.890987, val top-1 acc: 68.909744, top-5 acc: 97.843450
2022-08-04 09:35:50,512 [dl_trainer.py:731] WARNING [  6][ 1200/  196][rank:0] loss: 0.889, average forward (0.009211) and backward (0.020711) time: 0.101381, iotime: 0.004982 
2022-08-04 09:35:50,991 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083150, Speed: 384.845196 images/s
2022-08-04 09:35:52,275 [dl_trainer.py:731] WARNING [  6][ 1240/  196][rank:0] loss: 0.530, average forward (0.009834) and backward (0.018469) time: 0.029924, iotime: 0.001370 
2022-08-04 09:35:52,812 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045525, Speed: 702.907137 images/s
2022-08-04 09:35:54,212 [dl_trainer.py:731] WARNING [  6][ 1280/  196][rank:0] loss: 1.038, average forward (0.011494) and backward (0.020730) time: 0.034125, iotime: 0.001628 
2022-08-04 09:35:54,765 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048810, Speed: 655.606413 images/s
2022-08-04 09:35:56,098 [dl_trainer.py:731] WARNING [  6][ 1320/  196][rank:0] loss: 1.032, average forward (0.009580) and backward (0.020656) time: 0.031914, iotime: 0.001430 
2022-08-04 09:35:56,591 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045624, Speed: 701.381390 images/s
2022-08-04 09:35:57,944 [dl_trainer.py:731] WARNING [  6][ 1360/  196][rank:0] loss: 0.545, average forward (0.009043) and backward (0.019200) time: 0.029796, iotime: 0.001318 
2022-08-04 09:35:58,180 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:35:58,180 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:35:58,655 [dl_trainer.py:634] INFO train iter: 1372, num_batches_per_epoch: 196
2022-08-04 09:35:58,656 [dl_trainer.py:635] INFO Epoch 7, avg train acc: 74.170918, lr: 0.010000, avg loss: 0.734251
2022-08-04 09:36:01,360 [dl_trainer.py:822] INFO Epoch 7, lr: 0.010000, val loss: 0.866577, val top-1 acc: 71.255990, top-5 acc: 97.643770
2022-08-04 09:36:02,520 [dl_trainer.py:731] WARNING [  7][ 1400/  196][rank:0] loss: 0.959, average forward (0.009720) and backward (0.016596) time: 0.099710, iotime: 0.005420 
2022-08-04 09:36:02,776 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082444, Speed: 388.140292 images/s
2022-08-04 09:36:04,284 [dl_trainer.py:731] WARNING [  7][ 1440/  196][rank:0] loss: 0.482, average forward (0.009127) and backward (0.017601) time: 0.028339, iotime: 0.001377 
2022-08-04 09:36:04,571 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044863, Speed: 713.277298 images/s
2022-08-04 09:36:06,095 [dl_trainer.py:731] WARNING [  7][ 1480/  196][rank:0] loss: 0.657, average forward (0.010163) and backward (0.018616) time: 0.030427, iotime: 0.001415 
2022-08-04 09:36:06,375 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045083, Speed: 709.802793 images/s
2022-08-04 09:36:07,912 [dl_trainer.py:731] WARNING [  7][ 1520/  196][rank:0] loss: 0.627, average forward (0.010355) and backward (0.018914) time: 0.031037, iotime: 0.001522 
2022-08-04 09:36:08,215 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046004, Speed: 695.587042 images/s
2022-08-04 09:36:09,758 [dl_trainer.py:731] WARNING [  7][ 1560/  196][rank:0] loss: 0.687, average forward (0.009140) and backward (0.019148) time: 0.029952, iotime: 0.001434 
2022-08-04 09:36:09,771 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:36:09,771 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:36:10,292 [dl_trainer.py:634] INFO train iter: 1568, num_batches_per_epoch: 196
2022-08-04 09:36:10,293 [dl_trainer.py:635] INFO Epoch 8, avg train acc: 75.892857, lr: 0.010000, avg loss: 0.689648
2022-08-04 09:36:12,983 [dl_trainer.py:822] INFO Epoch 8, lr: 0.010000, val loss: 0.876938, val top-1 acc: 71.655351, top-5 acc: 97.783546
2022-08-04 09:36:14,470 [dl_trainer.py:731] WARNING [  8][ 1600/  196][rank:0] loss: 0.670, average forward (0.009339) and backward (0.019111) time: 0.101681, iotime: 0.005189 
2022-08-04 09:36:14,541 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084334, Speed: 379.443677 images/s
2022-08-04 09:36:16,401 [dl_trainer.py:731] WARNING [  8][ 1640/  196][rank:0] loss: 0.356, average forward (0.009920) and backward (0.021635) time: 0.033300, iotime: 0.001502 
2022-08-04 09:36:16,474 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048298, Speed: 662.550926 images/s
2022-08-04 09:36:18,290 [dl_trainer.py:731] WARNING [  8][ 1680/  196][rank:0] loss: 0.515, average forward (0.010866) and backward (0.020861) time: 0.033517, iotime: 0.001525 
2022-08-04 09:36:18,358 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047087, Speed: 679.586788 images/s
2022-08-04 09:36:20,168 [dl_trainer.py:731] WARNING [  8][ 1720/  196][rank:0] loss: 0.358, average forward (0.010263) and backward (0.019983) time: 0.032002, iotime: 0.001514 
2022-08-04 09:36:20,229 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046759, Speed: 684.353725 images/s
2022-08-04 09:36:21,851 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:36:21,852 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:36:22,224 [dl_trainer.py:731] WARNING [  8][ 1760/  196][rank:0] loss: 0.708, average forward (0.011248) and backward (0.020746) time: 0.037779, iotime: 0.005493 
2022-08-04 09:36:22,414 [dl_trainer.py:634] INFO train iter: 1764, num_batches_per_epoch: 196
2022-08-04 09:36:22,414 [dl_trainer.py:635] INFO Epoch 9, avg train acc: 77.917730, lr: 0.010000, avg loss: 0.637543
2022-08-04 09:36:25,101 [dl_trainer.py:822] INFO Epoch 9, lr: 0.010000, val loss: 0.824844, val top-1 acc: 73.901757, top-5 acc: 97.513978
2022-08-04 09:36:26,497 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083570, Speed: 382.913561 images/s
2022-08-04 09:36:26,653 [dl_trainer.py:731] WARNING [  9][ 1800/  196][rank:0] loss: 0.702, average forward (0.009893) and backward (0.019267) time: 0.098045, iotime: 0.001401 
2022-08-04 09:36:28,331 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045833, Speed: 698.192018 images/s
2022-08-04 09:36:28,484 [dl_trainer.py:731] WARNING [  9][ 1840/  196][rank:0] loss: 0.723, average forward (0.010793) and backward (0.017239) time: 0.029789, iotime: 0.001498 
2022-08-04 09:36:30,099 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044192, Speed: 724.114065 images/s
2022-08-04 09:36:30,263 [dl_trainer.py:731] WARNING [  9][ 1880/  196][rank:0] loss: 0.544, average forward (0.009991) and backward (0.020005) time: 0.031633, iotime: 0.001398 
2022-08-04 09:36:31,876 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044411, Speed: 720.536928 images/s
2022-08-04 09:36:32,052 [dl_trainer.py:731] WARNING [  9][ 1920/  196][rank:0] loss: 0.502, average forward (0.009404) and backward (0.020320) time: 0.031302, iotime: 0.001334 
2022-08-04 09:36:33,474 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:36:33,474 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:36:34,047 [dl_trainer.py:731] WARNING [  9][ 1960/  196][rank:0] loss: 0.617, average forward (0.009289) and backward (0.018566) time: 0.033368, iotime: 0.005246 
2022-08-04 09:36:34,070 [dl_trainer.py:634] INFO train iter: 1960, num_batches_per_epoch: 196
2022-08-04 09:36:34,071 [dl_trainer.py:635] INFO Epoch 10, avg train acc: 79.496173, lr: 0.010000, avg loss: 0.609251
2022-08-04 09:36:36,711 [dl_trainer.py:822] INFO Epoch 10, lr: 0.010000, val loss: 0.748657, val top-1 acc: 75.099840, top-5 acc: 97.963259
2022-08-04 09:36:38,044 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082229, Speed: 389.158340 images/s
2022-08-04 09:36:38,409 [dl_trainer.py:731] WARNING [ 10][ 2000/  196][rank:0] loss: 0.762, average forward (0.009675) and backward (0.017467) time: 0.095318, iotime: 0.001404 
2022-08-04 09:36:39,834 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044740, Speed: 715.250437 images/s
2022-08-04 09:36:40,206 [dl_trainer.py:731] WARNING [ 10][ 2040/  196][rank:0] loss: 0.362, average forward (0.009678) and backward (0.018354) time: 0.029711, iotime: 0.001424 
2022-08-04 09:36:41,573 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043450, Speed: 736.485516 images/s
2022-08-04 09:36:41,941 [dl_trainer.py:731] WARNING [ 10][ 2080/  196][rank:0] loss: 0.979, average forward (0.009138) and backward (0.018003) time: 0.028707, iotime: 0.001332 
2022-08-04 09:36:43,291 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042946, Speed: 745.122627 images/s
2022-08-04 09:36:43,644 [dl_trainer.py:731] WARNING [ 10][ 2120/  196][rank:0] loss: 0.526, average forward (0.009990) and backward (0.018713) time: 0.030413, iotime: 0.001462 
2022-08-04 09:36:44,731 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:36:44,731 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:36:45,373 [dl_trainer.py:634] INFO train iter: 2156, num_batches_per_epoch: 196
2022-08-04 09:36:45,373 [dl_trainer.py:635] INFO Epoch 11, avg train acc: 80.181760, lr: 0.010000, avg loss: 0.563987
2022-08-04 09:36:48,007 [dl_trainer.py:822] INFO Epoch 11, lr: 0.010000, val loss: 0.706818, val top-1 acc: 77.276358, top-5 acc: 98.292732
2022-08-04 09:36:48,189 [dl_trainer.py:731] WARNING [ 11][ 2160/  196][rank:0] loss: 0.279, average forward (0.010101) and backward (0.019853) time: 0.101804, iotime: 0.005636 
2022-08-04 09:36:49,447 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082059, Speed: 389.961059 images/s
2022-08-04 09:36:50,078 [dl_trainer.py:731] WARNING [ 11][ 2200/  196][rank:0] loss: 0.983, average forward (0.010010) and backward (0.021523) time: 0.033259, iotime: 0.001484 
2022-08-04 09:36:51,239 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044782, Speed: 714.573568 images/s
2022-08-04 09:36:51,878 [dl_trainer.py:731] WARNING [ 11][ 2240/  196][rank:0] loss: 0.460, average forward (0.009473) and backward (0.020276) time: 0.031402, iotime: 0.001417 
2022-08-04 09:36:53,057 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045451, Speed: 704.048771 images/s
2022-08-04 09:36:53,680 [dl_trainer.py:731] WARNING [ 11][ 2280/  196][rank:0] loss: 0.717, average forward (0.008358) and backward (0.019817) time: 0.029687, iotime: 0.001288 
2022-08-04 09:36:54,838 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044505, Speed: 719.027459 images/s
2022-08-04 09:36:55,464 [dl_trainer.py:731] WARNING [ 11][ 2320/  196][rank:0] loss: 0.458, average forward (0.009096) and backward (0.019084) time: 0.029801, iotime: 0.001392 
2022-08-04 09:36:56,401 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:36:56,401 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:36:57,092 [dl_trainer.py:634] INFO train iter: 2352, num_batches_per_epoch: 196
2022-08-04 09:36:57,093 [dl_trainer.py:635] INFO Epoch 12, avg train acc: 80.691964, lr: 0.010000, avg loss: 0.552934
2022-08-04 09:36:59,712 [dl_trainer.py:822] INFO Epoch 12, lr: 0.010000, val loss: 0.671071, val top-1 acc: 78.045128, top-5 acc: 98.682109
2022-08-04 09:37:00,080 [dl_trainer.py:731] WARNING [ 12][ 2360/  196][rank:0] loss: 0.450, average forward (0.010793) and backward (0.019531) time: 0.101922, iotime: 0.005285 
2022-08-04 09:37:01,106 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083547, Speed: 383.016539 images/s
2022-08-04 09:37:02,014 [dl_trainer.py:731] WARNING [ 12][ 2400/  196][rank:0] loss: 0.524, average forward (0.008826) and backward (0.021434) time: 0.031879, iotime: 0.001379 
2022-08-04 09:37:03,071 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049135, Speed: 651.269926 images/s
2022-08-04 09:37:03,955 [dl_trainer.py:731] WARNING [ 12][ 2440/  196][rank:0] loss: 0.675, average forward (0.009457) and backward (0.020684) time: 0.031825, iotime: 0.001431 
2022-08-04 09:37:04,938 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046644, Speed: 686.046161 images/s
2022-08-04 09:37:05,851 [dl_trainer.py:731] WARNING [ 12][ 2480/  196][rank:0] loss: 0.476, average forward (0.009641) and backward (0.020939) time: 0.032362, iotime: 0.001529 
2022-08-04 09:37:06,879 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048520, Speed: 659.527778 images/s
2022-08-04 09:37:07,774 [dl_trainer.py:731] WARNING [ 12][ 2520/  196][rank:0] loss: 0.457, average forward (0.009375) and backward (0.019818) time: 0.030876, iotime: 0.001438 
2022-08-04 09:37:08,482 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:37:08,482 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:37:09,193 [dl_trainer.py:634] INFO train iter: 2548, num_batches_per_epoch: 196
2022-08-04 09:37:09,194 [dl_trainer.py:635] INFO Epoch 13, avg train acc: 81.616709, lr: 0.010000, avg loss: 0.527123
2022-08-04 09:37:11,808 [dl_trainer.py:822] INFO Epoch 13, lr: 0.010000, val loss: 0.794461, val top-1 acc: 75.698882, top-5 acc: 97.763578
2022-08-04 09:37:12,333 [dl_trainer.py:731] WARNING [ 13][ 2560/  196][rank:0] loss: 0.757, average forward (0.010228) and backward (0.018438) time: 0.099628, iotime: 0.005259 
2022-08-04 09:37:13,059 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082383, Speed: 388.429277 images/s
2022-08-04 09:37:14,133 [dl_trainer.py:731] WARNING [ 13][ 2600/  196][rank:0] loss: 0.318, average forward (0.008779) and backward (0.019725) time: 0.029983, iotime: 0.001270 
2022-08-04 09:37:14,858 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044961, Speed: 711.720402 images/s
2022-08-04 09:37:15,917 [dl_trainer.py:731] WARNING [ 13][ 2640/  196][rank:0] loss: 0.660, average forward (0.009356) and backward (0.018959) time: 0.029918, iotime: 0.001368 
2022-08-04 09:37:16,648 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044744, Speed: 715.184122 images/s
2022-08-04 09:37:17,680 [dl_trainer.py:731] WARNING [ 13][ 2680/  196][rank:0] loss: 0.444, average forward (0.009669) and backward (0.018744) time: 0.030057, iotime: 0.001399 
2022-08-04 09:37:18,421 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044319, Speed: 722.039638 images/s
2022-08-04 09:37:19,532 [dl_trainer.py:731] WARNING [ 13][ 2720/  196][rank:0] loss: 0.492, average forward (0.009133) and backward (0.019460) time: 0.030183, iotime: 0.001341 
2022-08-04 09:37:20,009 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:37:20,009 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:37:20,788 [dl_trainer.py:634] INFO train iter: 2744, num_batches_per_epoch: 196
2022-08-04 09:37:20,788 [dl_trainer.py:635] INFO Epoch 14, avg train acc: 82.605230, lr: 0.010000, avg loss: 0.510592
2022-08-04 09:37:23,413 [dl_trainer.py:822] INFO Epoch 14, lr: 0.010000, val loss: 0.627075, val top-1 acc: 78.224840, top-5 acc: 98.941693
2022-08-04 09:37:24,144 [dl_trainer.py:731] WARNING [ 14][ 2760/  196][rank:0] loss: 0.452, average forward (0.009453) and backward (0.020548) time: 0.101657, iotime: 0.005249 
2022-08-04 09:37:24,634 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082817, Speed: 386.392208 images/s
2022-08-04 09:37:25,880 [dl_trainer.py:731] WARNING [ 14][ 2800/  196][rank:0] loss: 0.338, average forward (0.009777) and backward (0.019530) time: 0.030948, iotime: 0.001405 
2022-08-04 09:37:26,378 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043614, Speed: 733.711263 images/s
2022-08-04 09:37:27,621 [dl_trainer.py:731] WARNING [ 14][ 2840/  196][rank:0] loss: 0.581, average forward (0.009650) and backward (0.018717) time: 0.030017, iotime: 0.001423 
2022-08-04 09:37:28,099 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043016, Speed: 743.914421 images/s
2022-08-04 09:37:29,389 [dl_trainer.py:731] WARNING [ 14][ 2880/  196][rank:0] loss: 0.522, average forward (0.009121) and backward (0.019010) time: 0.029708, iotime: 0.001336 
2022-08-04 09:37:29,896 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044913, Speed: 712.486322 images/s
2022-08-04 09:37:31,147 [dl_trainer.py:731] WARNING [ 14][ 2920/  196][rank:0] loss: 0.388, average forward (0.009608) and backward (0.019380) time: 0.030659, iotime: 0.001449 
2022-08-04 09:37:31,384 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:37:31,384 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:37:32,194 [dl_trainer.py:634] INFO train iter: 2940, num_batches_per_epoch: 196
2022-08-04 09:37:32,194 [dl_trainer.py:635] INFO Epoch 15, avg train acc: 82.669005, lr: 0.010000, avg loss: 0.502796
2022-08-04 09:37:34,873 [dl_trainer.py:822] INFO Epoch 15, lr: 0.010000, val loss: 0.575445, val top-1 acc: 80.431310, top-5 acc: 99.061502
2022-08-04 09:37:35,734 [dl_trainer.py:731] WARNING [ 15][ 2960/  196][rank:0] loss: 0.477, average forward (0.011266) and backward (0.017752) time: 0.101578, iotime: 0.005200 
2022-08-04 09:37:35,998 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081346, Speed: 393.381481 images/s
2022-08-04 09:37:37,441 [dl_trainer.py:731] WARNING [ 15][ 3000/  196][rank:0] loss: 0.472, average forward (0.010227) and backward (0.018089) time: 0.029982, iotime: 0.001422 
2022-08-04 09:37:37,729 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043260, Speed: 739.720153 images/s
2022-08-04 09:37:39,217 [dl_trainer.py:731] WARNING [ 15][ 3040/  196][rank:0] loss: 0.791, average forward (0.008962) and backward (0.020007) time: 0.030541, iotime: 0.001338 
2022-08-04 09:37:39,504 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044349, Speed: 721.545021 images/s
2022-08-04 09:37:41,005 [dl_trainer.py:731] WARNING [ 15][ 3080/  196][rank:0] loss: 0.213, average forward (0.009418) and backward (0.020318) time: 0.031329, iotime: 0.001364 
2022-08-04 09:37:41,266 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044049, Speed: 726.457997 images/s
2022-08-04 09:37:42,706 [dl_trainer.py:731] WARNING [ 15][ 3120/  196][rank:0] loss: 0.412, average forward (0.009267) and backward (0.019301) time: 0.030171, iotime: 0.001370 
2022-08-04 09:37:42,720 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:37:42,720 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:37:43,574 [dl_trainer.py:634] INFO train iter: 3136, num_batches_per_epoch: 196
2022-08-04 09:37:43,574 [dl_trainer.py:635] INFO Epoch 16, avg train acc: 82.955995, lr: 0.010000, avg loss: 0.487863
2022-08-04 09:37:46,252 [dl_trainer.py:822] INFO Epoch 16, lr: 0.010000, val loss: 0.530446, val top-1 acc: 82.168530, top-5 acc: 99.171326
2022-08-04 09:37:47,249 [dl_trainer.py:731] WARNING [ 16][ 3160/  196][rank:0] loss: 0.376, average forward (0.010018) and backward (0.017087) time: 0.100055, iotime: 0.005203 
2022-08-04 09:37:47,311 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.080593, Speed: 397.058252 images/s
2022-08-04 09:37:49,006 [dl_trainer.py:731] WARNING [ 16][ 3200/  196][rank:0] loss: 0.547, average forward (0.011215) and backward (0.019579) time: 0.032622, iotime: 0.001551 
2022-08-04 09:37:49,057 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043618, Speed: 733.638874 images/s
2022-08-04 09:37:50,707 [dl_trainer.py:731] WARNING [ 16][ 3240/  196][rank:0] loss: 0.386, average forward (0.010903) and backward (0.016353) time: 0.029042, iotime: 0.001526 
2022-08-04 09:37:50,764 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042670, Speed: 749.942570 images/s
2022-08-04 09:37:52,492 [dl_trainer.py:731] WARNING [ 16][ 3280/  196][rank:0] loss: 0.415, average forward (0.009887) and backward (0.019029) time: 0.030627, iotime: 0.001453 
2022-08-04 09:37:52,542 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044459, Speed: 719.760365 images/s
2022-08-04 09:37:54,105 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:37:54,106 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:37:54,483 [dl_trainer.py:731] WARNING [ 16][ 3320/  196][rank:0] loss: 0.478, average forward (0.010721) and backward (0.020550) time: 0.036908, iotime: 0.005340 
2022-08-04 09:37:55,006 [dl_trainer.py:634] INFO train iter: 3332, num_batches_per_epoch: 196
2022-08-04 09:37:55,006 [dl_trainer.py:635] INFO Epoch 17, avg train acc: 83.370536, lr: 0.010000, avg loss: 0.476299
2022-08-04 09:37:57,675 [dl_trainer.py:822] INFO Epoch 17, lr: 0.010000, val loss: 0.655126, val top-1 acc: 79.163339, top-5 acc: 98.622204
2022-08-04 09:37:58,725 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082415, Speed: 388.279092 images/s
2022-08-04 09:37:58,898 [dl_trainer.py:731] WARNING [ 17][ 3360/  196][rank:0] loss: 0.601, average forward (0.010279) and backward (0.020013) time: 0.098811, iotime: 0.001471 
2022-08-04 09:38:00,515 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044761, Speed: 714.911747 images/s
2022-08-04 09:38:00,688 [dl_trainer.py:731] WARNING [ 17][ 3400/  196][rank:0] loss: 0.565, average forward (0.009738) and backward (0.018985) time: 0.030445, iotime: 0.001476 
2022-08-04 09:38:02,295 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044477, Speed: 719.480734 images/s
2022-08-04 09:38:02,449 [dl_trainer.py:731] WARNING [ 17][ 3440/  196][rank:0] loss: 0.277, average forward (0.009943) and backward (0.019649) time: 0.031302, iotime: 0.001466 
2022-08-04 09:38:04,185 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047232, Speed: 677.499650 images/s
2022-08-04 09:38:04,349 [dl_trainer.py:731] WARNING [ 17][ 3480/  196][rank:0] loss: 0.271, average forward (0.009708) and backward (0.019235) time: 0.030670, iotime: 0.001479 
2022-08-04 09:38:05,787 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:38:05,787 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:38:06,390 [dl_trainer.py:731] WARNING [ 17][ 3520/  196][rank:0] loss: 0.367, average forward (0.010433) and backward (0.020120) time: 0.036378, iotime: 0.005536 
2022-08-04 09:38:06,791 [dl_trainer.py:634] INFO train iter: 3528, num_batches_per_epoch: 196
2022-08-04 09:38:06,792 [dl_trainer.py:635] INFO Epoch 18, avg train acc: 84.119898, lr: 0.010000, avg loss: 0.454594
2022-08-04 09:38:09,455 [dl_trainer.py:822] INFO Epoch 18, lr: 0.010000, val loss: 0.529427, val top-1 acc: 82.218450, top-5 acc: 98.991613
2022-08-04 09:38:10,620 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085783, Speed: 373.032356 images/s
2022-08-04 09:38:11,036 [dl_trainer.py:731] WARNING [ 18][ 3560/  196][rank:0] loss: 0.281, average forward (0.009533) and backward (0.020326) time: 0.098687, iotime: 0.001448 
2022-08-04 09:38:12,574 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048853, Speed: 655.024332 images/s
2022-08-04 09:38:12,989 [dl_trainer.py:731] WARNING [ 18][ 3600/  196][rank:0] loss: 0.525, average forward (0.009478) and backward (0.022367) time: 0.033511, iotime: 0.001426 
2022-08-04 09:38:14,476 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047530, Speed: 673.256273 images/s
2022-08-04 09:38:14,858 [dl_trainer.py:731] WARNING [ 18][ 3640/  196][rank:0] loss: 0.686, average forward (0.010357) and backward (0.021147) time: 0.033259, iotime: 0.001497 
2022-08-04 09:38:16,349 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046835, Speed: 683.244673 images/s
2022-08-04 09:38:16,765 [dl_trainer.py:731] WARNING [ 18][ 3680/  196][rank:0] loss: 0.619, average forward (0.009043) and backward (0.021068) time: 0.031806, iotime: 0.001447 
2022-08-04 09:38:17,964 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:38:17,964 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:38:18,817 [dl_trainer.py:731] WARNING [ 18][ 3720/  196][rank:0] loss: 0.590, average forward (0.012078) and backward (0.019864) time: 0.037919, iotime: 0.005682 
2022-08-04 09:38:19,012 [dl_trainer.py:634] INFO train iter: 3724, num_batches_per_epoch: 196
2022-08-04 09:38:19,012 [dl_trainer.py:635] INFO Epoch 19, avg train acc: 84.805485, lr: 0.010000, avg loss: 0.429923
2022-08-04 09:38:21,689 [dl_trainer.py:822] INFO Epoch 19, lr: 0.010000, val loss: 0.623605, val top-1 acc: 79.872204, top-5 acc: 99.111422
2022-08-04 09:38:22,719 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084906, Speed: 376.889571 images/s
2022-08-04 09:38:23,339 [dl_trainer.py:731] WARNING [ 19][ 3760/  196][rank:0] loss: 0.518, average forward (0.009539) and backward (0.020004) time: 0.098188, iotime: 0.001429 
2022-08-04 09:38:24,510 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044783, Speed: 714.551884 images/s
2022-08-04 09:38:25,097 [dl_trainer.py:731] WARNING [ 19][ 3800/  196][rank:0] loss: 0.435, average forward (0.009756) and backward (0.020038) time: 0.031495, iotime: 0.001455 
2022-08-04 09:38:26,308 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044924, Speed: 712.315975 images/s
2022-08-04 09:38:26,948 [dl_trainer.py:731] WARNING [ 19][ 3840/  196][rank:0] loss: 0.401, average forward (0.009631) and backward (0.021471) time: 0.032826, iotime: 0.001469 
2022-08-04 09:38:28,171 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046559, Speed: 687.296905 images/s
2022-08-04 09:38:28,837 [dl_trainer.py:731] WARNING [ 19][ 3880/  196][rank:0] loss: 0.469, average forward (0.009393) and backward (0.021321) time: 0.032320, iotime: 0.001371 
2022-08-04 09:38:29,734 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:38:29,734 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:38:30,789 [dl_trainer.py:731] WARNING [ 19][ 3920/  196][rank:0] loss: 0.542, average forward (0.010965) and backward (0.018492) time: 0.035060, iotime: 0.005321 
2022-08-04 09:38:30,814 [dl_trainer.py:634] INFO train iter: 3920, num_batches_per_epoch: 196
2022-08-04 09:38:30,814 [dl_trainer.py:635] INFO Epoch 20, avg train acc: 85.507015, lr: 0.010000, avg loss: 0.436536
2022-08-04 09:38:33,508 [dl_trainer.py:822] INFO Epoch 20, lr: 0.010000, val loss: 0.776768, val top-1 acc: 76.148163, top-5 acc: 98.103035
2022-08-04 09:38:34,408 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083150, Speed: 384.845314 images/s
2022-08-04 09:38:35,240 [dl_trainer.py:731] WARNING [ 20][ 3960/  196][rank:0] loss: 0.535, average forward (0.010005) and backward (0.018324) time: 0.097841, iotime: 0.001404 
2022-08-04 09:38:36,231 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045572, Speed: 702.188480 images/s
2022-08-04 09:38:37,090 [dl_trainer.py:731] WARNING [ 20][ 4000/  196][rank:0] loss: 0.369, average forward (0.009791) and backward (0.019679) time: 0.031130, iotime: 0.001408 
2022-08-04 09:38:38,094 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046560, Speed: 687.280188 images/s
2022-08-04 09:38:38,965 [dl_trainer.py:731] WARNING [ 20][ 4040/  196][rank:0] loss: 0.205, average forward (0.009254) and backward (0.021045) time: 0.031909, iotime: 0.001370 
2022-08-04 09:38:39,896 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045033, Speed: 710.586032 images/s
2022-08-04 09:38:40,773 [dl_trainer.py:731] WARNING [ 20][ 4080/  196][rank:0] loss: 0.464, average forward (0.010072) and backward (0.019758) time: 0.031495, iotime: 0.001407 
2022-08-04 09:38:41,478 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:38:41,479 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:38:42,577 [dl_trainer.py:634] INFO train iter: 4116, num_batches_per_epoch: 196
2022-08-04 09:38:42,577 [dl_trainer.py:635] INFO Epoch 21, avg train acc: 86.463648, lr: 0.010000, avg loss: 0.390374
2022-08-04 09:38:45,189 [dl_trainer.py:822] INFO Epoch 21, lr: 0.010000, val loss: 0.531228, val top-1 acc: 82.557907, top-5 acc: 99.271166
2022-08-04 09:38:45,355 [dl_trainer.py:731] WARNING [ 21][ 4120/  196][rank:0] loss: 0.375, average forward (0.009082) and backward (0.020459) time: 0.100342, iotime: 0.005155 
2022-08-04 09:38:46,083 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082469, Speed: 388.024550 images/s
2022-08-04 09:38:47,178 [dl_trainer.py:731] WARNING [ 21][ 4160/  196][rank:0] loss: 0.434, average forward (0.010969) and backward (0.018955) time: 0.031700, iotime: 0.001508 
2022-08-04 09:38:47,857 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044359, Speed: 721.379039 images/s
2022-08-04 09:38:48,825 [dl_trainer.py:731] WARNING [ 21][ 4200/  196][rank:0] loss: 0.302, average forward (0.009213) and backward (0.016985) time: 0.027760, iotime: 0.001344 
2022-08-04 09:38:49,555 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042439, Speed: 754.024767 images/s
2022-08-04 09:38:50,556 [dl_trainer.py:731] WARNING [ 21][ 4240/  196][rank:0] loss: 0.289, average forward (0.010408) and backward (0.017272) time: 0.029352, iotime: 0.001431 
2022-08-04 09:38:51,272 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042918, Speed: 745.601749 images/s
2022-08-04 09:38:52,289 [dl_trainer.py:731] WARNING [ 21][ 4280/  196][rank:0] loss: 0.367, average forward (0.009300) and backward (0.017889) time: 0.028797, iotime: 0.001367 
2022-08-04 09:38:52,764 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:38:52,764 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:38:53,856 [dl_trainer.py:634] INFO train iter: 4312, num_batches_per_epoch: 196
2022-08-04 09:38:53,856 [dl_trainer.py:635] INFO Epoch 22, avg train acc: 86.336097, lr: 0.010000, avg loss: 0.407761
2022-08-04 09:38:56,558 [dl_trainer.py:822] INFO Epoch 22, lr: 0.010000, val loss: 0.743082, val top-1 acc: 77.985224, top-5 acc: 98.712061
2022-08-04 09:38:56,917 [dl_trainer.py:731] WARNING [ 22][ 4320/  196][rank:0] loss: 0.237, average forward (0.010201) and backward (0.016796) time: 0.100663, iotime: 0.005348 
2022-08-04 09:38:57,427 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082047, Speed: 390.020362 images/s
2022-08-04 09:38:58,702 [dl_trainer.py:731] WARNING [ 22][ 4360/  196][rank:0] loss: 0.180, average forward (0.009217) and backward (0.018054) time: 0.028910, iotime: 0.001410 
2022-08-04 09:38:59,225 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044941, Speed: 712.038509 images/s
2022-08-04 09:39:00,495 [dl_trainer.py:731] WARNING [ 22][ 4400/  196][rank:0] loss: 0.324, average forward (0.008743) and backward (0.018468) time: 0.028748, iotime: 0.001312 
2022-08-04 09:39:00,953 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043177, Speed: 741.137020 images/s
2022-08-04 09:39:02,211 [dl_trainer.py:731] WARNING [ 22][ 4440/  196][rank:0] loss: 0.272, average forward (0.009885) and backward (0.017206) time: 0.028711, iotime: 0.001381 
2022-08-04 09:39:02,705 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043800, Speed: 730.600130 images/s
2022-08-04 09:39:03,952 [dl_trainer.py:731] WARNING [ 22][ 4480/  196][rank:0] loss: 0.417, average forward (0.010675) and backward (0.019068) time: 0.031476, iotime: 0.001496 
2022-08-04 09:39:04,206 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:39:04,206 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:39:05,369 [dl_trainer.py:634] INFO train iter: 4508, num_batches_per_epoch: 196
2022-08-04 09:39:05,370 [dl_trainer.py:635] INFO Epoch 23, avg train acc: 85.873724, lr: 0.010000, avg loss: 0.395909
2022-08-04 09:39:08,006 [dl_trainer.py:822] INFO Epoch 23, lr: 0.010000, val loss: 0.684200, val top-1 acc: 78.793930, top-5 acc: 99.001597
2022-08-04 09:39:08,491 [dl_trainer.py:731] WARNING [ 23][ 4520/  196][rank:0] loss: 0.789, average forward (0.009085) and backward (0.018345) time: 0.098812, iotime: 0.005141 
2022-08-04 09:39:08,767 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.080807, Speed: 396.006703 images/s
2022-08-04 09:39:10,077 [dl_trainer.py:731] WARNING [ 23][ 4560/  196][rank:0] loss: 0.135, average forward (0.008904) and backward (0.016911) time: 0.027329, iotime: 0.001289 
2022-08-04 09:39:10,328 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.039024, Speed: 820.001283 images/s
2022-08-04 09:39:11,711 [dl_trainer.py:731] WARNING [ 23][ 4600/  196][rank:0] loss: 0.348, average forward (0.009974) and backward (0.016752) time: 0.028312, iotime: 0.001361 
2022-08-04 09:39:11,965 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040917, Speed: 782.065151 images/s
2022-08-04 09:39:13,501 [dl_trainer.py:731] WARNING [ 23][ 4640/  196][rank:0] loss: 0.201, average forward (0.009242) and backward (0.017788) time: 0.028588, iotime: 0.001331 
2022-08-04 09:39:13,775 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045222, Speed: 707.627984 images/s
2022-08-04 09:39:15,112 [dl_trainer.py:731] WARNING [ 23][ 4680/  196][rank:0] loss: 0.279, average forward (0.008670) and backward (0.016325) time: 0.026508, iotime: 0.001287 
2022-08-04 09:39:15,124 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:39:15,124 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:39:16,309 [dl_trainer.py:634] INFO train iter: 4704, num_batches_per_epoch: 196
2022-08-04 09:39:16,310 [dl_trainer.py:635] INFO Epoch 24, avg train acc: 87.675383, lr: 0.010000, avg loss: 0.365259
2022-08-04 09:39:18,918 [dl_trainer.py:822] INFO Epoch 24, lr: 0.010000, val loss: 0.548796, val top-1 acc: 81.779153, top-5 acc: 98.791933
2022-08-04 09:39:19,601 [dl_trainer.py:731] WARNING [ 24][ 4720/  196][rank:0] loss: 0.479, average forward (0.008988) and backward (0.018806) time: 0.098801, iotime: 0.005244 
2022-08-04 09:39:19,653 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.078366, Speed: 408.340236 images/s
2022-08-04 09:39:21,380 [dl_trainer.py:731] WARNING [ 24][ 4760/  196][rank:0] loss: 0.519, average forward (0.008724) and backward (0.019120) time: 0.029412, iotime: 0.001342 
2022-08-04 09:39:21,444 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044761, Speed: 714.906035 images/s
2022-08-04 09:39:23,145 [dl_trainer.py:731] WARNING [ 24][ 4800/  196][rank:0] loss: 0.259, average forward (0.010397) and backward (0.017948) time: 0.030055, iotime: 0.001445 
2022-08-04 09:39:23,201 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043932, Speed: 728.390778 images/s
2022-08-04 09:39:24,875 [dl_trainer.py:731] WARNING [ 24][ 4840/  196][rank:0] loss: 0.341, average forward (0.009900) and backward (0.017415) time: 0.028967, iotime: 0.001403 
2022-08-04 09:39:24,919 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042926, Speed: 745.471611 images/s
2022-08-04 09:39:26,487 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:39:26,488 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:39:26,877 [dl_trainer.py:731] WARNING [ 24][ 4880/  196][rank:0] loss: 0.279, average forward (0.008930) and backward (0.018423) time: 0.032920, iotime: 0.005310 
2022-08-04 09:39:27,714 [dl_trainer.py:634] INFO train iter: 4900, num_batches_per_epoch: 196
2022-08-04 09:39:27,715 [dl_trainer.py:635] INFO Epoch 25, avg train acc: 87.611607, lr: 0.010000, avg loss: 0.357841
2022-08-04 09:39:30,376 [dl_trainer.py:822] INFO Epoch 25, lr: 0.010000, val loss: 0.544745, val top-1 acc: 82.398163, top-5 acc: 99.101438
2022-08-04 09:39:31,032 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081494, Speed: 392.665180 images/s
2022-08-04 09:39:31,175 [dl_trainer.py:731] WARNING [ 25][ 4920/  196][rank:0] loss: 0.362, average forward (0.009627) and backward (0.016755) time: 0.094602, iotime: 0.001377 
2022-08-04 09:39:32,686 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041339, Speed: 774.090250 images/s
2022-08-04 09:39:32,857 [dl_trainer.py:731] WARNING [ 25][ 4960/  196][rank:0] loss: 0.520, average forward (0.009249) and backward (0.016772) time: 0.027618, iotime: 0.001371 
2022-08-04 09:39:34,410 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043099, Speed: 742.479840 images/s
2022-08-04 09:39:34,563 [dl_trainer.py:731] WARNING [ 25][ 5000/  196][rank:0] loss: 0.223, average forward (0.012317) and backward (0.016247) time: 0.030641, iotime: 0.001810 
2022-08-04 09:39:36,159 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043706, Speed: 732.169915 images/s
2022-08-04 09:39:36,318 [dl_trainer.py:731] WARNING [ 25][ 5040/  196][rank:0] loss: 0.404, average forward (0.010523) and backward (0.019030) time: 0.031405, iotime: 0.001595 
2022-08-04 09:39:37,605 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:39:37,606 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:39:38,213 [dl_trainer.py:731] WARNING [ 25][ 5080/  196][rank:0] loss: 0.484, average forward (0.009575) and backward (0.018028) time: 0.033152, iotime: 0.005279 
2022-08-04 09:39:38,947 [dl_trainer.py:634] INFO train iter: 5096, num_batches_per_epoch: 196
2022-08-04 09:39:38,947 [dl_trainer.py:635] INFO Epoch 26, avg train acc: 87.372449, lr: 0.010000, avg loss: 0.369617
2022-08-04 09:39:41,592 [dl_trainer.py:822] INFO Epoch 26, lr: 0.010000, val loss: 0.643580, val top-1 acc: 80.910543, top-5 acc: 98.911741
2022-08-04 09:39:42,272 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081493, Speed: 392.672088 images/s
2022-08-04 09:39:42,641 [dl_trainer.py:731] WARNING [ 26][ 5120/  196][rank:0] loss: 0.300, average forward (0.009079) and backward (0.017355) time: 0.094721, iotime: 0.001393 
2022-08-04 09:39:43,981 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042696, Speed: 749.488825 images/s
2022-08-04 09:39:44,399 [dl_trainer.py:731] WARNING [ 26][ 5160/  196][rank:0] loss: 0.342, average forward (0.010490) and backward (0.017363) time: 0.029646, iotime: 0.001516 
2022-08-04 09:39:45,782 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045027, Speed: 710.692043 images/s
2022-08-04 09:39:46,163 [dl_trainer.py:731] WARNING [ 26][ 5200/  196][rank:0] loss: 0.171, average forward (0.010055) and backward (0.019048) time: 0.030762, iotime: 0.001410 
2022-08-04 09:39:47,547 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044100, Speed: 725.625079 images/s
2022-08-04 09:39:47,928 [dl_trainer.py:731] WARNING [ 26][ 5240/  196][rank:0] loss: 0.451, average forward (0.009548) and backward (0.018519) time: 0.029637, iotime: 0.001326 
2022-08-04 09:39:49,039 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:39:49,039 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:39:49,862 [dl_trainer.py:731] WARNING [ 26][ 5280/  196][rank:0] loss: 0.646, average forward (0.010018) and backward (0.018488) time: 0.033798, iotime: 0.005026 
2022-08-04 09:39:50,426 [dl_trainer.py:634] INFO train iter: 5292, num_batches_per_epoch: 196
2022-08-04 09:39:50,426 [dl_trainer.py:635] INFO Epoch 27, avg train acc: 87.786990, lr: 0.010000, avg loss: 0.358661
2022-08-04 09:39:53,127 [dl_trainer.py:822] INFO Epoch 27, lr: 0.010000, val loss: 0.542621, val top-1 acc: 82.857428, top-5 acc: 99.121406
2022-08-04 09:39:53,734 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082485, Speed: 387.950347 images/s
2022-08-04 09:39:54,305 [dl_trainer.py:731] WARNING [ 27][ 5320/  196][rank:0] loss: 0.162, average forward (0.010389) and backward (0.018586) time: 0.098363, iotime: 0.001501 
2022-08-04 09:39:55,511 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044404, Speed: 720.651250 images/s
2022-08-04 09:39:56,108 [dl_trainer.py:731] WARNING [ 27][ 5360/  196][rank:0] loss: 0.554, average forward (0.009701) and backward (0.020390) time: 0.031916, iotime: 0.001575 
2022-08-04 09:39:57,263 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043798, Speed: 730.621905 images/s
2022-08-04 09:39:57,833 [dl_trainer.py:731] WARNING [ 27][ 5400/  196][rank:0] loss: 0.399, average forward (0.008465) and backward (0.018363) time: 0.028316, iotime: 0.001268 
2022-08-04 09:39:58,960 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042396, Speed: 754.791105 images/s
2022-08-04 09:39:59,634 [dl_trainer.py:731] WARNING [ 27][ 5440/  196][rank:0] loss: 0.454, average forward (0.009877) and backward (0.019552) time: 0.031095, iotime: 0.001421 
2022-08-04 09:40:00,589 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:40:00,589 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:40:01,643 [dl_trainer.py:731] WARNING [ 27][ 5480/  196][rank:0] loss: 0.270, average forward (0.010243) and backward (0.020422) time: 0.036264, iotime: 0.005318 
2022-08-04 09:40:02,004 [dl_trainer.py:634] INFO train iter: 5488, num_batches_per_epoch: 196
2022-08-04 09:40:02,004 [dl_trainer.py:635] INFO Epoch 28, avg train acc: 88.249362, lr: 0.010000, avg loss: 0.338725
2022-08-04 09:40:04,747 [dl_trainer.py:822] INFO Epoch 28, lr: 0.010000, val loss: 0.485825, val top-1 acc: 84.155351, top-5 acc: 99.261182
2022-08-04 09:40:05,383 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.085622, Speed: 373.733964 images/s
2022-08-04 09:40:06,199 [dl_trainer.py:731] WARNING [ 28][ 5520/  196][rank:0] loss: 0.559, average forward (0.009557) and backward (0.017682) time: 0.098794, iotime: 0.001495 
2022-08-04 09:40:07,150 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044159, Speed: 724.656225 images/s
2022-08-04 09:40:08,040 [dl_trainer.py:731] WARNING [ 28][ 5560/  196][rank:0] loss: 0.551, average forward (0.009425) and backward (0.019275) time: 0.030409, iotime: 0.001478 
2022-08-04 09:40:09,009 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046467, Speed: 688.662180 images/s
2022-08-04 09:40:09,855 [dl_trainer.py:731] WARNING [ 28][ 5600/  196][rank:0] loss: 0.434, average forward (0.008810) and backward (0.019120) time: 0.029495, iotime: 0.001327 
2022-08-04 09:40:10,874 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046608, Speed: 686.581875 images/s
2022-08-04 09:40:11,727 [dl_trainer.py:731] WARNING [ 28][ 5640/  196][rank:0] loss: 0.293, average forward (0.010073) and backward (0.017463) time: 0.029221, iotime: 0.001429 
2022-08-04 09:40:12,402 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:40:12,403 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:40:13,760 [dl_trainer.py:731] WARNING [ 28][ 5680/  196][rank:0] loss: 0.424, average forward (0.009202) and backward (0.020294) time: 0.034682, iotime: 0.004907 
2022-08-04 09:40:13,958 [dl_trainer.py:634] INFO train iter: 5684, num_batches_per_epoch: 196
2022-08-04 09:40:13,958 [dl_trainer.py:635] INFO Epoch 29, avg train acc: 87.771046, lr: 0.010000, avg loss: 0.362861
2022-08-04 09:40:16,642 [dl_trainer.py:822] INFO Epoch 29, lr: 0.010000, val loss: 0.464263, val top-1 acc: 84.824281, top-5 acc: 99.291134
2022-08-04 09:40:17,222 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084618, Speed: 378.169805 images/s
2022-08-04 09:40:18,334 [dl_trainer.py:731] WARNING [ 29][ 5720/  196][rank:0] loss: 0.440, average forward (0.011271) and backward (0.021733) time: 0.102032, iotime: 0.001598 
2022-08-04 09:40:19,077 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046362, Speed: 690.221405 images/s
2022-08-04 09:40:20,194 [dl_trainer.py:731] WARNING [ 29][ 5760/  196][rank:0] loss: 0.330, average forward (0.010319) and backward (0.019677) time: 0.031704, iotime: 0.001461 
2022-08-04 09:40:20,990 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047820, Speed: 669.176885 images/s
2022-08-04 09:40:22,137 [dl_trainer.py:731] WARNING [ 29][ 5800/  196][rank:0] loss: 0.200, average forward (0.008764) and backward (0.021522) time: 0.031864, iotime: 0.001342 
2022-08-04 09:40:22,927 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048421, Speed: 660.865302 images/s
2022-08-04 09:40:24,051 [dl_trainer.py:731] WARNING [ 29][ 5840/  196][rank:0] loss: 0.411, average forward (0.009074) and backward (0.022038) time: 0.032755, iotime: 0.001408 
2022-08-04 09:40:24,518 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:40:24,518 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:40:26,049 [dl_trainer.py:731] WARNING [ 29][ 5880/  196][rank:0] loss: 0.302, average forward (0.010936) and backward (0.018481) time: 0.035392, iotime: 0.005684 
2022-08-04 09:40:26,057 [dl_trainer.py:634] INFO train iter: 5880, num_batches_per_epoch: 196
2022-08-04 09:40:26,058 [dl_trainer.py:635] INFO Epoch 30, avg train acc: 88.504464, lr: 0.010000, avg loss: 0.328821
2022-08-04 09:40:28,982 [dl_trainer.py:822] INFO Epoch 30, lr: 0.010000, val loss: 0.551891, val top-1 acc: 83.077077, top-5 acc: 99.041534
2022-08-04 09:40:29,526 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.087976, Speed: 363.737439 images/s
2022-08-04 09:40:30,831 [dl_trainer.py:731] WARNING [ 30][ 5920/  196][rank:0] loss: 0.272, average forward (0.010301) and backward (0.018587) time: 0.105239, iotime: 0.001523 
2022-08-04 09:40:31,356 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045730, Speed: 699.765831 images/s
2022-08-04 09:40:32,626 [dl_trainer.py:731] WARNING [ 30][ 5960/  196][rank:0] loss: 0.124, average forward (0.008850) and backward (0.016895) time: 0.027482, iotime: 0.001479 
2022-08-04 09:40:33,141 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044615, Speed: 717.253496 images/s
2022-08-04 09:40:34,452 [dl_trainer.py:731] WARNING [ 30][ 6000/  196][rank:0] loss: 0.170, average forward (0.011455) and backward (0.020443) time: 0.033912, iotime: 0.001722 
2022-08-04 09:40:34,990 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046218, Speed: 692.376000 images/s
2022-08-04 09:40:36,251 [dl_trainer.py:731] WARNING [ 30][ 6040/  196][rank:0] loss: 0.241, average forward (0.011085) and backward (0.019841) time: 0.032756, iotime: 0.001544 
2022-08-04 09:40:36,498 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:40:36,498 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:40:38,088 [dl_trainer.py:634] INFO train iter: 6076, num_batches_per_epoch: 196
2022-08-04 09:40:38,089 [dl_trainer.py:635] INFO Epoch 31, avg train acc: 89.062500, lr: 0.010000, avg loss: 0.324195
2022-08-04 09:40:40,726 [dl_trainer.py:822] INFO Epoch 31, lr: 0.010000, val loss: 0.517353, val top-1 acc: 83.606230, top-5 acc: 99.281150
2022-08-04 09:40:40,882 [dl_trainer.py:731] WARNING [ 31][ 6080/  196][rank:0] loss: 0.139, average forward (0.011481) and backward (0.019535) time: 0.103506, iotime: 0.006132 
2022-08-04 09:40:41,131 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081856, Speed: 390.931160 images/s
2022-08-04 09:40:42,542 [dl_trainer.py:731] WARNING [ 31][ 6120/  196][rank:0] loss: 0.185, average forward (0.009388) and backward (0.017518) time: 0.028580, iotime: 0.001411 
2022-08-04 09:40:42,817 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042116, Speed: 759.811765 images/s
2022-08-04 09:40:44,351 [dl_trainer.py:731] WARNING [ 31][ 6160/  196][rank:0] loss: 0.411, average forward (0.009876) and backward (0.019155) time: 0.030647, iotime: 0.001376 
2022-08-04 09:40:44,615 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044959, Speed: 711.757107 images/s
2022-08-04 09:40:46,117 [dl_trainer.py:731] WARNING [ 31][ 6200/  196][rank:0] loss: 0.170, average forward (0.010264) and backward (0.018396) time: 0.030385, iotime: 0.001472 
2022-08-04 09:40:46,414 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044945, Speed: 711.973448 images/s
2022-08-04 09:40:47,941 [dl_trainer.py:731] WARNING [ 31][ 6240/  196][rank:0] loss: 0.375, average forward (0.008878) and backward (0.018757) time: 0.029273, iotime: 0.001406 
2022-08-04 09:40:47,960 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:40:47,960 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:40:49,473 [dl_trainer.py:634] INFO train iter: 6272, num_batches_per_epoch: 196
2022-08-04 09:40:49,473 [dl_trainer.py:635] INFO Epoch 32, avg train acc: 88.663903, lr: 0.010000, avg loss: 0.318603
2022-08-04 09:40:52,115 [dl_trainer.py:822] INFO Epoch 32, lr: 0.010000, val loss: 0.463014, val top-1 acc: 85.363419, top-5 acc: 99.311102
2022-08-04 09:40:52,467 [dl_trainer.py:731] WARNING [ 32][ 6280/  196][rank:0] loss: 0.246, average forward (0.010067) and backward (0.016208) time: 0.098915, iotime: 0.005775 
2022-08-04 09:40:52,525 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081465, Speed: 392.808216 images/s
2022-08-04 09:40:54,147 [dl_trainer.py:731] WARNING [ 32][ 6320/  196][rank:0] loss: 0.394, average forward (0.009352) and backward (0.017383) time: 0.028383, iotime: 0.001402 
2022-08-04 09:40:54,205 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042000, Speed: 761.900407 images/s
2022-08-04 09:40:55,891 [dl_trainer.py:731] WARNING [ 32][ 6360/  196][rank:0] loss: 0.465, average forward (0.010379) and backward (0.018393) time: 0.030461, iotime: 0.001429 
2022-08-04 09:40:55,950 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043613, Speed: 733.724499 images/s
2022-08-04 09:40:57,606 [dl_trainer.py:731] WARNING [ 32][ 6400/  196][rank:0] loss: 0.613, average forward (0.009152) and backward (0.016621) time: 0.027354, iotime: 0.001348 
2022-08-04 09:40:57,656 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042650, Speed: 750.299859 images/s
2022-08-04 09:40:59,147 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:40:59,148 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:40:59,500 [dl_trainer.py:731] WARNING [ 32][ 6440/  196][rank:0] loss: 0.343, average forward (0.009615) and backward (0.016566) time: 0.031455, iotime: 0.005012 
2022-08-04 09:41:00,772 [dl_trainer.py:634] INFO train iter: 6468, num_batches_per_epoch: 196
2022-08-04 09:41:00,773 [dl_trainer.py:635] INFO Epoch 33, avg train acc: 88.536352, lr: 0.010000, avg loss: 0.321985
2022-08-04 09:41:03,424 [dl_trainer.py:822] INFO Epoch 33, lr: 0.010000, val loss: 0.476940, val top-1 acc: 84.974042, top-5 acc: 99.261182
2022-08-04 09:41:03,797 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081851, Speed: 390.953752 images/s
2022-08-04 09:41:03,970 [dl_trainer.py:731] WARNING [ 33][ 6480/  196][rank:0] loss: 0.421, average forward (0.010005) and backward (0.018924) time: 0.096999, iotime: 0.001448 
2022-08-04 09:41:05,586 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044699, Speed: 715.904914 images/s
2022-08-04 09:41:05,740 [dl_trainer.py:731] WARNING [ 33][ 6520/  196][rank:0] loss: 0.253, average forward (0.011146) and backward (0.018958) time: 0.031997, iotime: 0.001632 
2022-08-04 09:41:07,425 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045968, Speed: 696.139390 images/s
2022-08-04 09:41:07,585 [dl_trainer.py:731] WARNING [ 33][ 6560/  196][rank:0] loss: 0.237, average forward (0.009606) and backward (0.016764) time: 0.028081, iotime: 0.001473 
2022-08-04 09:41:09,253 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045694, Speed: 700.306568 images/s
2022-08-04 09:41:09,424 [dl_trainer.py:731] WARNING [ 33][ 6600/  196][rank:0] loss: 0.240, average forward (0.010311) and backward (0.019396) time: 0.031469, iotime: 0.001522 
2022-08-04 09:41:10,845 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:41:10,845 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:41:11,463 [dl_trainer.py:731] WARNING [ 33][ 6640/  196][rank:0] loss: 0.130, average forward (0.009909) and backward (0.019561) time: 0.035179, iotime: 0.005445 
2022-08-04 09:41:12,548 [dl_trainer.py:634] INFO train iter: 6664, num_batches_per_epoch: 196
2022-08-04 09:41:12,549 [dl_trainer.py:635] INFO Epoch 34, avg train acc: 89.477041, lr: 0.010000, avg loss: 0.300929
2022-08-04 09:41:15,172 [dl_trainer.py:822] INFO Epoch 34, lr: 0.010000, val loss: 0.500958, val top-1 acc: 84.275160, top-5 acc: 99.351038
2022-08-04 09:41:15,513 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083447, Speed: 383.476462 images/s
2022-08-04 09:41:15,915 [dl_trainer.py:731] WARNING [ 34][ 6680/  196][rank:0] loss: 0.209, average forward (0.009396) and backward (0.019655) time: 0.096811, iotime: 0.001406 
2022-08-04 09:41:17,304 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044767, Speed: 714.808661 images/s
2022-08-04 09:41:17,666 [dl_trainer.py:731] WARNING [ 34][ 6720/  196][rank:0] loss: 0.345, average forward (0.009535) and backward (0.018770) time: 0.029994, iotime: 0.001456 
2022-08-04 09:41:19,004 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042497, Speed: 752.995436 images/s
2022-08-04 09:41:19,390 [dl_trainer.py:731] WARNING [ 34][ 6760/  196][rank:0] loss: 0.273, average forward (0.009884) and backward (0.017941) time: 0.029451, iotime: 0.001391 
2022-08-04 09:41:20,776 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044284, Speed: 722.616528 images/s
2022-08-04 09:41:21,168 [dl_trainer.py:731] WARNING [ 34][ 6800/  196][rank:0] loss: 0.218, average forward (0.008867) and backward (0.019386) time: 0.029796, iotime: 0.001326 
2022-08-04 09:41:22,366 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:41:22,367 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:41:23,152 [dl_trainer.py:731] WARNING [ 34][ 6840/  196][rank:0] loss: 0.215, average forward (0.010766) and backward (0.020474) time: 0.036769, iotime: 0.005224 
2022-08-04 09:41:24,050 [dl_trainer.py:634] INFO train iter: 6860, num_batches_per_epoch: 196
2022-08-04 09:41:24,051 [dl_trainer.py:635] INFO Epoch 35, avg train acc: 89.620536, lr: 0.010000, avg loss: 0.298906
2022-08-04 09:41:26,744 [dl_trainer.py:822] INFO Epoch 35, lr: 0.010000, val loss: 0.432128, val top-1 acc: 86.122204, top-5 acc: 99.311102
2022-08-04 09:41:27,012 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083141, Speed: 384.888957 images/s
2022-08-04 09:41:27,591 [dl_trainer.py:731] WARNING [ 35][ 6880/  196][rank:0] loss: 0.130, average forward (0.009216) and backward (0.018297) time: 0.096554, iotime: 0.001381 
2022-08-04 09:41:28,753 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043501, Speed: 735.619984 images/s
2022-08-04 09:41:29,341 [dl_trainer.py:731] WARNING [ 35][ 6920/  196][rank:0] loss: 0.325, average forward (0.009199) and backward (0.017878) time: 0.028631, iotime: 0.001323 
2022-08-04 09:41:30,480 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043164, Speed: 741.359616 images/s
2022-08-04 09:41:31,087 [dl_trainer.py:731] WARNING [ 35][ 6960/  196][rank:0] loss: 0.142, average forward (0.009685) and backward (0.018205) time: 0.029604, iotime: 0.001470 
2022-08-04 09:41:32,232 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043796, Speed: 730.666054 images/s
2022-08-04 09:41:32,812 [dl_trainer.py:731] WARNING [ 35][ 7000/  196][rank:0] loss: 0.297, average forward (0.009423) and backward (0.018497) time: 0.029564, iotime: 0.001419 
2022-08-04 09:41:33,760 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:41:33,760 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:41:34,803 [dl_trainer.py:731] WARNING [ 35][ 7040/  196][rank:0] loss: 0.353, average forward (0.010156) and backward (0.019132) time: 0.034941, iotime: 0.005344 
2022-08-04 09:41:35,538 [dl_trainer.py:634] INFO train iter: 7056, num_batches_per_epoch: 196
2022-08-04 09:41:35,539 [dl_trainer.py:635] INFO Epoch 36, avg train acc: 89.429209, lr: 0.010000, avg loss: 0.300261
2022-08-04 09:41:38,223 [dl_trainer.py:822] INFO Epoch 36, lr: 0.010000, val loss: 0.503834, val top-1 acc: 84.165335, top-5 acc: 99.321086
2022-08-04 09:41:38,470 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083156, Speed: 384.819656 images/s
2022-08-04 09:41:39,339 [dl_trainer.py:731] WARNING [ 36][ 7080/  196][rank:0] loss: 0.232, average forward (0.010091) and backward (0.020434) time: 0.099976, iotime: 0.001429 
2022-08-04 09:41:40,269 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044976, Speed: 711.492427 images/s
2022-08-04 09:41:41,071 [dl_trainer.py:731] WARNING [ 36][ 7120/  196][rank:0] loss: 0.149, average forward (0.010133) and backward (0.018975) time: 0.030773, iotime: 0.001432 
2022-08-04 09:41:42,053 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044587, Speed: 717.690625 images/s
2022-08-04 09:41:42,811 [dl_trainer.py:731] WARNING [ 36][ 7160/  196][rank:0] loss: 0.148, average forward (0.010355) and backward (0.019411) time: 0.031470, iotime: 0.001460 
2022-08-04 09:41:43,786 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043303, Speed: 738.984097 images/s
2022-08-04 09:41:44,589 [dl_trainer.py:731] WARNING [ 36][ 7200/  196][rank:0] loss: 0.226, average forward (0.011574) and backward (0.019875) time: 0.033309, iotime: 0.001577 
2022-08-04 09:41:45,244 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:41:45,245 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:41:46,461 [dl_trainer.py:731] WARNING [ 36][ 7240/  196][rank:0] loss: 0.592, average forward (0.009260) and backward (0.018863) time: 0.033479, iotime: 0.005097 
2022-08-04 09:41:46,996 [dl_trainer.py:634] INFO train iter: 7252, num_batches_per_epoch: 196
2022-08-04 09:41:46,997 [dl_trainer.py:635] INFO Epoch 37, avg train acc: 89.827806, lr: 0.010000, avg loss: 0.300493
2022-08-04 09:41:49,709 [dl_trainer.py:822] INFO Epoch 37, lr: 0.010000, val loss: 0.484800, val top-1 acc: 84.874201, top-5 acc: 99.271166
2022-08-04 09:41:49,900 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.081505, Speed: 392.613706 images/s
2022-08-04 09:41:50,971 [dl_trainer.py:731] WARNING [ 37][ 7280/  196][rank:0] loss: 0.293, average forward (0.009294) and backward (0.017983) time: 0.096781, iotime: 0.001370 
2022-08-04 09:41:51,724 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045587, Speed: 701.953170 images/s
2022-08-04 09:41:52,780 [dl_trainer.py:731] WARNING [ 37][ 7320/  196][rank:0] loss: 0.248, average forward (0.009864) and backward (0.019243) time: 0.030793, iotime: 0.001441 
2022-08-04 09:41:53,512 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044693, Speed: 715.989696 images/s
2022-08-04 09:41:54,593 [dl_trainer.py:731] WARNING [ 37][ 7360/  196][rank:0] loss: 0.243, average forward (0.009529) and backward (0.019113) time: 0.030276, iotime: 0.001387 
2022-08-04 09:41:55,357 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046109, Speed: 694.001086 images/s
2022-08-04 09:41:56,434 [dl_trainer.py:731] WARNING [ 37][ 7400/  196][rank:0] loss: 0.345, average forward (0.010237) and backward (0.021587) time: 0.033563, iotime: 0.001485 
2022-08-04 09:41:56,875 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:41:56,875 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:41:58,379 [dl_trainer.py:731] WARNING [ 37][ 7440/  196][rank:0] loss: 0.236, average forward (0.009012) and backward (0.020236) time: 0.034764, iotime: 0.005261 
2022-08-04 09:41:58,748 [dl_trainer.py:634] INFO train iter: 7448, num_batches_per_epoch: 196
2022-08-04 09:41:58,749 [dl_trainer.py:635] INFO Epoch 38, avg train acc: 90.258291, lr: 0.010000, avg loss: 0.286541
2022-08-04 09:42:01,409 [dl_trainer.py:822] INFO Epoch 38, lr: 0.010000, val loss: 0.449691, val top-1 acc: 85.393371, top-5 acc: 99.271166
2022-08-04 09:42:01,617 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.083455, Speed: 383.438396 images/s
2022-08-04 09:42:02,855 [dl_trainer.py:731] WARNING [ 38][ 7480/  196][rank:0] loss: 0.497, average forward (0.009628) and backward (0.019842) time: 0.099311, iotime: 0.001466 
2022-08-04 09:42:03,365 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043690, Speed: 732.440013 images/s
2022-08-04 09:42:04,679 [dl_trainer.py:731] WARNING [ 38][ 7520/  196][rank:0] loss: 0.244, average forward (0.008884) and backward (0.020816) time: 0.031344, iotime: 0.001413 
2022-08-04 09:42:05,192 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045649, Speed: 701.007189 images/s
2022-08-04 09:42:06,509 [dl_trainer.py:731] WARNING [ 38][ 7560/  196][rank:0] loss: 0.425, average forward (0.009668) and backward (0.020223) time: 0.031546, iotime: 0.001414 
2022-08-04 09:42:07,032 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045993, Speed: 695.753177 images/s
2022-08-04 09:42:08,324 [dl_trainer.py:731] WARNING [ 38][ 7600/  196][rank:0] loss: 0.264, average forward (0.010021) and backward (0.018043) time: 0.029817, iotime: 0.001479 
2022-08-04 09:42:08,586 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:42:08,587 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:42:10,376 [dl_trainer.py:731] WARNING [ 38][ 7640/  196][rank:0] loss: 0.342, average forward (0.008828) and backward (0.021268) time: 0.035268, iotime: 0.004920 
2022-08-04 09:42:10,583 [dl_trainer.py:634] INFO train iter: 7644, num_batches_per_epoch: 196
2022-08-04 09:42:10,583 [dl_trainer.py:635] INFO Epoch 39, avg train acc: 89.955357, lr: 0.010000, avg loss: 0.291520
2022-08-04 09:42:13,258 [dl_trainer.py:822] INFO Epoch 39, lr: 0.010000, val loss: 0.504478, val top-1 acc: 83.885783, top-5 acc: 99.281150
2022-08-04 09:42:13,353 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.084261, Speed: 379.771811 images/s
2022-08-04 09:42:14,883 [dl_trainer.py:731] WARNING [ 39][ 7680/  196][rank:0] loss: 0.208, average forward (0.009358) and backward (0.020469) time: 0.098389, iotime: 0.001356 
2022-08-04 09:42:15,189 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045885, Speed: 697.397163 images/s
2022-08-04 09:42:16,776 [dl_trainer.py:731] WARNING [ 39][ 7720/  196][rank:0] loss: 0.238, average forward (0.009449) and backward (0.020399) time: 0.031473, iotime: 0.001387 
2022-08-04 09:42:17,090 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047529, Speed: 673.266573 images/s
2022-08-04 09:42:18,681 [dl_trainer.py:731] WARNING [ 39][ 7760/  196][rank:0] loss: 0.159, average forward (0.010579) and backward (0.020591) time: 0.032969, iotime: 0.001530 
2022-08-04 09:42:18,974 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047081, Speed: 679.676437 images/s
2022-08-04 09:42:20,550 [dl_trainer.py:731] WARNING [ 39][ 7800/  196][rank:0] loss: 0.266, average forward (0.009935) and backward (0.019310) time: 0.031059, iotime: 0.001561 
2022-08-04 09:42:20,571 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:42:20,572 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:42:22,452 [dl_trainer.py:731] WARNING [ 39][ 7840/  196][rank:0] loss: 0.347, average forward (0.010005) and backward (0.018027) time: 0.033645, iotime: 0.005344 
2022-08-04 09:42:22,464 [dl_trainer.py:634] INFO train iter: 7840, num_batches_per_epoch: 196
2022-08-04 09:42:22,464 [dl_trainer.py:635] INFO Epoch 40, avg train acc: 90.768495, lr: 0.010000, avg loss: 0.270340
2022-08-04 09:42:25,116 [dl_trainer.py:822] INFO Epoch 40, lr: 0.010000, val loss: 0.475272, val top-1 acc: 85.463259, top-5 acc: 99.361022
2022-08-04 09:42:25,183 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.082771, Speed: 386.609909 images/s
2022-08-04 09:42:26,948 [dl_trainer.py:731] WARNING [ 40][ 7880/  196][rank:0] loss: 0.301, average forward (0.008651) and backward (0.020153) time: 0.097198, iotime: 0.001338 
2022-08-04 09:42:27,017 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045837, Speed: 698.121474 images/s
2022-08-04 09:42:28,799 [dl_trainer.py:731] WARNING [ 40][ 7920/  196][rank:0] loss: 0.575, average forward (0.009234) and backward (0.019643) time: 0.030523, iotime: 0.001405 
2022-08-04 09:42:28,852 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045887, Speed: 697.368085 images/s
2022-08-04 09:42:30,550 [dl_trainer.py:731] WARNING [ 40][ 7960/  196][rank:0] loss: 0.238, average forward (0.009304) and backward (0.019651) time: 0.030559, iotime: 0.001371 
2022-08-04 09:42:30,599 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043644, Speed: 733.197628 images/s
2022-08-04 09:42:32,160 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:42:32,160 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:42:32,545 [dl_trainer.py:731] WARNING [ 40][ 8000/  196][rank:0] loss: 0.421, average forward (0.010399) and backward (0.018464) time: 0.034775, iotime: 0.005636 
2022-08-04 09:42:34,203 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048042, Speed: 666.078266 images/s
2022-08-04 09:42:34,204 [dl_trainer.py:634] INFO train iter: 8036, num_batches_per_epoch: 196
2022-08-04 09:42:34,204 [dl_trainer.py:635] INFO Epoch 41, avg train acc: 90.066964, lr: 0.010000, avg loss: 0.277635
2022-08-04 09:42:37,095 [dl_trainer.py:822] INFO Epoch 41, lr: 0.010000, val loss: 0.506084, val top-1 acc: 84.305112, top-5 acc: 99.560703
2022-08-04 09:42:37,273 [dl_trainer.py:731] WARNING [ 41][ 8040/  196][rank:0] loss: 0.202, average forward (0.010661) and backward (0.019051) time: 0.103882, iotime: 0.001544 
2022-08-04 09:42:38,940 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.118415, Speed: 270.235046 images/s
2022-08-04 09:42:39,102 [dl_trainer.py:731] WARNING [ 41][ 8080/  196][rank:0] loss: 0.440, average forward (0.008265) and backward (0.018422) time: 0.028244, iotime: 0.001340 
2022-08-04 09:42:40,703 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044050, Speed: 726.444825 images/s
2022-08-04 09:42:40,855 [dl_trainer.py:731] WARNING [ 41][ 8120/  196][rank:0] loss: 0.292, average forward (0.009206) and backward (0.018387) time: 0.029188, iotime: 0.001368 
2022-08-04 09:42:42,413 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042742, Speed: 748.670250 images/s
2022-08-04 09:42:42,579 [dl_trainer.py:731] WARNING [ 41][ 8160/  196][rank:0] loss: 0.188, average forward (0.009438) and backward (0.016563) time: 0.027680, iotime: 0.001424 
2022-08-04 09:42:43,905 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:42:43,905 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:42:44,498 [dl_trainer.py:731] WARNING [ 41][ 8200/  196][rank:0] loss: 0.118, average forward (0.010230) and backward (0.019316) time: 0.035083, iotime: 0.005266 
2022-08-04 09:42:45,825 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045483, Speed: 703.566390 images/s
2022-08-04 09:42:45,872 [dl_trainer.py:634] INFO train iter: 8232, num_batches_per_epoch: 196
2022-08-04 09:42:45,873 [dl_trainer.py:635] INFO Epoch 42, avg train acc: 90.688776, lr: 0.010000, avg loss: 0.271345
2022-08-04 09:42:48,494 [dl_trainer.py:822] INFO Epoch 42, lr: 0.010000, val loss: 0.456216, val top-1 acc: 85.373403, top-5 acc: 99.510783
2022-08-04 09:42:48,869 [dl_trainer.py:731] WARNING [ 42][ 8240/  196][rank:0] loss: 0.096, average forward (0.009970) and backward (0.018252) time: 0.095994, iotime: 0.001434 
2022-08-04 09:42:50,289 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111596, Speed: 286.749256 images/s
2022-08-04 09:42:50,641 [dl_trainer.py:731] WARNING [ 42][ 8280/  196][rank:0] loss: 0.321, average forward (0.008646) and backward (0.018471) time: 0.028629, iotime: 0.001289 
2022-08-04 09:42:51,931 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041041, Speed: 779.713557 images/s
2022-08-04 09:42:52,285 [dl_trainer.py:731] WARNING [ 42][ 8320/  196][rank:0] loss: 0.373, average forward (0.008895) and backward (0.018497) time: 0.028939, iotime: 0.001331 
2022-08-04 09:42:53,589 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041439, Speed: 772.221244 images/s
2022-08-04 09:42:53,974 [dl_trainer.py:731] WARNING [ 42][ 8360/  196][rank:0] loss: 0.176, average forward (0.008679) and backward (0.018341) time: 0.028540, iotime: 0.001287 
2022-08-04 09:42:55,081 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:42:55,081 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:42:55,895 [dl_trainer.py:731] WARNING [ 42][ 8400/  196][rank:0] loss: 0.233, average forward (0.009654) and backward (0.019895) time: 0.035007, iotime: 0.005199 
2022-08-04 09:42:57,145 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047388, Speed: 675.273445 images/s
2022-08-04 09:42:57,235 [dl_trainer.py:634] INFO train iter: 8428, num_batches_per_epoch: 196
2022-08-04 09:42:57,235 [dl_trainer.py:635] INFO Epoch 43, avg train acc: 91.103316, lr: 0.010000, avg loss: 0.256801
2022-08-04 09:42:59,917 [dl_trainer.py:822] INFO Epoch 43, lr: 0.010000, val loss: 0.419922, val top-1 acc: 86.751198, top-5 acc: 99.460863
2022-08-04 09:43:00,466 [dl_trainer.py:731] WARNING [ 43][ 8440/  196][rank:0] loss: 0.134, average forward (0.010859) and backward (0.019167) time: 0.099011, iotime: 0.001572 
2022-08-04 09:43:01,643 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112437, Speed: 284.602711 images/s
2022-08-04 09:43:02,229 [dl_trainer.py:731] WARNING [ 43][ 8480/  196][rank:0] loss: 0.178, average forward (0.009749) and backward (0.020192) time: 0.031631, iotime: 0.001450 
2022-08-04 09:43:03,482 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045980, Speed: 695.958725 images/s
2022-08-04 09:43:04,093 [dl_trainer.py:731] WARNING [ 43][ 8520/  196][rank:0] loss: 0.199, average forward (0.010241) and backward (0.019353) time: 0.031299, iotime: 0.001449 
2022-08-04 09:43:05,355 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046813, Speed: 683.573947 images/s
2022-08-04 09:43:06,004 [dl_trainer.py:731] WARNING [ 43][ 8560/  196][rank:0] loss: 0.074, average forward (0.009686) and backward (0.020452) time: 0.031801, iotime: 0.001419 
2022-08-04 09:43:06,947 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:43:06,947 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:43:07,935 [dl_trainer.py:731] WARNING [ 43][ 8600/  196][rank:0] loss: 0.087, average forward (0.010300) and backward (0.017592) time: 0.033365, iotime: 0.005219 
2022-08-04 09:43:08,918 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047481, Speed: 673.948292 images/s
2022-08-04 09:43:09,058 [dl_trainer.py:634] INFO train iter: 8624, num_batches_per_epoch: 196
2022-08-04 09:43:09,059 [dl_trainer.py:635] INFO Epoch 44, avg train acc: 91.071429, lr: 0.010000, avg loss: 0.258369
2022-08-04 09:43:11,664 [dl_trainer.py:822] INFO Epoch 44, lr: 0.010000, val loss: 0.445891, val top-1 acc: 86.222045, top-5 acc: 99.470847
2022-08-04 09:43:12,412 [dl_trainer.py:731] WARNING [ 44][ 8640/  196][rank:0] loss: 0.227, average forward (0.009406) and backward (0.019955) time: 0.097373, iotime: 0.001342 
2022-08-04 09:43:13,387 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111734, Speed: 286.393595 images/s
2022-08-04 09:43:14,256 [dl_trainer.py:731] WARNING [ 44][ 8680/  196][rank:0] loss: 0.184, average forward (0.009841) and backward (0.021050) time: 0.032644, iotime: 0.001505 
2022-08-04 09:43:15,218 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045760, Speed: 699.304893 images/s
2022-08-04 09:43:16,052 [dl_trainer.py:731] WARNING [ 44][ 8720/  196][rank:0] loss: 0.292, average forward (0.011421) and backward (0.020363) time: 0.033710, iotime: 0.001645 
2022-08-04 09:43:17,023 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045102, Speed: 709.498681 images/s
2022-08-04 09:43:17,887 [dl_trainer.py:731] WARNING [ 44][ 8760/  196][rank:0] loss: 0.288, average forward (0.010454) and backward (0.018569) time: 0.030734, iotime: 0.001453 
2022-08-04 09:43:18,612 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:43:18,613 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:43:19,818 [dl_trainer.py:731] WARNING [ 44][ 8800/  196][rank:0] loss: 0.479, average forward (0.009249) and backward (0.020602) time: 0.035028, iotime: 0.004928 
2022-08-04 09:43:20,553 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047040, Speed: 680.271351 images/s
2022-08-04 09:43:20,738 [dl_trainer.py:634] INFO train iter: 8820, num_batches_per_epoch: 196
2022-08-04 09:43:20,738 [dl_trainer.py:635] INFO Epoch 45, avg train acc: 90.991709, lr: 0.010000, avg loss: 0.266587
2022-08-04 09:43:23,427 [dl_trainer.py:822] INFO Epoch 45, lr: 0.010000, val loss: 0.442109, val top-1 acc: 86.381789, top-5 acc: 99.500799
2022-08-04 09:43:24,344 [dl_trainer.py:731] WARNING [ 45][ 8840/  196][rank:0] loss: 0.361, average forward (0.009938) and backward (0.019159) time: 0.098112, iotime: 0.001456 
2022-08-04 09:43:25,060 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112665, Speed: 284.028357 images/s
2022-08-04 09:43:26,120 [dl_trainer.py:731] WARNING [ 45][ 8880/  196][rank:0] loss: 0.192, average forward (0.010928) and backward (0.019466) time: 0.032301, iotime: 0.001639 
2022-08-04 09:43:26,889 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045713, Speed: 700.014280 images/s
2022-08-04 09:43:27,897 [dl_trainer.py:731] WARNING [ 45][ 8920/  196][rank:0] loss: 0.190, average forward (0.009741) and backward (0.019308) time: 0.030791, iotime: 0.001495 
2022-08-04 09:43:28,662 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044308, Speed: 722.225258 images/s
2022-08-04 09:43:29,701 [dl_trainer.py:731] WARNING [ 45][ 8960/  196][rank:0] loss: 0.390, average forward (0.009121) and backward (0.018330) time: 0.029048, iotime: 0.001379 
2022-08-04 09:43:30,213 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:43:30,213 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:43:31,758 [dl_trainer.py:731] WARNING [ 45][ 9000/  196][rank:0] loss: 0.417, average forward (0.009758) and backward (0.020024) time: 0.035216, iotime: 0.005165 
2022-08-04 09:43:32,257 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047916, Speed: 667.829277 images/s
2022-08-04 09:43:32,473 [dl_trainer.py:634] INFO train iter: 9016, num_batches_per_epoch: 196
2022-08-04 09:43:32,473 [dl_trainer.py:635] INFO Epoch 46, avg train acc: 90.736607, lr: 0.010000, avg loss: 0.262827
2022-08-04 09:43:35,090 [dl_trainer.py:822] INFO Epoch 46, lr: 0.010000, val loss: 0.532819, val top-1 acc: 83.935703, top-5 acc: 99.241214
2022-08-04 09:43:36,220 [dl_trainer.py:731] WARNING [ 46][ 9040/  196][rank:0] loss: 0.154, average forward (0.009284) and backward (0.018641) time: 0.095786, iotime: 0.001379 
2022-08-04 09:43:36,718 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111537, Speed: 286.899505 images/s
2022-08-04 09:43:38,036 [dl_trainer.py:731] WARNING [ 46][ 9080/  196][rank:0] loss: 0.336, average forward (0.010053) and backward (0.018422) time: 0.030192, iotime: 0.001471 
2022-08-04 09:43:38,558 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045977, Speed: 696.000048 images/s
2022-08-04 09:43:39,833 [dl_trainer.py:731] WARNING [ 46][ 9120/  196][rank:0] loss: 0.378, average forward (0.009325) and backward (0.019822) time: 0.030779, iotime: 0.001392 
2022-08-04 09:43:40,346 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044685, Speed: 716.128275 images/s
2022-08-04 09:43:41,668 [dl_trainer.py:731] WARNING [ 46][ 9160/  196][rank:0] loss: 0.249, average forward (0.011078) and backward (0.019763) time: 0.032702, iotime: 0.001579 
2022-08-04 09:43:41,926 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:43:41,927 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:43:43,673 [dl_trainer.py:731] WARNING [ 46][ 9200/  196][rank:0] loss: 0.118, average forward (0.009789) and backward (0.018553) time: 0.034019, iotime: 0.005398 
2022-08-04 09:43:43,975 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048357, Speed: 661.742541 images/s
2022-08-04 09:43:44,228 [dl_trainer.py:634] INFO train iter: 9212, num_batches_per_epoch: 196
2022-08-04 09:43:44,229 [dl_trainer.py:635] INFO Epoch 47, avg train acc: 91.167092, lr: 0.010000, avg loss: 0.248990
2022-08-04 09:43:46,891 [dl_trainer.py:822] INFO Epoch 47, lr: 0.010000, val loss: 0.458408, val top-1 acc: 85.982428, top-5 acc: 99.450879
2022-08-04 09:43:48,118 [dl_trainer.py:731] WARNING [ 47][ 9240/  196][rank:0] loss: 0.160, average forward (0.010616) and backward (0.017447) time: 0.096485, iotime: 0.001531 
2022-08-04 09:43:48,383 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110193, Speed: 290.399676 images/s
2022-08-04 09:43:49,837 [dl_trainer.py:731] WARNING [ 47][ 9280/  196][rank:0] loss: 0.096, average forward (0.009170) and backward (0.019061) time: 0.029826, iotime: 0.001363 
2022-08-04 09:43:50,101 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042944, Speed: 745.153756 images/s
2022-08-04 09:43:51,559 [dl_trainer.py:731] WARNING [ 47][ 9320/  196][rank:0] loss: 0.326, average forward (0.008741) and backward (0.018144) time: 0.028421, iotime: 0.001303 
2022-08-04 09:43:51,875 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044337, Speed: 721.752023 images/s
2022-08-04 09:43:53,319 [dl_trainer.py:731] WARNING [ 47][ 9360/  196][rank:0] loss: 0.733, average forward (0.010838) and backward (0.018281) time: 0.031025, iotime: 0.001651 
2022-08-04 09:43:53,338 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:43:53,338 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:43:55,352 [dl_trainer.py:731] WARNING [ 47][ 9400/  196][rank:0] loss: 0.213, average forward (0.009762) and backward (0.018724) time: 0.034452, iotime: 0.005689 
2022-08-04 09:43:55,414 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047168, Speed: 678.431211 images/s
2022-08-04 09:43:55,739 [dl_trainer.py:634] INFO train iter: 9408, num_batches_per_epoch: 196
2022-08-04 09:43:55,739 [dl_trainer.py:635] INFO Epoch 48, avg train acc: 90.625000, lr: 0.010000, avg loss: 0.259387
2022-08-04 09:43:58,396 [dl_trainer.py:822] INFO Epoch 48, lr: 0.010000, val loss: 0.426512, val top-1 acc: 86.551518, top-5 acc: 99.470847
2022-08-04 09:43:59,901 [dl_trainer.py:731] WARNING [ 48][ 9440/  196][rank:0] loss: 0.485, average forward (0.008933) and backward (0.020592) time: 0.098120, iotime: 0.001373 
2022-08-04 09:43:59,972 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113942, Speed: 280.845631 images/s
2022-08-04 09:44:01,688 [dl_trainer.py:731] WARNING [ 48][ 9480/  196][rank:0] loss: 0.485, average forward (0.009940) and backward (0.019386) time: 0.031058, iotime: 0.001476 
2022-08-04 09:44:01,738 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044132, Speed: 725.092241 images/s
2022-08-04 09:44:03,561 [dl_trainer.py:731] WARNING [ 48][ 9520/  196][rank:0] loss: 0.236, average forward (0.008964) and backward (0.018435) time: 0.029001, iotime: 0.001367 
2022-08-04 09:44:03,626 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047196, Speed: 678.018840 images/s
2022-08-04 09:44:05,157 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:44:05,157 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:44:05,519 [dl_trainer.py:731] WARNING [ 48][ 9560/  196][rank:0] loss: 0.299, average forward (0.009038) and backward (0.019350) time: 0.033883, iotime: 0.005237 
2022-08-04 09:44:07,072 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045931, Speed: 696.690916 images/s
2022-08-04 09:44:07,242 [dl_trainer.py:731] WARNING [ 48][ 9600/  196][rank:0] loss: 0.125, average forward (0.009980) and backward (0.015807) time: 0.027559, iotime: 0.001508 
2022-08-04 09:44:07,441 [dl_trainer.py:634] INFO train iter: 9604, num_batches_per_epoch: 196
2022-08-04 09:44:07,441 [dl_trainer.py:635] INFO Epoch 49, avg train acc: 91.645408, lr: 0.010000, avg loss: 0.242611
2022-08-04 09:44:10,084 [dl_trainer.py:822] INFO Epoch 49, lr: 0.010000, val loss: 0.453162, val top-1 acc: 86.431709, top-5 acc: 99.460863
2022-08-04 09:44:11,480 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110189, Speed: 290.410012 images/s
2022-08-04 09:44:11,637 [dl_trainer.py:731] WARNING [ 49][ 9640/  196][rank:0] loss: 0.097, average forward (0.011418) and backward (0.017828) time: 0.097392, iotime: 0.001712 
2022-08-04 09:44:13,308 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045667, Speed: 700.719803 images/s
2022-08-04 09:44:13,487 [dl_trainer.py:731] WARNING [ 49][ 9680/  196][rank:0] loss: 0.131, average forward (0.009496) and backward (0.018536) time: 0.029729, iotime: 0.001444 
2022-08-04 09:44:15,045 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043422, Speed: 736.954400 images/s
2022-08-04 09:44:15,208 [dl_trainer.py:731] WARNING [ 49][ 9720/  196][rank:0] loss: 0.469, average forward (0.009859) and backward (0.018864) time: 0.030368, iotime: 0.001414 
2022-08-04 09:44:16,571 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:44:16,571 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:44:17,186 [dl_trainer.py:731] WARNING [ 49][ 9760/  196][rank:0] loss: 0.171, average forward (0.011159) and backward (0.020288) time: 0.037146, iotime: 0.005398 
2022-08-04 09:44:18,545 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046648, Speed: 685.995552 images/s
2022-08-04 09:44:18,919 [dl_trainer.py:731] WARNING [ 49][ 9800/  196][rank:0] loss: 0.117, average forward (0.009802) and backward (0.018630) time: 0.030089, iotime: 0.001414 
2022-08-04 09:44:18,935 [dl_trainer.py:634] INFO train iter: 9800, num_batches_per_epoch: 196
2022-08-04 09:44:18,936 [dl_trainer.py:635] INFO Epoch 50, avg train acc: 91.246811, lr: 0.010000, avg loss: 0.252456
2022-08-04 09:44:21,597 [dl_trainer.py:822] INFO Epoch 50, lr: 0.010000, val loss: 0.465787, val top-1 acc: 85.742812, top-5 acc: 99.470847
2022-08-04 09:44:22,949 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110077, Speed: 290.705094 images/s
2022-08-04 09:44:23,311 [dl_trainer.py:731] WARNING [ 50][ 9840/  196][rank:0] loss: 0.209, average forward (0.008839) and backward (0.017417) time: 0.094874, iotime: 0.001302 
2022-08-04 09:44:24,721 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044278, Speed: 722.706799 images/s
2022-08-04 09:44:25,075 [dl_trainer.py:731] WARNING [ 50][ 9880/  196][rank:0] loss: 0.403, average forward (0.008776) and backward (0.017878) time: 0.028215, iotime: 0.001337 
2022-08-04 09:44:26,455 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043356, Speed: 738.079706 images/s
2022-08-04 09:44:26,853 [dl_trainer.py:731] WARNING [ 50][ 9920/  196][rank:0] loss: 0.359, average forward (0.008849) and backward (0.019673) time: 0.030095, iotime: 0.001346 
2022-08-04 09:44:27,991 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:44:27,991 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:44:28,842 [dl_trainer.py:731] WARNING [ 50][ 9960/  196][rank:0] loss: 0.509, average forward (0.010232) and backward (0.019707) time: 0.035503, iotime: 0.005288 
2022-08-04 09:44:30,090 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048442, Speed: 660.587847 images/s
2022-08-04 09:44:30,537 [dl_trainer.py:634] INFO train iter: 9996, num_batches_per_epoch: 196
2022-08-04 09:44:30,538 [dl_trainer.py:635] INFO Epoch 51, avg train acc: 91.980230, lr: 0.010000, avg loss: 0.227291
2022-08-04 09:44:33,222 [dl_trainer.py:822] INFO Epoch 51, lr: 0.010000, val loss: 0.554539, val top-1 acc: 83.636182, top-5 acc: 99.181310
2022-08-04 09:44:33,395 [dl_trainer.py:731] WARNING [ 51][10000/  196][rank:0] loss: 0.126, average forward (0.009270) and backward (0.019988) time: 0.098033, iotime: 0.001364 
2022-08-04 09:44:34,615 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113104, Speed: 282.926439 images/s
2022-08-04 09:44:35,225 [dl_trainer.py:731] WARNING [ 51][10040/  196][rank:0] loss: 0.167, average forward (0.009124) and backward (0.020329) time: 0.031089, iotime: 0.001418 
2022-08-04 09:44:36,438 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045581, Speed: 702.049919 images/s
2022-08-04 09:44:37,086 [dl_trainer.py:731] WARNING [ 51][10080/  196][rank:0] loss: 0.151, average forward (0.010043) and backward (0.021109) time: 0.032884, iotime: 0.001469 
2022-08-04 09:44:38,288 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046225, Speed: 692.260385 images/s
2022-08-04 09:44:38,939 [dl_trainer.py:731] WARNING [ 51][10120/  196][rank:0] loss: 0.378, average forward (0.009641) and backward (0.021463) time: 0.032809, iotime: 0.001463 
2022-08-04 09:44:39,881 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:44:39,881 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:44:40,943 [dl_trainer.py:731] WARNING [ 51][10160/  196][rank:0] loss: 0.201, average forward (0.009371) and backward (0.020095) time: 0.035170, iotime: 0.005462 
2022-08-04 09:44:41,870 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047745, Speed: 670.229317 images/s
2022-08-04 09:44:42,390 [dl_trainer.py:634] INFO train iter: 10192, num_batches_per_epoch: 196
2022-08-04 09:44:42,390 [dl_trainer.py:635] INFO Epoch 52, avg train acc: 91.358418, lr: 0.010000, avg loss: 0.240427
2022-08-04 09:44:45,025 [dl_trainer.py:822] INFO Epoch 52, lr: 0.010000, val loss: 0.487055, val top-1 acc: 85.233626, top-5 acc: 99.321086
2022-08-04 09:44:45,392 [dl_trainer.py:731] WARNING [ 52][10200/  196][rank:0] loss: 0.247, average forward (0.010181) and backward (0.019615) time: 0.097863, iotime: 0.001431 
2022-08-04 09:44:46,403 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113318, Speed: 282.390458 images/s
2022-08-04 09:44:47,285 [dl_trainer.py:731] WARNING [ 52][10240/  196][rank:0] loss: 0.430, average forward (0.009380) and backward (0.019668) time: 0.030691, iotime: 0.001396 
2022-08-04 09:44:48,234 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045776, Speed: 699.055400 images/s
2022-08-04 09:44:49,082 [dl_trainer.py:731] WARNING [ 52][10280/  196][rank:0] loss: 0.501, average forward (0.009263) and backward (0.018412) time: 0.029330, iotime: 0.001418 
2022-08-04 09:44:50,010 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044382, Speed: 721.018253 images/s
2022-08-04 09:44:50,889 [dl_trainer.py:731] WARNING [ 52][10320/  196][rank:0] loss: 0.178, average forward (0.010121) and backward (0.019925) time: 0.031781, iotime: 0.001483 
2022-08-04 09:44:51,610 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:44:51,611 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:44:52,920 [dl_trainer.py:731] WARNING [ 52][10360/  196][rank:0] loss: 0.228, average forward (0.009801) and backward (0.020204) time: 0.035274, iotime: 0.005002 
2022-08-04 09:44:53,635 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048312, Speed: 662.357749 images/s
2022-08-04 09:44:54,205 [dl_trainer.py:634] INFO train iter: 10388, num_batches_per_epoch: 196
2022-08-04 09:44:54,205 [dl_trainer.py:635] INFO Epoch 53, avg train acc: 92.362883, lr: 0.010000, avg loss: 0.215369
2022-08-04 09:44:56,864 [dl_trainer.py:822] INFO Epoch 53, lr: 0.010000, val loss: 0.474720, val top-1 acc: 85.513179, top-5 acc: 99.371006
2022-08-04 09:44:57,409 [dl_trainer.py:731] WARNING [ 53][10400/  196][rank:0] loss: 0.134, average forward (0.011880) and backward (0.020640) time: 0.101012, iotime: 0.001665 
2022-08-04 09:44:58,140 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112595, Speed: 284.203868 images/s
2022-08-04 09:44:59,166 [dl_trainer.py:731] WARNING [ 53][10440/  196][rank:0] loss: 0.143, average forward (0.009961) and backward (0.020365) time: 0.032040, iotime: 0.001454 
2022-08-04 09:44:59,896 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043882, Speed: 729.223524 images/s
2022-08-04 09:45:00,978 [dl_trainer.py:731] WARNING [ 53][10480/  196][rank:0] loss: 0.099, average forward (0.009936) and backward (0.017691) time: 0.029276, iotime: 0.001383 
2022-08-04 09:45:01,745 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046230, Speed: 692.190679 images/s
2022-08-04 09:45:02,832 [dl_trainer.py:731] WARNING [ 53][10520/  196][rank:0] loss: 0.155, average forward (0.008744) and backward (0.020703) time: 0.031007, iotime: 0.001328 
2022-08-04 09:45:03,328 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:45:03,329 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:45:04,809 [dl_trainer.py:731] WARNING [ 53][10560/  196][rank:0] loss: 0.461, average forward (0.008845) and backward (0.019586) time: 0.033851, iotime: 0.005166 
2022-08-04 09:45:05,284 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047165, Speed: 678.468843 images/s
2022-08-04 09:45:05,855 [dl_trainer.py:634] INFO train iter: 10584, num_batches_per_epoch: 196
2022-08-04 09:45:05,856 [dl_trainer.py:635] INFO Epoch 54, avg train acc: 92.554209, lr: 0.010000, avg loss: 0.222304
2022-08-04 09:45:08,481 [dl_trainer.py:822] INFO Epoch 54, lr: 0.010000, val loss: 0.463745, val top-1 acc: 85.782748, top-5 acc: 99.400958
2022-08-04 09:45:09,205 [dl_trainer.py:731] WARNING [ 54][10600/  196][rank:0] loss: 0.295, average forward (0.009892) and backward (0.019433) time: 0.097154, iotime: 0.001402 
2022-08-04 09:45:09,719 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110868, Speed: 288.631446 images/s
2022-08-04 09:45:11,083 [dl_trainer.py:731] WARNING [ 54][10640/  196][rank:0] loss: 0.169, average forward (0.010950) and backward (0.021559) time: 0.034419, iotime: 0.001634 
2022-08-04 09:45:11,604 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047117, Speed: 679.165961 images/s
2022-08-04 09:45:12,947 [dl_trainer.py:731] WARNING [ 54][10680/  196][rank:0] loss: 0.308, average forward (0.008966) and backward (0.020251) time: 0.030751, iotime: 0.001309 
2022-08-04 09:45:13,461 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046404, Speed: 689.598764 images/s
2022-08-04 09:45:14,807 [dl_trainer.py:731] WARNING [ 54][10720/  196][rank:0] loss: 0.209, average forward (0.009801) and backward (0.018012) time: 0.029513, iotime: 0.001454 
2022-08-04 09:45:15,068 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:45:15,069 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:45:16,747 [dl_trainer.py:731] WARNING [ 54][10760/  196][rank:0] loss: 0.255, average forward (0.010065) and backward (0.018852) time: 0.034600, iotime: 0.005405 
2022-08-04 09:45:17,017 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047394, Speed: 675.188973 images/s
2022-08-04 09:45:17,610 [dl_trainer.py:634] INFO train iter: 10780, num_batches_per_epoch: 196
2022-08-04 09:45:17,610 [dl_trainer.py:635] INFO Epoch 55, avg train acc: 92.458546, lr: 0.010000, avg loss: 0.213432
2022-08-04 09:45:20,253 [dl_trainer.py:822] INFO Epoch 55, lr: 0.010000, val loss: 0.569356, val top-1 acc: 83.835863, top-5 acc: 99.271166
2022-08-04 09:45:21,177 [dl_trainer.py:731] WARNING [ 55][10800/  196][rank:0] loss: 0.118, average forward (0.009479) and backward (0.019675) time: 0.096921, iotime: 0.001376 
2022-08-04 09:45:21,424 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110156, Speed: 290.496847 images/s
2022-08-04 09:45:22,979 [dl_trainer.py:731] WARNING [ 55][10840/  196][rank:0] loss: 0.159, average forward (0.009260) and backward (0.019873) time: 0.030763, iotime: 0.001403 
2022-08-04 09:45:23,245 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045508, Speed: 703.175137 images/s
2022-08-04 09:45:24,813 [dl_trainer.py:731] WARNING [ 55][10880/  196][rank:0] loss: 0.294, average forward (0.009610) and backward (0.020110) time: 0.031410, iotime: 0.001442 
2022-08-04 09:45:25,092 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046176, Speed: 693.000001 images/s
2022-08-04 09:45:26,692 [dl_trainer.py:731] WARNING [ 55][10920/  196][rank:0] loss: 0.057, average forward (0.009155) and backward (0.021247) time: 0.031988, iotime: 0.001362 
2022-08-04 09:45:26,712 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:45:26,712 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:45:28,690 [dl_trainer.py:731] WARNING [ 55][10960/  196][rank:0] loss: 0.233, average forward (0.010340) and backward (0.019869) time: 0.035978, iotime: 0.005504 
2022-08-04 09:45:28,755 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048821, Speed: 655.459813 images/s
2022-08-04 09:45:29,397 [dl_trainer.py:634] INFO train iter: 10976, num_batches_per_epoch: 196
2022-08-04 09:45:29,397 [dl_trainer.py:635] INFO Epoch 56, avg train acc: 92.554209, lr: 0.010000, avg loss: 0.217600
2022-08-04 09:45:32,117 [dl_trainer.py:822] INFO Epoch 56, lr: 0.010000, val loss: 0.443292, val top-1 acc: 86.581470, top-5 acc: 99.390974
2022-08-04 09:45:33,138 [dl_trainer.py:731] WARNING [ 56][11000/  196][rank:0] loss: 0.220, average forward (0.009795) and backward (0.018145) time: 0.098241, iotime: 0.001460 
2022-08-04 09:45:33,192 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110920, Speed: 288.497050 images/s
2022-08-04 09:45:34,919 [dl_trainer.py:731] WARNING [ 56][11040/  196][rank:0] loss: 0.267, average forward (0.009320) and backward (0.018175) time: 0.029110, iotime: 0.001383 
2022-08-04 09:45:34,977 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044603, Speed: 717.436759 images/s
2022-08-04 09:45:36,662 [dl_trainer.py:731] WARNING [ 56][11080/  196][rank:0] loss: 0.223, average forward (0.010997) and backward (0.018670) time: 0.031438, iotime: 0.001493 
2022-08-04 09:45:36,721 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043603, Speed: 733.893503 images/s
2022-08-04 09:45:38,292 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:45:38,293 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:45:38,656 [dl_trainer.py:731] WARNING [ 56][11120/  196][rank:0] loss: 0.307, average forward (0.011318) and backward (0.020888) time: 0.038148, iotime: 0.005641 
2022-08-04 09:45:40,318 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047930, Speed: 667.642448 images/s
2022-08-04 09:45:40,497 [dl_trainer.py:731] WARNING [ 56][11160/  196][rank:0] loss: 0.526, average forward (0.010670) and backward (0.019769) time: 0.032235, iotime: 0.001537 
2022-08-04 09:45:41,053 [dl_trainer.py:634] INFO train iter: 11172, num_batches_per_epoch: 196
2022-08-04 09:45:41,053 [dl_trainer.py:635] INFO Epoch 57, avg train acc: 92.617985, lr: 0.010000, avg loss: 0.216155
2022-08-04 09:45:43,707 [dl_trainer.py:822] INFO Epoch 57, lr: 0.010000, val loss: 0.409748, val top-1 acc: 87.080671, top-5 acc: 99.480831
2022-08-04 09:45:44,860 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113530, Speed: 281.863903 images/s
2022-08-04 09:45:45,039 [dl_trainer.py:731] WARNING [ 57][11200/  196][rank:0] loss: 0.062, average forward (0.010507) and backward (0.020667) time: 0.099407, iotime: 0.001557 
2022-08-04 09:45:46,633 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044323, Speed: 721.971281 images/s
2022-08-04 09:45:46,808 [dl_trainer.py:731] WARNING [ 57][11240/  196][rank:0] loss: 0.339, average forward (0.010599) and backward (0.018986) time: 0.031351, iotime: 0.001522 
2022-08-04 09:45:48,459 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045640, Speed: 701.144789 images/s
2022-08-04 09:45:48,633 [dl_trainer.py:731] WARNING [ 57][11280/  196][rank:0] loss: 0.313, average forward (0.010584) and backward (0.020557) time: 0.032918, iotime: 0.001517 
2022-08-04 09:45:50,029 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:45:50,029 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:45:50,626 [dl_trainer.py:731] WARNING [ 57][11320/  196][rank:0] loss: 0.313, average forward (0.008928) and backward (0.019991) time: 0.034557, iotime: 0.005383 
2022-08-04 09:45:52,010 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047330, Speed: 676.108293 images/s
2022-08-04 09:45:52,439 [dl_trainer.py:731] WARNING [ 57][11360/  196][rank:0] loss: 0.255, average forward (0.009270) and backward (0.020248) time: 0.031114, iotime: 0.001371 
2022-08-04 09:45:52,819 [dl_trainer.py:634] INFO train iter: 11368, num_batches_per_epoch: 196
2022-08-04 09:45:52,819 [dl_trainer.py:635] INFO Epoch 58, avg train acc: 92.378827, lr: 0.010000, avg loss: 0.215463
2022-08-04 09:45:55,509 [dl_trainer.py:822] INFO Epoch 58, lr: 0.010000, val loss: 0.517673, val top-1 acc: 85.363419, top-5 acc: 99.371006
2022-08-04 09:45:56,545 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113370, Speed: 282.261099 images/s
2022-08-04 09:45:56,932 [dl_trainer.py:731] WARNING [ 58][11400/  196][rank:0] loss: 0.136, average forward (0.010108) and backward (0.018479) time: 0.098163, iotime: 0.001483 
2022-08-04 09:45:58,326 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044501, Speed: 719.077249 images/s
2022-08-04 09:45:58,698 [dl_trainer.py:731] WARNING [ 58][11440/  196][rank:0] loss: 0.162, average forward (0.011273) and backward (0.017216) time: 0.030245, iotime: 0.001516 
2022-08-04 09:46:00,064 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043450, Speed: 736.474301 images/s
2022-08-04 09:46:00,463 [dl_trainer.py:731] WARNING [ 58][11480/  196][rank:0] loss: 0.376, average forward (0.009415) and backward (0.017427) time: 0.028454, iotime: 0.001377 
2022-08-04 09:46:01,566 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:46:01,566 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:46:02,418 [dl_trainer.py:731] WARNING [ 58][11520/  196][rank:0] loss: 0.059, average forward (0.008655) and backward (0.019073) time: 0.033216, iotime: 0.005234 
2022-08-04 09:46:03,602 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047152, Speed: 678.656932 images/s
2022-08-04 09:46:04,205 [dl_trainer.py:731] WARNING [ 58][11560/  196][rank:0] loss: 0.029, average forward (0.009641) and backward (0.018914) time: 0.030178, iotime: 0.001389 
2022-08-04 09:46:04,384 [dl_trainer.py:634] INFO train iter: 11564, num_batches_per_epoch: 196
2022-08-04 09:46:04,385 [dl_trainer.py:635] INFO Epoch 59, avg train acc: 92.729592, lr: 0.010000, avg loss: 0.216349
2022-08-04 09:46:07,091 [dl_trainer.py:822] INFO Epoch 59, lr: 0.010000, val loss: 0.416895, val top-1 acc: 87.569888, top-5 acc: 99.460863
2022-08-04 09:46:08,169 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114158, Speed: 280.313341 images/s
2022-08-04 09:46:08,822 [dl_trainer.py:731] WARNING [ 59][11600/  196][rank:0] loss: 0.192, average forward (0.010687) and backward (0.021738) time: 0.102035, iotime: 0.001601 
2022-08-04 09:46:09,990 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045515, Speed: 703.070251 images/s
2022-08-04 09:46:10,619 [dl_trainer.py:731] WARNING [ 59][11640/  196][rank:0] loss: 0.194, average forward (0.009126) and backward (0.020183) time: 0.030917, iotime: 0.001371 
2022-08-04 09:46:11,806 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045394, Speed: 704.934205 images/s
2022-08-04 09:46:12,378 [dl_trainer.py:731] WARNING [ 59][11680/  196][rank:0] loss: 0.244, average forward (0.009273) and backward (0.018463) time: 0.029405, iotime: 0.001423 
2022-08-04 09:46:13,294 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:46:13,295 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:46:14,267 [dl_trainer.py:731] WARNING [ 59][11720/  196][rank:0] loss: 0.328, average forward (0.009433) and backward (0.018955) time: 0.033805, iotime: 0.005168 
2022-08-04 09:46:15,213 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045373, Speed: 705.265822 images/s
2022-08-04 09:46:16,023 [dl_trainer.py:731] WARNING [ 59][11760/  196][rank:0] loss: 0.261, average forward (0.010025) and backward (0.017599) time: 0.029379, iotime: 0.001512 
2022-08-04 09:46:16,029 [dl_trainer.py:634] INFO train iter: 11760, num_batches_per_epoch: 196
2022-08-04 09:46:16,029 [dl_trainer.py:635] INFO Epoch 60, avg train acc: 92.761480, lr: 0.010000, avg loss: 0.207023
2022-08-04 09:46:18,687 [dl_trainer.py:822] INFO Epoch 60, lr: 0.010000, val loss: 0.443753, val top-1 acc: 86.821086, top-5 acc: 99.500799
2022-08-04 09:46:19,686 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111803, Speed: 286.218147 images/s
2022-08-04 09:46:20,445 [dl_trainer.py:731] WARNING [ 60][11800/  196][rank:0] loss: 0.418, average forward (0.009887) and backward (0.018971) time: 0.098044, iotime: 0.001403 
2022-08-04 09:46:21,276 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.039734, Speed: 805.357307 images/s
2022-08-04 09:46:22,129 [dl_trainer.py:731] WARNING [ 60][11840/  196][rank:0] loss: 0.337, average forward (0.009742) and backward (0.016170) time: 0.027493, iotime: 0.001342 
2022-08-04 09:46:23,078 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045042, Speed: 710.450906 images/s
2022-08-04 09:46:23,922 [dl_trainer.py:731] WARNING [ 60][11880/  196][rank:0] loss: 0.072, average forward (0.009795) and backward (0.019529) time: 0.031129, iotime: 0.001559 
2022-08-04 09:46:24,621 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:46:24,621 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:46:25,868 [dl_trainer.py:731] WARNING [ 60][11920/  196][rank:0] loss: 0.200, average forward (0.010068) and backward (0.018498) time: 0.034258, iotime: 0.005425 
2022-08-04 09:46:26,574 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046605, Speed: 686.623543 images/s
2022-08-04 09:46:27,531 [dl_trainer.py:634] INFO train iter: 11956, num_batches_per_epoch: 196
2022-08-04 09:46:27,532 [dl_trainer.py:635] INFO Epoch 61, avg train acc: 92.490434, lr: 0.010000, avg loss: 0.218149
2022-08-04 09:46:30,209 [dl_trainer.py:822] INFO Epoch 61, lr: 0.010000, val loss: 0.436493, val top-1 acc: 87.140575, top-5 acc: 99.460863
2022-08-04 09:46:30,375 [dl_trainer.py:731] WARNING [ 61][11960/  196][rank:0] loss: 0.048, average forward (0.009178) and backward (0.017742) time: 0.095531, iotime: 0.001352 
2022-08-04 09:46:31,160 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114633, Speed: 279.152425 images/s
2022-08-04 09:46:32,256 [dl_trainer.py:731] WARNING [ 61][12000/  196][rank:0] loss: 0.380, average forward (0.009578) and backward (0.019596) time: 0.030825, iotime: 0.001409 
2022-08-04 09:46:32,936 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044387, Speed: 720.930242 images/s
2022-08-04 09:46:33,971 [dl_trainer.py:731] WARNING [ 61][12040/  196][rank:0] loss: 0.103, average forward (0.008759) and backward (0.019281) time: 0.029574, iotime: 0.001303 
2022-08-04 09:46:34,662 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043123, Speed: 742.064308 images/s
2022-08-04 09:46:35,740 [dl_trainer.py:731] WARNING [ 61][12080/  196][rank:0] loss: 0.190, average forward (0.010477) and backward (0.018889) time: 0.031121, iotime: 0.001502 
2022-08-04 09:46:36,202 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:46:36,203 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:46:37,676 [dl_trainer.py:731] WARNING [ 61][12120/  196][rank:0] loss: 0.101, average forward (0.011347) and backward (0.019065) time: 0.036164, iotime: 0.005450 
2022-08-04 09:46:38,126 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046166, Speed: 693.157385 images/s
2022-08-04 09:46:38,988 [dl_trainer.py:634] INFO train iter: 12152, num_batches_per_epoch: 196
2022-08-04 09:46:38,988 [dl_trainer.py:635] INFO Epoch 62, avg train acc: 93.000638, lr: 0.010000, avg loss: 0.205802
2022-08-04 09:46:41,664 [dl_trainer.py:822] INFO Epoch 62, lr: 0.010000, val loss: 0.497296, val top-1 acc: 85.553115, top-5 acc: 99.460863
2022-08-04 09:46:42,010 [dl_trainer.py:731] WARNING [ 62][12160/  196][rank:0] loss: 0.131, average forward (0.009629) and backward (0.018472) time: 0.097191, iotime: 0.001412 
2022-08-04 09:46:42,527 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110009, Speed: 290.884937 images/s
2022-08-04 09:46:43,852 [dl_trainer.py:731] WARNING [ 62][12200/  196][rank:0] loss: 0.246, average forward (0.009585) and backward (0.020264) time: 0.031660, iotime: 0.001565 
2022-08-04 09:46:44,365 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045951, Speed: 696.395839 images/s
2022-08-04 09:46:45,651 [dl_trainer.py:731] WARNING [ 62][12240/  196][rank:0] loss: 0.238, average forward (0.009399) and backward (0.018047) time: 0.029068, iotime: 0.001384 
2022-08-04 09:46:46,164 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044966, Speed: 711.654834 images/s
2022-08-04 09:46:47,457 [dl_trainer.py:731] WARNING [ 62][12280/  196][rank:0] loss: 0.443, average forward (0.009780) and backward (0.020534) time: 0.031936, iotime: 0.001372 
2022-08-04 09:46:47,708 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:46:47,708 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:46:49,320 [dl_trainer.py:731] WARNING [ 62][12320/  196][rank:0] loss: 0.288, average forward (0.010352) and backward (0.017223) time: 0.033203, iotime: 0.005362 
2022-08-04 09:46:49,580 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045525, Speed: 702.903898 images/s
2022-08-04 09:46:50,529 [dl_trainer.py:634] INFO train iter: 12348, num_batches_per_epoch: 196
2022-08-04 09:46:50,529 [dl_trainer.py:635] INFO Epoch 63, avg train acc: 92.904974, lr: 0.010000, avg loss: 0.190680
2022-08-04 09:46:53,199 [dl_trainer.py:822] INFO Epoch 63, lr: 0.010000, val loss: 0.450467, val top-1 acc: 86.471645, top-5 acc: 99.540735
2022-08-04 09:46:53,759 [dl_trainer.py:731] WARNING [ 63][12360/  196][rank:0] loss: 0.410, average forward (0.010540) and backward (0.016470) time: 0.095495, iotime: 0.001413 
2022-08-04 09:46:54,068 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112190, Speed: 285.229180 images/s
2022-08-04 09:46:55,639 [dl_trainer.py:731] WARNING [ 63][12400/  196][rank:0] loss: 0.230, average forward (0.008355) and backward (0.020178) time: 0.030092, iotime: 0.001341 
2022-08-04 09:46:55,941 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046811, Speed: 683.595620 images/s
2022-08-04 09:46:57,440 [dl_trainer.py:731] WARNING [ 63][12440/  196][rank:0] loss: 0.340, average forward (0.010377) and backward (0.019988) time: 0.032149, iotime: 0.001528 
2022-08-04 09:46:57,734 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044809, Speed: 714.136237 images/s
2022-08-04 09:46:59,311 [dl_trainer.py:731] WARNING [ 63][12480/  196][rank:0] loss: 0.291, average forward (0.009622) and backward (0.020330) time: 0.031615, iotime: 0.001426 
2022-08-04 09:46:59,328 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:46:59,329 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:47:01,265 [dl_trainer.py:731] WARNING [ 63][12520/  196][rank:0] loss: 0.074, average forward (0.010467) and backward (0.020638) time: 0.036651, iotime: 0.005271 
2022-08-04 09:47:01,334 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047986, Speed: 666.856148 images/s
2022-08-04 09:47:02,374 [dl_trainer.py:634] INFO train iter: 12544, num_batches_per_epoch: 196
2022-08-04 09:47:02,375 [dl_trainer.py:635] INFO Epoch 64, avg train acc: 92.777423, lr: 0.010000, avg loss: 0.206387
2022-08-04 09:47:05,044 [dl_trainer.py:822] INFO Epoch 64, lr: 0.010000, val loss: 0.448532, val top-1 acc: 86.880990, top-5 acc: 99.241214
2022-08-04 09:47:05,804 [dl_trainer.py:731] WARNING [ 64][12560/  196][rank:0] loss: 0.191, average forward (0.011218) and backward (0.018532) time: 0.098943, iotime: 0.001661 
2022-08-04 09:47:05,871 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113434, Speed: 282.103572 images/s
2022-08-04 09:47:07,630 [dl_trainer.py:731] WARNING [ 64][12600/  196][rank:0] loss: 0.243, average forward (0.011591) and backward (0.018676) time: 0.032152, iotime: 0.001617 
2022-08-04 09:47:07,677 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045136, Speed: 708.963603 images/s
2022-08-04 09:47:09,320 [dl_trainer.py:731] WARNING [ 64][12640/  196][rank:0] loss: 0.384, average forward (0.009845) and backward (0.019601) time: 0.031087, iotime: 0.001399 
2022-08-04 09:47:09,384 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042660, Speed: 750.108962 images/s
2022-08-04 09:47:10,978 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:47:10,978 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:47:11,353 [dl_trainer.py:731] WARNING [ 64][12680/  196][rank:0] loss: 0.298, average forward (0.009827) and backward (0.020213) time: 0.035789, iotime: 0.005488 
2022-08-04 09:47:12,997 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048160, Speed: 664.457882 images/s
2022-08-04 09:47:13,179 [dl_trainer.py:731] WARNING [ 64][12720/  196][rank:0] loss: 0.058, average forward (0.009621) and backward (0.018083) time: 0.029337, iotime: 0.001405 
2022-08-04 09:47:14,142 [dl_trainer.py:634] INFO train iter: 12740, num_batches_per_epoch: 196
2022-08-04 09:47:14,142 [dl_trainer.py:635] INFO Epoch 65, avg train acc: 92.904974, lr: 0.010000, avg loss: 0.199033
2022-08-04 09:47:16,737 [dl_trainer.py:822] INFO Epoch 65, lr: 0.010000, val loss: 0.491469, val top-1 acc: 85.303514, top-5 acc: 99.311102
2022-08-04 09:47:17,528 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113266, Speed: 282.522018 images/s
2022-08-04 09:47:17,719 [dl_trainer.py:731] WARNING [ 65][12760/  196][rank:0] loss: 0.188, average forward (0.011117) and backward (0.018113) time: 0.096066, iotime: 0.001607 
2022-08-04 09:47:19,312 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044579, Speed: 717.831686 images/s
2022-08-04 09:47:19,490 [dl_trainer.py:731] WARNING [ 65][12800/  196][rank:0] loss: 0.207, average forward (0.008734) and backward (0.017843) time: 0.028110, iotime: 0.001302 
2022-08-04 09:47:21,122 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045234, Speed: 707.430587 images/s
2022-08-04 09:47:21,279 [dl_trainer.py:731] WARNING [ 65][12840/  196][rank:0] loss: 0.197, average forward (0.010264) and backward (0.019379) time: 0.031330, iotime: 0.001436 
2022-08-04 09:47:22,594 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:47:22,594 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:47:23,157 [dl_trainer.py:731] WARNING [ 65][12880/  196][rank:0] loss: 0.194, average forward (0.009822) and backward (0.020287) time: 0.035502, iotime: 0.005117 
2022-08-04 09:47:24,534 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045479, Speed: 703.614880 images/s
2022-08-04 09:47:24,942 [dl_trainer.py:731] WARNING [ 65][12920/  196][rank:0] loss: 0.070, average forward (0.010112) and backward (0.019686) time: 0.031491, iotime: 0.001439 
2022-08-04 09:47:25,660 [dl_trainer.py:634] INFO train iter: 12936, num_batches_per_epoch: 196
2022-08-04 09:47:25,660 [dl_trainer.py:635] INFO Epoch 66, avg train acc: 93.463010, lr: 0.010000, avg loss: 0.191732
2022-08-04 09:47:28,275 [dl_trainer.py:822] INFO Epoch 66, lr: 0.010000, val loss: 0.445056, val top-1 acc: 86.871006, top-5 acc: 99.490815
2022-08-04 09:47:28,992 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111439, Speed: 287.152532 images/s
2022-08-04 09:47:29,400 [dl_trainer.py:731] WARNING [ 66][12960/  196][rank:0] loss: 0.359, average forward (0.009311) and backward (0.019675) time: 0.096521, iotime: 0.001393 
2022-08-04 09:47:30,832 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045980, Speed: 695.961612 images/s
2022-08-04 09:47:31,213 [dl_trainer.py:731] WARNING [ 66][13000/  196][rank:0] loss: 0.095, average forward (0.008678) and backward (0.018023) time: 0.028311, iotime: 0.001388 
2022-08-04 09:47:32,649 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045414, Speed: 704.627592 images/s
2022-08-04 09:47:33,033 [dl_trainer.py:731] WARNING [ 66][13040/  196][rank:0] loss: 0.186, average forward (0.009144) and backward (0.019918) time: 0.030702, iotime: 0.001389 
2022-08-04 09:47:34,187 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:47:34,187 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:47:34,930 [dl_trainer.py:731] WARNING [ 66][13080/  196][rank:0] loss: 0.143, average forward (0.010931) and backward (0.018996) time: 0.035422, iotime: 0.005216 
2022-08-04 09:47:36,094 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045899, Speed: 697.184874 images/s
2022-08-04 09:47:36,708 [dl_trainer.py:731] WARNING [ 66][13120/  196][rank:0] loss: 0.099, average forward (0.010212) and backward (0.017727) time: 0.029763, iotime: 0.001570 
2022-08-04 09:47:37,278 [dl_trainer.py:634] INFO train iter: 13132, num_batches_per_epoch: 196
2022-08-04 09:47:37,278 [dl_trainer.py:635] INFO Epoch 67, avg train acc: 93.606505, lr: 0.010000, avg loss: 0.190239
2022-08-04 09:47:39,966 [dl_trainer.py:822] INFO Epoch 67, lr: 0.010000, val loss: 0.412697, val top-1 acc: 87.679712, top-5 acc: 99.510783
2022-08-04 09:47:40,615 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113000, Speed: 283.185394 images/s
2022-08-04 09:47:41,289 [dl_trainer.py:731] WARNING [ 67][13160/  196][rank:0] loss: 0.241, average forward (0.010404) and backward (0.020111) time: 0.099546, iotime: 0.001511 
2022-08-04 09:47:42,502 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047175, Speed: 678.330582 images/s
2022-08-04 09:47:43,144 [dl_trainer.py:731] WARNING [ 67][13200/  196][rank:0] loss: 0.035, average forward (0.008991) and backward (0.020862) time: 0.031417, iotime: 0.001334 
2022-08-04 09:47:44,298 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044884, Speed: 712.945397 images/s
2022-08-04 09:47:44,928 [dl_trainer.py:731] WARNING [ 67][13240/  196][rank:0] loss: 0.431, average forward (0.009031) and backward (0.019378) time: 0.029955, iotime: 0.001319 
2022-08-04 09:47:45,864 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:47:45,865 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:47:46,897 [dl_trainer.py:731] WARNING [ 67][13280/  196][rank:0] loss: 0.151, average forward (0.009041) and backward (0.017796) time: 0.032081, iotime: 0.004983 
2022-08-04 09:47:47,822 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046972, Speed: 681.261509 images/s
2022-08-04 09:47:48,640 [dl_trainer.py:731] WARNING [ 67][13320/  196][rank:0] loss: 0.165, average forward (0.009233) and backward (0.018937) time: 0.029799, iotime: 0.001399 
2022-08-04 09:47:49,035 [dl_trainer.py:634] INFO train iter: 13328, num_batches_per_epoch: 196
2022-08-04 09:47:49,036 [dl_trainer.py:635] INFO Epoch 68, avg train acc: 93.415179, lr: 0.010000, avg loss: 0.188645
2022-08-04 09:47:51,698 [dl_trainer.py:822] INFO Epoch 68, lr: 0.010000, val loss: 0.500601, val top-1 acc: 85.772764, top-5 acc: 99.261182
2022-08-04 09:47:52,310 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112172, Speed: 285.276012 images/s
2022-08-04 09:47:53,133 [dl_trainer.py:731] WARNING [ 68][13360/  196][rank:0] loss: 0.156, average forward (0.009562) and backward (0.019669) time: 0.097965, iotime: 0.001395 
2022-08-04 09:47:54,042 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043285, Speed: 739.282965 images/s
2022-08-04 09:47:54,852 [dl_trainer.py:731] WARNING [ 68][13400/  196][rank:0] loss: 0.081, average forward (0.010819) and backward (0.017832) time: 0.030417, iotime: 0.001512 
2022-08-04 09:47:55,782 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043499, Speed: 735.655969 images/s
2022-08-04 09:47:56,650 [dl_trainer.py:731] WARNING [ 68][13440/  196][rank:0] loss: 0.329, average forward (0.011023) and backward (0.018935) time: 0.031876, iotime: 0.001659 
2022-08-04 09:47:57,376 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:47:57,376 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:47:58,540 [dl_trainer.py:731] WARNING [ 68][13480/  196][rank:0] loss: 0.266, average forward (0.009325) and backward (0.019438) time: 0.034152, iotime: 0.005145 
2022-08-04 09:47:59,303 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046929, Speed: 681.879658 images/s
2022-08-04 09:48:00,438 [dl_trainer.py:731] WARNING [ 68][13520/  196][rank:0] loss: 0.146, average forward (0.010722) and backward (0.022012) time: 0.034503, iotime: 0.001508 
2022-08-04 09:48:00,645 [dl_trainer.py:634] INFO train iter: 13524, num_batches_per_epoch: 196
2022-08-04 09:48:00,645 [dl_trainer.py:635] INFO Epoch 69, avg train acc: 93.319515, lr: 0.010000, avg loss: 0.183782
2022-08-04 09:48:03,313 [dl_trainer.py:822] INFO Epoch 69, lr: 0.010000, val loss: 0.586784, val top-1 acc: 84.345048, top-5 acc: 99.261182
2022-08-04 09:48:03,898 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114874, Speed: 278.565288 images/s
2022-08-04 09:48:05,020 [dl_trainer.py:731] WARNING [ 69][13560/  196][rank:0] loss: 0.067, average forward (0.011320) and backward (0.022747) time: 0.102713, iotime: 0.001609 
2022-08-04 09:48:05,799 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047524, Speed: 673.344850 images/s
2022-08-04 09:48:06,907 [dl_trainer.py:731] WARNING [ 69][13600/  196][rank:0] loss: 0.179, average forward (0.009897) and backward (0.019481) time: 0.031140, iotime: 0.001496 
2022-08-04 09:48:07,645 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046137, Speed: 693.592867 images/s
2022-08-04 09:48:08,703 [dl_trainer.py:731] WARNING [ 69][13640/  196][rank:0] loss: 0.273, average forward (0.009511) and backward (0.019231) time: 0.030422, iotime: 0.001440 
2022-08-04 09:48:09,158 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:48:09,158 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:48:10,648 [dl_trainer.py:731] WARNING [ 69][13680/  196][rank:0] loss: 0.155, average forward (0.010386) and backward (0.018536) time: 0.034579, iotime: 0.005361 
2022-08-04 09:48:11,168 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046945, Speed: 681.654004 images/s
2022-08-04 09:48:12,506 [dl_trainer.py:731] WARNING [ 69][13720/  196][rank:0] loss: 0.557, average forward (0.009393) and backward (0.021169) time: 0.032200, iotime: 0.001401 
2022-08-04 09:48:12,521 [dl_trainer.py:634] INFO train iter: 13720, num_batches_per_epoch: 196
2022-08-04 09:48:12,521 [dl_trainer.py:635] INFO Epoch 70, avg train acc: 93.367347, lr: 0.010000, avg loss: 0.185455
2022-08-04 09:48:15,162 [dl_trainer.py:822] INFO Epoch 70, lr: 0.010000, val loss: 0.476276, val top-1 acc: 86.611422, top-5 acc: 99.480831
2022-08-04 09:48:15,711 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113573, Speed: 281.757692 images/s
2022-08-04 09:48:17,054 [dl_trainer.py:731] WARNING [ 70][13760/  196][rank:0] loss: 0.187, average forward (0.009390) and backward (0.020112) time: 0.097913, iotime: 0.001532 
2022-08-04 09:48:17,543 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045777, Speed: 699.035739 images/s
2022-08-04 09:48:18,806 [dl_trainer.py:731] WARNING [ 70][13800/  196][rank:0] loss: 0.122, average forward (0.010801) and backward (0.017581) time: 0.030164, iotime: 0.001517 
2022-08-04 09:48:19,316 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044306, Speed: 722.255281 images/s
2022-08-04 09:48:20,646 [dl_trainer.py:731] WARNING [ 70][13840/  196][rank:0] loss: 0.349, average forward (0.009826) and backward (0.019063) time: 0.030550, iotime: 0.001424 
2022-08-04 09:48:20,907 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:48:20,907 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:48:22,656 [dl_trainer.py:731] WARNING [ 70][13880/  196][rank:0] loss: 0.204, average forward (0.009980) and backward (0.021225) time: 0.036474, iotime: 0.005001 
2022-08-04 09:48:22,965 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048639, Speed: 657.903078 images/s
2022-08-04 09:48:24,428 [dl_trainer.py:634] INFO train iter: 13916, num_batches_per_epoch: 196
2022-08-04 09:48:24,429 [dl_trainer.py:635] INFO Epoch 71, avg train acc: 93.303571, lr: 0.010000, avg loss: 0.191810
2022-08-04 09:48:27,132 [dl_trainer.py:822] INFO Epoch 71, lr: 0.010000, val loss: 0.466344, val top-1 acc: 86.751198, top-5 acc: 99.371006
2022-08-04 09:48:27,296 [dl_trainer.py:731] WARNING [ 71][13920/  196][rank:0] loss: 0.153, average forward (0.011698) and backward (0.021913) time: 0.103199, iotime: 0.001634 
2022-08-04 09:48:27,569 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115071, Speed: 278.088420 images/s
2022-08-04 09:48:28,975 [dl_trainer.py:731] WARNING [ 71][13960/  196][rank:0] loss: 0.062, average forward (0.008765) and backward (0.018835) time: 0.029157, iotime: 0.001328 
2022-08-04 09:48:29,268 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042480, Speed: 753.302682 images/s
2022-08-04 09:48:30,757 [dl_trainer.py:731] WARNING [ 71][14000/  196][rank:0] loss: 0.202, average forward (0.008914) and backward (0.018681) time: 0.029187, iotime: 0.001356 
2022-08-04 09:48:31,049 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044501, Speed: 719.087747 images/s
2022-08-04 09:48:32,514 [dl_trainer.py:731] WARNING [ 71][14040/  196][rank:0] loss: 0.182, average forward (0.009064) and backward (0.018351) time: 0.028989, iotime: 0.001339 
2022-08-04 09:48:32,522 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:48:32,523 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:48:34,381 [dl_trainer.py:731] WARNING [ 71][14080/  196][rank:0] loss: 0.091, average forward (0.010451) and backward (0.017824) time: 0.034006, iotime: 0.005456 
2022-08-04 09:48:34,447 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045290, Speed: 706.560075 images/s
2022-08-04 09:48:35,810 [dl_trainer.py:634] INFO train iter: 14112, num_batches_per_epoch: 196
2022-08-04 09:48:35,810 [dl_trainer.py:635] INFO Epoch 72, avg train acc: 93.670281, lr: 0.010000, avg loss: 0.177326
2022-08-04 09:48:38,482 [dl_trainer.py:822] INFO Epoch 72, lr: 0.010000, val loss: 0.564764, val top-1 acc: 84.115415, top-5 acc: 99.540735
2022-08-04 09:48:38,854 [dl_trainer.py:731] WARNING [ 72][14120/  196][rank:0] loss: 0.099, average forward (0.009584) and backward (0.019900) time: 0.098742, iotime: 0.001412 
2022-08-04 09:48:38,914 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111678, Speed: 286.538148 images/s
2022-08-04 09:48:40,638 [dl_trainer.py:731] WARNING [ 72][14160/  196][rank:0] loss: 0.115, average forward (0.008372) and backward (0.020091) time: 0.029945, iotime: 0.001261 
2022-08-04 09:48:40,703 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044702, Speed: 715.857853 images/s
2022-08-04 09:48:42,368 [dl_trainer.py:731] WARNING [ 72][14200/  196][rank:0] loss: 0.352, average forward (0.009054) and backward (0.019715) time: 0.030354, iotime: 0.001357 
2022-08-04 09:48:42,411 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042705, Speed: 749.324172 images/s
2022-08-04 09:48:43,978 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:48:43,978 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:48:44,348 [dl_trainer.py:731] WARNING [ 72][14240/  196][rank:0] loss: 0.231, average forward (0.011656) and backward (0.019230) time: 0.036504, iotime: 0.005295 
2022-08-04 09:48:45,816 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045382, Speed: 705.127742 images/s
2022-08-04 09:48:45,956 [dl_trainer.py:731] WARNING [ 72][14280/  196][rank:0] loss: 0.118, average forward (0.009776) and backward (0.017411) time: 0.028760, iotime: 0.001349 
2022-08-04 09:48:47,051 [dl_trainer.py:634] INFO train iter: 14308, num_batches_per_epoch: 196
2022-08-04 09:48:47,051 [dl_trainer.py:635] INFO Epoch 73, avg train acc: 93.431122, lr: 0.010000, avg loss: 0.183997
2022-08-04 09:48:49,744 [dl_trainer.py:822] INFO Epoch 73, lr: 0.010000, val loss: 0.465374, val top-1 acc: 86.671326, top-5 acc: 99.560703
2022-08-04 09:48:50,080 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.106577, Speed: 300.252207 images/s
2022-08-04 09:48:50,246 [dl_trainer.py:731] WARNING [ 73][14320/  196][rank:0] loss: 0.123, average forward (0.010043) and backward (0.016100) time: 0.095208, iotime: 0.001425 
2022-08-04 09:48:51,760 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041985, Speed: 762.185856 images/s
2022-08-04 09:48:51,929 [dl_trainer.py:731] WARNING [ 73][14360/  196][rank:0] loss: 0.155, average forward (0.009859) and backward (0.017477) time: 0.028935, iotime: 0.001345 
2022-08-04 09:48:53,506 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043639, Speed: 733.290362 images/s
2022-08-04 09:48:53,677 [dl_trainer.py:731] WARNING [ 73][14400/  196][rank:0] loss: 0.279, average forward (0.010094) and backward (0.017704) time: 0.029594, iotime: 0.001518 
2022-08-04 09:48:54,950 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:48:54,951 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:48:55,546 [dl_trainer.py:731] WARNING [ 73][14440/  196][rank:0] loss: 0.153, average forward (0.010767) and backward (0.017909) time: 0.034165, iotime: 0.005195 
2022-08-04 09:48:56,928 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045604, Speed: 701.693517 images/s
2022-08-04 09:48:57,290 [dl_trainer.py:731] WARNING [ 73][14480/  196][rank:0] loss: 0.344, average forward (0.009011) and backward (0.019244) time: 0.029869, iotime: 0.001360 
2022-08-04 09:48:58,411 [dl_trainer.py:634] INFO train iter: 14504, num_batches_per_epoch: 196
2022-08-04 09:48:58,411 [dl_trainer.py:635] INFO Epoch 74, avg train acc: 93.303571, lr: 0.010000, avg loss: 0.188129
2022-08-04 09:49:01,088 [dl_trainer.py:822] INFO Epoch 74, lr: 0.010000, val loss: 0.402277, val top-1 acc: 88.428514, top-5 acc: 99.550719
2022-08-04 09:49:01,410 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112052, Speed: 285.581452 images/s
2022-08-04 09:49:01,802 [dl_trainer.py:731] WARNING [ 74][14520/  196][rank:0] loss: 0.141, average forward (0.010108) and backward (0.019270) time: 0.098549, iotime: 0.001446 
2022-08-04 09:49:03,155 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043616, Speed: 733.671558 images/s
2022-08-04 09:49:03,550 [dl_trainer.py:731] WARNING [ 74][14560/  196][rank:0] loss: 0.180, average forward (0.008881) and backward (0.020361) time: 0.030831, iotime: 0.001366 
2022-08-04 09:49:04,917 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044041, Speed: 726.602035 images/s
2022-08-04 09:49:05,290 [dl_trainer.py:731] WARNING [ 74][14600/  196][rank:0] loss: 0.206, average forward (0.009070) and backward (0.018615) time: 0.029277, iotime: 0.001350 
2022-08-04 09:49:06,486 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:49:06,486 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:49:07,314 [dl_trainer.py:731] WARNING [ 74][14640/  196][rank:0] loss: 0.149, average forward (0.010996) and backward (0.020514) time: 0.037039, iotime: 0.005243 
2022-08-04 09:49:08,504 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047806, Speed: 669.378868 images/s
2022-08-04 09:49:09,140 [dl_trainer.py:731] WARNING [ 74][14680/  196][rank:0] loss: 0.242, average forward (0.009842) and backward (0.018765) time: 0.030294, iotime: 0.001435 
2022-08-04 09:49:10,053 [dl_trainer.py:634] INFO train iter: 14700, num_batches_per_epoch: 196
2022-08-04 09:49:10,053 [dl_trainer.py:635] INFO Epoch 75, avg train acc: 93.781888, lr: 0.010000, avg loss: 0.175501
2022-08-04 09:49:12,744 [dl_trainer.py:822] INFO Epoch 75, lr: 0.010000, val loss: 0.453506, val top-1 acc: 87.240415, top-5 acc: 99.361022
2022-08-04 09:49:13,051 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113662, Speed: 281.536784 images/s
2022-08-04 09:49:13,673 [dl_trainer.py:731] WARNING [ 75][14720/  196][rank:0] loss: 0.209, average forward (0.011281) and backward (0.017981) time: 0.098492, iotime: 0.001611 
2022-08-04 09:49:14,844 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044810, Speed: 714.130917 images/s
2022-08-04 09:49:15,429 [dl_trainer.py:731] WARNING [ 75][14760/  196][rank:0] loss: 0.222, average forward (0.010160) and backward (0.018786) time: 0.030704, iotime: 0.001486 
2022-08-04 09:49:16,623 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044463, Speed: 719.701798 images/s
2022-08-04 09:49:17,236 [dl_trainer.py:731] WARNING [ 75][14800/  196][rank:0] loss: 0.143, average forward (0.008777) and backward (0.020472) time: 0.030796, iotime: 0.001325 
2022-08-04 09:49:18,130 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:49:18,130 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:49:19,214 [dl_trainer.py:731] WARNING [ 75][14840/  196][rank:0] loss: 0.092, average forward (0.009311) and backward (0.019007) time: 0.033565, iotime: 0.004979 
2022-08-04 09:49:20,208 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047784, Speed: 669.678119 images/s
2022-08-04 09:49:21,096 [dl_trainer.py:731] WARNING [ 75][14880/  196][rank:0] loss: 0.074, average forward (0.010420) and backward (0.020346) time: 0.032511, iotime: 0.001483 
2022-08-04 09:49:21,858 [dl_trainer.py:634] INFO train iter: 14896, num_batches_per_epoch: 196
2022-08-04 09:49:21,859 [dl_trainer.py:635] INFO Epoch 76, avg train acc: 93.861607, lr: 0.010000, avg loss: 0.168643
2022-08-04 09:49:24,597 [dl_trainer.py:822] INFO Epoch 76, lr: 0.010000, val loss: 0.498076, val top-1 acc: 86.681310, top-5 acc: 99.400958
2022-08-04 09:49:24,923 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.117873, Speed: 271.478678 images/s
2022-08-04 09:49:25,745 [dl_trainer.py:731] WARNING [ 76][14920/  196][rank:0] loss: 0.184, average forward (0.011460) and backward (0.020396) time: 0.104422, iotime: 0.001646 
2022-08-04 09:49:26,668 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043583, Speed: 734.223711 images/s
2022-08-04 09:49:27,537 [dl_trainer.py:731] WARNING [ 76][14960/  196][rank:0] loss: 0.116, average forward (0.010315) and backward (0.020466) time: 0.032582, iotime: 0.001521 
2022-08-04 09:49:28,496 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045685, Speed: 700.446178 images/s
2022-08-04 09:49:29,359 [dl_trainer.py:731] WARNING [ 76][15000/  196][rank:0] loss: 0.237, average forward (0.009689) and backward (0.020137) time: 0.031492, iotime: 0.001427 
2022-08-04 09:49:30,123 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:49:30,123 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:49:31,375 [dl_trainer.py:731] WARNING [ 76][15040/  196][rank:0] loss: 0.082, average forward (0.010516) and backward (0.020502) time: 0.036551, iotime: 0.005249 
2022-08-04 09:49:32,065 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047562, Speed: 672.802312 images/s
2022-08-04 09:49:33,135 [dl_trainer.py:731] WARNING [ 76][15080/  196][rank:0] loss: 0.088, average forward (0.009296) and backward (0.019100) time: 0.029997, iotime: 0.001360 
2022-08-04 09:49:33,683 [dl_trainer.py:634] INFO train iter: 15092, num_batches_per_epoch: 196
2022-08-04 09:49:33,684 [dl_trainer.py:635] INFO Epoch 77, avg train acc: 93.941327, lr: 0.010000, avg loss: 0.177014
2022-08-04 09:49:36,316 [dl_trainer.py:822] INFO Epoch 77, lr: 0.010000, val loss: 0.496628, val top-1 acc: 86.491613, top-5 acc: 99.520767
2022-08-04 09:49:36,489 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110603, Speed: 289.323374 images/s
2022-08-04 09:49:37,473 [dl_trainer.py:731] WARNING [ 77][15120/  196][rank:0] loss: 0.162, average forward (0.008923) and backward (0.017795) time: 0.094228, iotime: 0.001406 
2022-08-04 09:49:38,180 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042262, Speed: 757.183744 images/s
2022-08-04 09:49:39,223 [dl_trainer.py:731] WARNING [ 77][15160/  196][rank:0] loss: 0.401, average forward (0.009979) and backward (0.017618) time: 0.029261, iotime: 0.001421 
2022-08-04 09:49:39,917 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043422, Speed: 736.953287 images/s
2022-08-04 09:49:40,940 [dl_trainer.py:731] WARNING [ 77][15200/  196][rank:0] loss: 0.133, average forward (0.008829) and backward (0.018735) time: 0.029072, iotime: 0.001291 
2022-08-04 09:49:41,375 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:49:41,376 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:49:42,818 [dl_trainer.py:731] WARNING [ 77][15240/  196][rank:0] loss: 0.180, average forward (0.010357) and backward (0.017273) time: 0.033386, iotime: 0.005478 
2022-08-04 09:49:43,280 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044813, Speed: 714.085134 images/s
2022-08-04 09:49:44,548 [dl_trainer.py:731] WARNING [ 77][15280/  196][rank:0] loss: 0.106, average forward (0.010033) and backward (0.018938) time: 0.030658, iotime: 0.001442 
2022-08-04 09:49:44,876 [dl_trainer.py:634] INFO train iter: 15288, num_batches_per_epoch: 196
2022-08-04 09:49:44,876 [dl_trainer.py:635] INFO Epoch 78, avg train acc: 93.734056, lr: 0.010000, avg loss: 0.173236
2022-08-04 09:49:47,527 [dl_trainer.py:822] INFO Epoch 78, lr: 0.010000, val loss: 0.450002, val top-1 acc: 87.450080, top-5 acc: 99.460863
2022-08-04 09:49:47,679 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109971, Speed: 290.986124 images/s
2022-08-04 09:49:49,009 [dl_trainer.py:731] WARNING [ 78][15320/  196][rank:0] loss: 0.363, average forward (0.010386) and backward (0.018977) time: 0.097787, iotime: 0.001488 
2022-08-04 09:49:49,557 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046931, Speed: 681.846819 images/s
2022-08-04 09:49:50,884 [dl_trainer.py:731] WARNING [ 78][15360/  196][rank:0] loss: 0.075, average forward (0.009429) and backward (0.020569) time: 0.031652, iotime: 0.001436 
2022-08-04 09:49:51,433 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046912, Speed: 682.131323 images/s
2022-08-04 09:49:52,813 [dl_trainer.py:731] WARNING [ 78][15400/  196][rank:0] loss: 0.053, average forward (0.009153) and backward (0.021714) time: 0.032517, iotime: 0.001406 
2022-08-04 09:49:53,056 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:49:53,057 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:49:54,810 [dl_trainer.py:731] WARNING [ 78][15440/  196][rank:0] loss: 0.244, average forward (0.011087) and backward (0.018732) time: 0.035556, iotime: 0.005446 
2022-08-04 09:49:55,094 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048787, Speed: 655.918256 images/s
2022-08-04 09:49:56,610 [dl_trainer.py:731] WARNING [ 78][15480/  196][rank:0] loss: 0.099, average forward (0.009049) and backward (0.018764) time: 0.029436, iotime: 0.001377 
2022-08-04 09:49:56,806 [dl_trainer.py:634] INFO train iter: 15484, num_batches_per_epoch: 196
2022-08-04 09:49:56,806 [dl_trainer.py:635] INFO Epoch 79, avg train acc: 94.052934, lr: 0.010000, avg loss: 0.160058
2022-08-04 09:49:59,483 [dl_trainer.py:822] INFO Epoch 79, lr: 0.010000, val loss: 0.457862, val top-1 acc: 87.110623, top-5 acc: 99.470847
2022-08-04 09:49:59,586 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112283, Speed: 284.992933 images/s
2022-08-04 09:50:01,033 [dl_trainer.py:731] WARNING [ 79][15520/  196][rank:0] loss: 0.124, average forward (0.009652) and backward (0.017268) time: 0.095534, iotime: 0.001380 
2022-08-04 09:50:01,299 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042808, Speed: 747.522747 images/s
2022-08-04 09:50:02,841 [dl_trainer.py:731] WARNING [ 79][15560/  196][rank:0] loss: 0.102, average forward (0.008228) and backward (0.019594) time: 0.029325, iotime: 0.001287 
2022-08-04 09:50:03,126 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045681, Speed: 700.508874 images/s
2022-08-04 09:50:04,646 [dl_trainer.py:731] WARNING [ 79][15600/  196][rank:0] loss: 0.086, average forward (0.011154) and backward (0.020397) time: 0.033398, iotime: 0.001576 
2022-08-04 09:50:04,667 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:50:04,667 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:50:06,715 [dl_trainer.py:731] WARNING [ 79][15640/  196][rank:0] loss: 0.031, average forward (0.010121) and backward (0.019075) time: 0.035051, iotime: 0.005562 
2022-08-04 09:50:06,785 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048762, Speed: 656.243451 images/s
2022-08-04 09:50:08,550 [dl_trainer.py:731] WARNING [ 79][15680/  196][rank:0] loss: 0.099, average forward (0.009618) and backward (0.018459) time: 0.029753, iotime: 0.001407 
2022-08-04 09:50:08,570 [dl_trainer.py:634] INFO train iter: 15680, num_batches_per_epoch: 196
2022-08-04 09:50:08,570 [dl_trainer.py:635] INFO Epoch 80, avg train acc: 94.626913, lr: 0.010000, avg loss: 0.154122
2022-08-04 09:50:11,248 [dl_trainer.py:822] INFO Epoch 80, lr: 0.010000, val loss: 0.501423, val top-1 acc: 86.581470, top-5 acc: 99.390974
2022-08-04 09:50:11,316 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113266, Speed: 282.520055 images/s
2022-08-04 09:50:13,094 [dl_trainer.py:731] WARNING [ 80][15720/  196][rank:0] loss: 0.065, average forward (0.010534) and backward (0.020270) time: 0.100074, iotime: 0.001542 
2022-08-04 09:50:13,150 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045849, Speed: 697.942592 images/s
2022-08-04 09:50:14,933 [dl_trainer.py:731] WARNING [ 80][15760/  196][rank:0] loss: 0.162, average forward (0.009155) and backward (0.020753) time: 0.031569, iotime: 0.001435 
2022-08-04 09:50:14,990 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045989, Speed: 695.819455 images/s
2022-08-04 09:50:16,590 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:50:16,590 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:50:16,957 [dl_trainer.py:731] WARNING [ 80][15800/  196][rank:0] loss: 0.045, average forward (0.010116) and backward (0.020199) time: 0.035797, iotime: 0.005206 
2022-08-04 09:50:18,634 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048564, Speed: 658.929415 images/s
2022-08-04 09:50:18,804 [dl_trainer.py:731] WARNING [ 80][15840/  196][rank:0] loss: 0.205, average forward (0.010291) and backward (0.019845) time: 0.031903, iotime: 0.001510 
2022-08-04 09:50:20,427 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044818, Speed: 714.006025 images/s
2022-08-04 09:50:20,428 [dl_trainer.py:634] INFO train iter: 15876, num_batches_per_epoch: 196
2022-08-04 09:50:20,428 [dl_trainer.py:635] INFO Epoch 81, avg train acc: 94.276148, lr: 0.010000, avg loss: 0.158864
2022-08-04 09:50:23,068 [dl_trainer.py:822] INFO Epoch 81, lr: 0.010000, val loss: 0.523631, val top-1 acc: 85.623003, top-5 acc: 99.341054
2022-08-04 09:50:23,252 [dl_trainer.py:731] WARNING [ 81][15880/  196][rank:0] loss: 0.022, average forward (0.010603) and backward (0.018636) time: 0.097045, iotime: 0.001455 
2022-08-04 09:50:24,927 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112486, Speed: 284.480769 images/s
2022-08-04 09:50:25,077 [dl_trainer.py:731] WARNING [ 81][15920/  196][rank:0] loss: 0.177, average forward (0.009385) and backward (0.018620) time: 0.029571, iotime: 0.001329 
2022-08-04 09:50:26,663 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043396, Speed: 737.387116 images/s
2022-08-04 09:50:26,821 [dl_trainer.py:731] WARNING [ 81][15960/  196][rank:0] loss: 0.139, average forward (0.009127) and backward (0.019567) time: 0.030295, iotime: 0.001379 
2022-08-04 09:50:28,200 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:50:28,200 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:50:28,782 [dl_trainer.py:731] WARNING [ 81][16000/  196][rank:0] loss: 0.141, average forward (0.009538) and backward (0.018900) time: 0.033862, iotime: 0.005162 
2022-08-04 09:50:30,196 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047079, Speed: 679.708522 images/s
2022-08-04 09:50:30,549 [dl_trainer.py:731] WARNING [ 81][16040/  196][rank:0] loss: 0.181, average forward (0.009532) and backward (0.020004) time: 0.031181, iotime: 0.001408 
2022-08-04 09:50:31,862 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041651, Speed: 768.285714 images/s
2022-08-04 09:50:31,902 [dl_trainer.py:634] INFO train iter: 16072, num_batches_per_epoch: 196
2022-08-04 09:50:31,902 [dl_trainer.py:635] INFO Epoch 82, avg train acc: 95.870536, lr: 0.001000, avg loss: 0.119928
2022-08-04 09:50:34,578 [dl_trainer.py:822] INFO Epoch 82, lr: 0.001000, val loss: 0.356089, val top-1 acc: 89.956070, top-5 acc: 99.700479
2022-08-04 09:50:34,953 [dl_trainer.py:731] WARNING [ 82][16080/  196][rank:0] loss: 0.190, average forward (0.009349) and backward (0.017665) time: 0.096798, iotime: 0.001429 
2022-08-04 09:50:36,300 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110951, Speed: 288.414506 images/s
2022-08-04 09:50:36,651 [dl_trainer.py:731] WARNING [ 82][16120/  196][rank:0] loss: 0.051, average forward (0.010180) and backward (0.019541) time: 0.031408, iotime: 0.001429 
2022-08-04 09:50:37,999 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042446, Speed: 753.896013 images/s
2022-08-04 09:50:38,422 [dl_trainer.py:731] WARNING [ 82][16160/  196][rank:0] loss: 0.110, average forward (0.011019) and backward (0.018516) time: 0.031474, iotime: 0.001649 
2022-08-04 09:50:39,567 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:50:39,568 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:50:40,365 [dl_trainer.py:731] WARNING [ 82][16200/  196][rank:0] loss: 0.129, average forward (0.010058) and backward (0.018813) time: 0.034713, iotime: 0.005559 
2022-08-04 09:50:41,506 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046725, Speed: 684.858729 images/s
2022-08-04 09:50:42,096 [dl_trainer.py:731] WARNING [ 82][16240/  196][rank:0] loss: 0.037, average forward (0.009920) and backward (0.018813) time: 0.030384, iotime: 0.001418 
2022-08-04 09:50:43,213 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042654, Speed: 750.225837 images/s
2022-08-04 09:50:43,298 [dl_trainer.py:634] INFO train iter: 16268, num_batches_per_epoch: 196
2022-08-04 09:50:43,298 [dl_trainer.py:635] INFO Epoch 83, avg train acc: 96.157526, lr: 0.001000, avg loss: 0.114284
2022-08-04 09:50:45,957 [dl_trainer.py:822] INFO Epoch 83, lr: 0.001000, val loss: 0.358082, val top-1 acc: 89.886182, top-5 acc: 99.700479
2022-08-04 09:50:46,463 [dl_trainer.py:731] WARNING [ 83][16280/  196][rank:0] loss: 0.255, average forward (0.010239) and backward (0.019148) time: 0.097628, iotime: 0.001431 
2022-08-04 09:50:47,591 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109448, Speed: 292.375753 images/s
2022-08-04 09:50:48,200 [dl_trainer.py:731] WARNING [ 83][16320/  196][rank:0] loss: 0.069, average forward (0.009552) and backward (0.018326) time: 0.029505, iotime: 0.001387 
2022-08-04 09:50:49,401 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045230, Speed: 707.494727 images/s
2022-08-04 09:50:50,013 [dl_trainer.py:731] WARNING [ 83][16360/  196][rank:0] loss: 0.071, average forward (0.010333) and backward (0.018654) time: 0.030854, iotime: 0.001609 
2022-08-04 09:50:50,888 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:50:50,889 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:50:51,884 [dl_trainer.py:731] WARNING [ 83][16400/  196][rank:0] loss: 0.117, average forward (0.009433) and backward (0.020438) time: 0.035113, iotime: 0.004988 
2022-08-04 09:50:52,903 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046675, Speed: 685.588564 images/s
2022-08-04 09:50:53,791 [dl_trainer.py:731] WARNING [ 83][16440/  196][rank:0] loss: 0.049, average forward (0.009945) and backward (0.020005) time: 0.031835, iotime: 0.001604 
2022-08-04 09:50:54,847 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048565, Speed: 658.908308 images/s
2022-08-04 09:50:54,995 [dl_trainer.py:634] INFO train iter: 16464, num_batches_per_epoch: 196
2022-08-04 09:50:54,995 [dl_trainer.py:635] INFO Epoch 84, avg train acc: 96.253189, lr: 0.001000, avg loss: 0.114869
2022-08-04 09:50:57,695 [dl_trainer.py:822] INFO Epoch 84, lr: 0.001000, val loss: 0.352761, val top-1 acc: 90.025958, top-5 acc: 99.670527
2022-08-04 09:50:58,358 [dl_trainer.py:731] WARNING [ 84][16480/  196][rank:0] loss: 0.134, average forward (0.009005) and backward (0.017677) time: 0.096339, iotime: 0.001359 
2022-08-04 09:50:59,281 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110855, Speed: 288.665324 images/s
2022-08-04 09:51:00,134 [dl_trainer.py:731] WARNING [ 84][16520/  196][rank:0] loss: 0.092, average forward (0.009717) and backward (0.019529) time: 0.030867, iotime: 0.001385 
2022-08-04 09:51:01,024 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043542, Speed: 734.915198 images/s
2022-08-04 09:51:01,875 [dl_trainer.py:731] WARNING [ 84][16560/  196][rank:0] loss: 0.068, average forward (0.009708) and backward (0.017563) time: 0.028886, iotime: 0.001373 
2022-08-04 09:51:02,573 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:51:02,573 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:51:03,865 [dl_trainer.py:731] WARNING [ 84][16600/  196][rank:0] loss: 0.070, average forward (0.009908) and backward (0.017017) time: 0.032605, iotime: 0.005405 
2022-08-04 09:51:04,606 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047747, Speed: 670.203168 images/s
2022-08-04 09:51:05,728 [dl_trainer.py:731] WARNING [ 84][16640/  196][rank:0] loss: 0.017, average forward (0.010396) and backward (0.020238) time: 0.032354, iotime: 0.001464 
2022-08-04 09:51:06,492 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047127, Speed: 679.013148 images/s
2022-08-04 09:51:06,674 [dl_trainer.py:634] INFO train iter: 16660, num_batches_per_epoch: 196
2022-08-04 09:51:06,674 [dl_trainer.py:635] INFO Epoch 85, avg train acc: 96.731505, lr: 0.001000, avg loss: 0.098994
2022-08-04 09:51:09,321 [dl_trainer.py:822] INFO Epoch 85, lr: 0.001000, val loss: 0.356193, val top-1 acc: 89.916134, top-5 acc: 99.660543
2022-08-04 09:51:10,191 [dl_trainer.py:731] WARNING [ 85][16680/  196][rank:0] loss: 0.065, average forward (0.009770) and backward (0.020393) time: 0.098104, iotime: 0.001439 
2022-08-04 09:51:10,873 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109525, Speed: 292.170846 images/s
2022-08-04 09:51:11,957 [dl_trainer.py:731] WARNING [ 85][16720/  196][rank:0] loss: 0.268, average forward (0.009971) and backward (0.018800) time: 0.030450, iotime: 0.001439 
2022-08-04 09:51:12,675 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045039, Speed: 710.489642 images/s
2022-08-04 09:51:13,765 [dl_trainer.py:731] WARNING [ 85][16760/  196][rank:0] loss: 0.055, average forward (0.010564) and backward (0.019815) time: 0.032123, iotime: 0.001494 
2022-08-04 09:51:14,245 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:51:14,245 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:51:15,755 [dl_trainer.py:731] WARNING [ 85][16800/  196][rank:0] loss: 0.213, average forward (0.009447) and backward (0.020315) time: 0.035235, iotime: 0.005213 
2022-08-04 09:51:16,263 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047825, Speed: 669.109459 images/s
2022-08-04 09:51:17,502 [dl_trainer.py:731] WARNING [ 85][16840/  196][rank:0] loss: 0.202, average forward (0.010084) and backward (0.018145) time: 0.029890, iotime: 0.001411 
2022-08-04 09:51:17,994 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043275, Speed: 739.463401 images/s
2022-08-04 09:51:18,211 [dl_trainer.py:634] INFO train iter: 16856, num_batches_per_epoch: 196
2022-08-04 09:51:18,211 [dl_trainer.py:635] INFO Epoch 86, avg train acc: 96.859056, lr: 0.001000, avg loss: 0.098356
2022-08-04 09:51:20,861 [dl_trainer.py:822] INFO Epoch 86, lr: 0.001000, val loss: 0.365559, val top-1 acc: 89.616613, top-5 acc: 99.710463
2022-08-04 09:51:21,925 [dl_trainer.py:731] WARNING [ 86][16880/  196][rank:0] loss: 0.131, average forward (0.009480) and backward (0.017407) time: 0.096581, iotime: 0.001381 
2022-08-04 09:51:22,419 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110605, Speed: 289.318307 images/s
2022-08-04 09:51:23,690 [dl_trainer.py:731] WARNING [ 86][16920/  196][rank:0] loss: 0.170, average forward (0.010438) and backward (0.018072) time: 0.030292, iotime: 0.001532 
2022-08-04 09:51:24,205 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044643, Speed: 716.797184 images/s
2022-08-04 09:51:25,546 [dl_trainer.py:731] WARNING [ 86][16960/  196][rank:0] loss: 0.020, average forward (0.008618) and backward (0.021446) time: 0.031573, iotime: 0.001285 
2022-08-04 09:51:25,788 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:51:25,788 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:51:27,468 [dl_trainer.py:731] WARNING [ 86][17000/  196][rank:0] loss: 0.120, average forward (0.009931) and backward (0.019105) time: 0.034524, iotime: 0.005203 
2022-08-04 09:51:27,720 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046852, Speed: 683.003592 images/s
2022-08-04 09:51:29,319 [dl_trainer.py:731] WARNING [ 86][17040/  196][rank:0] loss: 0.121, average forward (0.010603) and backward (0.020202) time: 0.032555, iotime: 0.001490 
2022-08-04 09:51:29,619 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047465, Speed: 674.182209 images/s
2022-08-04 09:51:29,886 [dl_trainer.py:634] INFO train iter: 17052, num_batches_per_epoch: 196
2022-08-04 09:51:29,886 [dl_trainer.py:635] INFO Epoch 87, avg train acc: 96.986607, lr: 0.001000, avg loss: 0.094750
2022-08-04 09:51:32,542 [dl_trainer.py:822] INFO Epoch 87, lr: 0.001000, val loss: 0.366052, val top-1 acc: 89.866214, top-5 acc: 99.650559
2022-08-04 09:51:33,837 [dl_trainer.py:731] WARNING [ 87][17080/  196][rank:0] loss: 0.072, average forward (0.010729) and backward (0.019984) time: 0.098993, iotime: 0.001556 
2022-08-04 09:51:34,134 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112834, Speed: 283.602863 images/s
2022-08-04 09:51:35,654 [dl_trainer.py:731] WARNING [ 87][17120/  196][rank:0] loss: 0.097, average forward (0.009030) and backward (0.021012) time: 0.031659, iotime: 0.001371 
2022-08-04 09:51:35,952 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045439, Speed: 704.236802 images/s
2022-08-04 09:51:37,512 [dl_trainer.py:731] WARNING [ 87][17160/  196][rank:0] loss: 0.046, average forward (0.009744) and backward (0.019126) time: 0.030571, iotime: 0.001444 
2022-08-04 09:51:37,525 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:51:37,526 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:51:39,466 [dl_trainer.py:731] WARNING [ 87][17200/  196][rank:0] loss: 0.180, average forward (0.010371) and backward (0.017774) time: 0.033806, iotime: 0.005395 
2022-08-04 09:51:39,529 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047664, Speed: 671.360272 images/s
2022-08-04 09:51:41,081 [dl_trainer.py:731] WARNING [ 87][17240/  196][rank:0] loss: 0.092, average forward (0.009490) and backward (0.016321) time: 0.027387, iotime: 0.001341 
2022-08-04 09:51:41,145 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040399, Speed: 792.098171 images/s
2022-08-04 09:51:41,449 [dl_trainer.py:634] INFO train iter: 17248, num_batches_per_epoch: 196
2022-08-04 09:51:41,449 [dl_trainer.py:635] INFO Epoch 88, avg train acc: 96.699617, lr: 0.001000, avg loss: 0.096357
2022-08-04 09:51:44,099 [dl_trainer.py:822] INFO Epoch 88, lr: 0.001000, val loss: 0.362729, val top-1 acc: 90.045927, top-5 acc: 99.660543
2022-08-04 09:51:45,494 [dl_trainer.py:731] WARNING [ 88][17280/  196][rank:0] loss: 0.094, average forward (0.008904) and backward (0.019070) time: 0.096308, iotime: 0.001322 
2022-08-04 09:51:45,553 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110189, Speed: 290.410766 images/s
2022-08-04 09:51:47,287 [dl_trainer.py:731] WARNING [ 88][17320/  196][rank:0] loss: 0.070, average forward (0.009125) and backward (0.019876) time: 0.030614, iotime: 0.001382 
2022-08-04 09:51:47,341 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044705, Speed: 715.805263 images/s
2022-08-04 09:51:48,856 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:51:48,857 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:51:49,192 [dl_trainer.py:731] WARNING [ 88][17360/  196][rank:0] loss: 0.114, average forward (0.010056) and backward (0.018852) time: 0.034508, iotime: 0.005340 
2022-08-04 09:51:50,798 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046071, Speed: 694.577108 images/s
2022-08-04 09:51:50,943 [dl_trainer.py:731] WARNING [ 88][17400/  196][rank:0] loss: 0.019, average forward (0.010225) and backward (0.018839) time: 0.030798, iotime: 0.001488 
2022-08-04 09:51:52,572 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044314, Speed: 722.115098 images/s
2022-08-04 09:51:52,718 [dl_trainer.py:731] WARNING [ 88][17440/  196][rank:0] loss: 0.221, average forward (0.009456) and backward (0.018668) time: 0.029818, iotime: 0.001452 
2022-08-04 09:51:52,938 [dl_trainer.py:634] INFO train iter: 17444, num_batches_per_epoch: 196
2022-08-04 09:51:52,939 [dl_trainer.py:635] INFO Epoch 89, avg train acc: 96.380740, lr: 0.001000, avg loss: 0.098644
2022-08-04 09:51:55,619 [dl_trainer.py:822] INFO Epoch 89, lr: 0.001000, val loss: 0.364775, val top-1 acc: 89.786342, top-5 acc: 99.650559
2022-08-04 09:51:56,960 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109689, Speed: 291.734607 images/s
2022-08-04 09:51:57,120 [dl_trainer.py:731] WARNING [ 89][17480/  196][rank:0] loss: 0.049, average forward (0.010078) and backward (0.016891) time: 0.095674, iotime: 0.001383 
2022-08-04 09:51:58,669 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042705, Speed: 749.330342 images/s
2022-08-04 09:51:58,824 [dl_trainer.py:731] WARNING [ 89][17520/  196][rank:0] loss: 0.011, average forward (0.009586) and backward (0.019057) time: 0.030307, iotime: 0.001444 
2022-08-04 09:52:00,174 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:52:00,175 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:52:00,752 [dl_trainer.py:731] WARNING [ 89][17560/  196][rank:0] loss: 0.100, average forward (0.009593) and backward (0.018676) time: 0.033609, iotime: 0.005066 
2022-08-04 09:52:02,141 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046276, Speed: 691.497260 images/s
2022-08-04 09:52:02,543 [dl_trainer.py:731] WARNING [ 89][17600/  196][rank:0] loss: 0.068, average forward (0.009182) and backward (0.018716) time: 0.029477, iotime: 0.001333 
2022-08-04 09:52:03,861 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042980, Speed: 744.538994 images/s
2022-08-04 09:52:04,247 [dl_trainer.py:731] WARNING [ 89][17640/  196][rank:0] loss: 0.035, average forward (0.010553) and backward (0.018666) time: 0.030960, iotime: 0.001502 
2022-08-04 09:52:04,274 [dl_trainer.py:634] INFO train iter: 17640, num_batches_per_epoch: 196
2022-08-04 09:52:04,274 [dl_trainer.py:635] INFO Epoch 90, avg train acc: 96.906888, lr: 0.001000, avg loss: 0.092008
2022-08-04 09:52:06,911 [dl_trainer.py:822] INFO Epoch 90, lr: 0.001000, val loss: 0.366051, val top-1 acc: 90.005990, top-5 acc: 99.680511
2022-08-04 09:52:08,352 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112277, Speed: 285.008501 images/s
2022-08-04 09:52:08,722 [dl_trainer.py:731] WARNING [ 90][17680/  196][rank:0] loss: 0.028, average forward (0.008821) and backward (0.019363) time: 0.097773, iotime: 0.001306 
2022-08-04 09:52:10,142 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044746, Speed: 715.143728 images/s
2022-08-04 09:52:10,503 [dl_trainer.py:731] WARNING [ 90][17720/  196][rank:0] loss: 0.073, average forward (0.009330) and backward (0.019364) time: 0.030344, iotime: 0.001416 
2022-08-04 09:52:11,608 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:52:11,609 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:52:12,428 [dl_trainer.py:731] WARNING [ 90][17760/  196][rank:0] loss: 0.163, average forward (0.009904) and backward (0.018857) time: 0.034807, iotime: 0.005768 
2022-08-04 09:52:13,588 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045909, Speed: 697.036328 images/s
2022-08-04 09:52:14,262 [dl_trainer.py:731] WARNING [ 90][17800/  196][rank:0] loss: 0.069, average forward (0.010808) and backward (0.018439) time: 0.031083, iotime: 0.001568 
2022-08-04 09:52:15,474 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047163, Speed: 678.495864 images/s
2022-08-04 09:52:15,979 [dl_trainer.py:634] INFO train iter: 17836, num_batches_per_epoch: 196
2022-08-04 09:52:15,979 [dl_trainer.py:635] INFO Epoch 91, avg train acc: 96.603954, lr: 0.001000, avg loss: 0.095641
2022-08-04 09:52:18,654 [dl_trainer.py:822] INFO Epoch 91, lr: 0.001000, val loss: 0.368749, val top-1 acc: 89.646565, top-5 acc: 99.630591
2022-08-04 09:52:18,832 [dl_trainer.py:731] WARNING [ 91][17840/  196][rank:0] loss: 0.096, average forward (0.011126) and backward (0.019519) time: 0.099676, iotime: 0.001690 
2022-08-04 09:52:19,996 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113032, Speed: 283.106532 images/s
2022-08-04 09:52:20,603 [dl_trainer.py:731] WARNING [ 91][17880/  196][rank:0] loss: 0.056, average forward (0.009751) and backward (0.019914) time: 0.031313, iotime: 0.001403 
2022-08-04 09:52:21,761 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044098, Speed: 725.650383 images/s
2022-08-04 09:52:22,401 [dl_trainer.py:731] WARNING [ 91][17920/  196][rank:0] loss: 0.105, average forward (0.010069) and backward (0.018515) time: 0.030292, iotime: 0.001448 
2022-08-04 09:52:23,384 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:52:23,384 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:52:24,473 [dl_trainer.py:731] WARNING [ 91][17960/  196][rank:0] loss: 0.173, average forward (0.010767) and backward (0.019148) time: 0.035621, iotime: 0.005384 
2022-08-04 09:52:25,452 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.049196, Speed: 650.463063 images/s
2022-08-04 09:52:26,286 [dl_trainer.py:731] WARNING [ 91][18000/  196][rank:0] loss: 0.030, average forward (0.010880) and backward (0.018343) time: 0.031094, iotime: 0.001603 
2022-08-04 09:52:27,252 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044971, Speed: 711.562398 images/s
2022-08-04 09:52:27,730 [dl_trainer.py:634] INFO train iter: 18032, num_batches_per_epoch: 196
2022-08-04 09:52:27,731 [dl_trainer.py:635] INFO Epoch 92, avg train acc: 97.018495, lr: 0.001000, avg loss: 0.088557
2022-08-04 09:52:30,364 [dl_trainer.py:822] INFO Epoch 92, lr: 0.001000, val loss: 0.374976, val top-1 acc: 89.686502, top-5 acc: 99.640575
2022-08-04 09:52:30,808 [dl_trainer.py:731] WARNING [ 92][18040/  196][rank:0] loss: 0.011, average forward (0.011129) and backward (0.021193) time: 0.101569, iotime: 0.001568 
2022-08-04 09:52:31,819 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114178, Speed: 280.264466 images/s
2022-08-04 09:52:32,684 [dl_trainer.py:731] WARNING [ 92][18080/  196][rank:0] loss: 0.164, average forward (0.010018) and backward (0.020001) time: 0.031748, iotime: 0.001481 
2022-08-04 09:52:33,707 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047178, Speed: 678.287475 images/s
2022-08-04 09:52:34,511 [dl_trainer.py:731] WARNING [ 92][18120/  196][rank:0] loss: 0.051, average forward (0.010774) and backward (0.017690) time: 0.030259, iotime: 0.001538 
2022-08-04 09:52:35,241 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:52:35,242 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:52:36,494 [dl_trainer.py:731] WARNING [ 92][18160/  196][rank:0] loss: 0.044, average forward (0.009802) and backward (0.018767) time: 0.034595, iotime: 0.005738 
2022-08-04 09:52:37,271 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047486, Speed: 673.885805 images/s
2022-08-04 09:52:38,372 [dl_trainer.py:731] WARNING [ 92][18200/  196][rank:0] loss: 0.179, average forward (0.009673) and backward (0.019672) time: 0.031065, iotime: 0.001457 
2022-08-04 09:52:39,127 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046380, Speed: 689.954320 images/s
2022-08-04 09:52:39,683 [dl_trainer.py:634] INFO train iter: 18228, num_batches_per_epoch: 196
2022-08-04 09:52:39,683 [dl_trainer.py:635] INFO Epoch 93, avg train acc: 97.002551, lr: 0.001000, avg loss: 0.085564
2022-08-04 09:52:42,309 [dl_trainer.py:822] INFO Epoch 93, lr: 0.001000, val loss: 0.369932, val top-1 acc: 89.776358, top-5 acc: 99.680511
2022-08-04 09:52:42,876 [dl_trainer.py:731] WARNING [ 93][18240/  196][rank:0] loss: 0.039, average forward (0.009871) and backward (0.018890) time: 0.096202, iotime: 0.001471 
2022-08-04 09:52:43,596 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111734, Speed: 286.395565 images/s
2022-08-04 09:52:44,717 [dl_trainer.py:731] WARNING [ 93][18280/  196][rank:0] loss: 0.140, average forward (0.009909) and backward (0.019716) time: 0.031293, iotime: 0.001424 
2022-08-04 09:52:45,440 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046083, Speed: 694.396133 images/s
2022-08-04 09:52:46,535 [dl_trainer.py:731] WARNING [ 93][18320/  196][rank:0] loss: 0.074, average forward (0.010331) and backward (0.021085) time: 0.033247, iotime: 0.001579 
2022-08-04 09:52:47,026 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:52:47,026 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:52:48,548 [dl_trainer.py:731] WARNING [ 93][18360/  196][rank:0] loss: 0.017, average forward (0.009531) and backward (0.018005) time: 0.033328, iotime: 0.005522 
2022-08-04 09:52:49,018 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047684, Speed: 671.086671 images/s
2022-08-04 09:52:50,249 [dl_trainer.py:731] WARNING [ 93][18400/  196][rank:0] loss: 0.064, average forward (0.009727) and backward (0.016620) time: 0.027995, iotime: 0.001411 
2022-08-04 09:52:50,775 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043915, Speed: 728.674116 images/s
2022-08-04 09:52:51,388 [dl_trainer.py:634] INFO train iter: 18424, num_batches_per_epoch: 196
2022-08-04 09:52:51,389 [dl_trainer.py:635] INFO Epoch 94, avg train acc: 97.193878, lr: 0.001000, avg loss: 0.088459
2022-08-04 09:52:54,272 [dl_trainer.py:822] INFO Epoch 94, lr: 0.001000, val loss: 0.369032, val top-1 acc: 89.606629, top-5 acc: 99.660543
2022-08-04 09:52:54,987 [dl_trainer.py:731] WARNING [ 94][18440/  196][rank:0] loss: 0.155, average forward (0.009526) and backward (0.018444) time: 0.102267, iotime: 0.001354 
2022-08-04 09:52:55,492 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.117917, Speed: 271.376499 images/s
2022-08-04 09:52:56,782 [dl_trainer.py:731] WARNING [ 94][18480/  196][rank:0] loss: 0.036, average forward (0.010162) and backward (0.016181) time: 0.028053, iotime: 0.001455 
2022-08-04 09:52:57,250 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043923, Speed: 728.545667 images/s
2022-08-04 09:52:58,618 [dl_trainer.py:731] WARNING [ 94][18520/  196][rank:0] loss: 0.033, average forward (0.009917) and backward (0.018931) time: 0.030514, iotime: 0.001424 
2022-08-04 09:52:58,880 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:52:58,881 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:53:00,623 [dl_trainer.py:731] WARNING [ 94][18560/  196][rank:0] loss: 0.088, average forward (0.010073) and backward (0.020352) time: 0.036122, iotime: 0.005423 
2022-08-04 09:53:00,897 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048613, Speed: 658.266099 images/s
2022-08-04 09:53:02,386 [dl_trainer.py:731] WARNING [ 94][18600/  196][rank:0] loss: 0.024, average forward (0.009903) and backward (0.018574) time: 0.030146, iotime: 0.001432 
2022-08-04 09:53:02,657 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043988, Speed: 727.477612 images/s
2022-08-04 09:53:03,330 [dl_trainer.py:634] INFO train iter: 18620, num_batches_per_epoch: 196
2022-08-04 09:53:03,330 [dl_trainer.py:635] INFO Epoch 95, avg train acc: 97.002551, lr: 0.001000, avg loss: 0.086466
2022-08-04 09:53:06,039 [dl_trainer.py:822] INFO Epoch 95, lr: 0.001000, val loss: 0.367384, val top-1 acc: 89.906150, top-5 acc: 99.730431
2022-08-04 09:53:06,960 [dl_trainer.py:731] WARNING [ 95][18640/  196][rank:0] loss: 0.033, average forward (0.010728) and backward (0.021353) time: 0.101679, iotime: 0.001532 
2022-08-04 09:53:07,263 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115143, Speed: 277.914710 images/s
2022-08-04 09:53:08,803 [dl_trainer.py:731] WARNING [ 95][18680/  196][rank:0] loss: 0.022, average forward (0.009369) and backward (0.021859) time: 0.032837, iotime: 0.001371 
2022-08-04 09:53:09,078 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045355, Speed: 705.540259 images/s
2022-08-04 09:53:10,623 [dl_trainer.py:731] WARNING [ 95][18720/  196][rank:0] loss: 0.055, average forward (0.009873) and backward (0.019719) time: 0.031262, iotime: 0.001423 
2022-08-04 09:53:10,635 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:53:10,635 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:53:12,487 [dl_trainer.py:731] WARNING [ 95][18760/  196][rank:0] loss: 0.011, average forward (0.009697) and backward (0.017804) time: 0.033053, iotime: 0.005277 
2022-08-04 09:53:12,537 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046110, Speed: 693.988646 images/s
2022-08-04 09:53:14,370 [dl_trainer.py:731] WARNING [ 95][18800/  196][rank:0] loss: 0.032, average forward (0.010432) and backward (0.020022) time: 0.032306, iotime: 0.001586 
2022-08-04 09:53:14,447 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047731, Speed: 670.418975 images/s
2022-08-04 09:53:15,086 [dl_trainer.py:634] INFO train iter: 18816, num_batches_per_epoch: 196
2022-08-04 09:53:15,086 [dl_trainer.py:635] INFO Epoch 96, avg train acc: 96.954719, lr: 0.001000, avg loss: 0.092603
2022-08-04 09:53:17,744 [dl_trainer.py:822] INFO Epoch 96, lr: 0.001000, val loss: 0.365129, val top-1 acc: 89.986022, top-5 acc: 99.650559
2022-08-04 09:53:18,824 [dl_trainer.py:731] WARNING [ 96][18840/  196][rank:0] loss: 0.102, average forward (0.009901) and backward (0.018784) time: 0.098382, iotime: 0.001638 
2022-08-04 09:53:18,874 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110653, Speed: 289.191792 images/s
2022-08-04 09:53:20,615 [dl_trainer.py:731] WARNING [ 96][18880/  196][rank:0] loss: 0.060, average forward (0.010277) and backward (0.017074) time: 0.029247, iotime: 0.001643 
2022-08-04 09:53:20,672 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044954, Speed: 711.832698 images/s
2022-08-04 09:53:22,241 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:53:22,242 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:53:22,617 [dl_trainer.py:731] WARNING [ 96][18920/  196][rank:0] loss: 0.086, average forward (0.010200) and backward (0.017656) time: 0.033416, iotime: 0.005270 
2022-08-04 09:53:24,168 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046583, Speed: 686.944229 images/s
2022-08-04 09:53:24,320 [dl_trainer.py:731] WARNING [ 96][18960/  196][rank:0] loss: 0.060, average forward (0.009825) and backward (0.019455) time: 0.030984, iotime: 0.001470 
2022-08-04 09:53:25,851 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042059, Speed: 760.838802 images/s
2022-08-04 09:53:25,993 [dl_trainer.py:731] WARNING [ 96][19000/  196][rank:0] loss: 0.099, average forward (0.009456) and backward (0.015470) time: 0.026533, iotime: 0.001377 
2022-08-04 09:53:26,563 [dl_trainer.py:634] INFO train iter: 19012, num_batches_per_epoch: 196
2022-08-04 09:53:26,563 [dl_trainer.py:635] INFO Epoch 97, avg train acc: 97.130102, lr: 0.001000, avg loss: 0.085444
2022-08-04 09:53:29,266 [dl_trainer.py:822] INFO Epoch 97, lr: 0.001000, val loss: 0.374400, val top-1 acc: 89.846246, top-5 acc: 99.670527
2022-08-04 09:53:30,282 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110766, Speed: 288.896244 images/s
2022-08-04 09:53:30,442 [dl_trainer.py:731] WARNING [ 97][19040/  196][rank:0] loss: 0.059, average forward (0.009551) and backward (0.019831) time: 0.098803, iotime: 0.001528 
2022-08-04 09:53:32,004 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043033, Speed: 743.616638 images/s
2022-08-04 09:53:32,186 [dl_trainer.py:731] WARNING [ 97][19080/  196][rank:0] loss: 0.019, average forward (0.011065) and backward (0.019456) time: 0.032310, iotime: 0.001514 
2022-08-04 09:53:33,529 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:53:33,529 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:53:34,110 [dl_trainer.py:731] WARNING [ 97][19120/  196][rank:0] loss: 0.031, average forward (0.009848) and backward (0.019203) time: 0.034590, iotime: 0.005281 
2022-08-04 09:53:35,488 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046433, Speed: 689.158420 images/s
2022-08-04 09:53:35,833 [dl_trainer.py:731] WARNING [ 97][19160/  196][rank:0] loss: 0.057, average forward (0.009165) and backward (0.018814) time: 0.029540, iotime: 0.001329 
2022-08-04 09:53:37,116 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040681, Speed: 786.604684 images/s
2022-08-04 09:53:37,478 [dl_trainer.py:731] WARNING [ 97][19200/  196][rank:0] loss: 0.072, average forward (0.009931) and backward (0.017891) time: 0.029467, iotime: 0.001378 
2022-08-04 09:53:37,852 [dl_trainer.py:634] INFO train iter: 19208, num_batches_per_epoch: 196
2022-08-04 09:53:37,852 [dl_trainer.py:635] INFO Epoch 98, avg train acc: 97.130102, lr: 0.001000, avg loss: 0.087194
2022-08-04 09:53:40,534 [dl_trainer.py:822] INFO Epoch 98, lr: 0.001000, val loss: 0.373573, val top-1 acc: 89.656550, top-5 acc: 99.620607
2022-08-04 09:53:41,585 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111713, Speed: 286.447489 images/s
2022-08-04 09:53:42,006 [dl_trainer.py:731] WARNING [ 98][19240/  196][rank:0] loss: 0.179, average forward (0.008806) and backward (0.019847) time: 0.097891, iotime: 0.001364 
2022-08-04 09:53:43,395 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045240, Speed: 707.336636 images/s
2022-08-04 09:53:43,763 [dl_trainer.py:731] WARNING [ 98][19280/  196][rank:0] loss: 0.022, average forward (0.008940) and backward (0.019797) time: 0.030411, iotime: 0.001421 
2022-08-04 09:53:44,890 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:53:44,890 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:53:45,693 [dl_trainer.py:731] WARNING [ 98][19320/  196][rank:0] loss: 0.025, average forward (0.011035) and backward (0.018444) time: 0.034877, iotime: 0.005111 
2022-08-04 09:53:46,802 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045407, Speed: 704.740516 images/s
2022-08-04 09:53:47,405 [dl_trainer.py:731] WARNING [ 98][19360/  196][rank:0] loss: 0.076, average forward (0.008980) and backward (0.016902) time: 0.027488, iotime: 0.001376 
2022-08-04 09:53:48,509 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042664, Speed: 750.045666 images/s
2022-08-04 09:53:49,078 [dl_trainer.py:731] WARNING [ 98][19400/  196][rank:0] loss: 0.050, average forward (0.008831) and backward (0.016721) time: 0.027170, iotime: 0.001388 
2022-08-04 09:53:49,255 [dl_trainer.py:634] INFO train iter: 19404, num_batches_per_epoch: 196
2022-08-04 09:53:49,255 [dl_trainer.py:635] INFO Epoch 99, avg train acc: 97.098214, lr: 0.001000, avg loss: 0.084512
2022-08-04 09:53:51,936 [dl_trainer.py:822] INFO Epoch 99, lr: 0.001000, val loss: 0.373457, val top-1 acc: 89.826278, top-5 acc: 99.660543
2022-08-04 09:53:52,822 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.107812, Speed: 296.814105 images/s
2022-08-04 09:53:53,354 [dl_trainer.py:731] WARNING [ 99][19440/  196][rank:0] loss: 0.078, average forward (0.010660) and backward (0.015730) time: 0.095196, iotime: 0.001445 
2022-08-04 09:53:54,437 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040364, Speed: 792.777510 images/s
2022-08-04 09:53:54,983 [dl_trainer.py:731] WARNING [ 99][19480/  196][rank:0] loss: 0.105, average forward (0.009014) and backward (0.015814) time: 0.026351, iotime: 0.001304 
2022-08-04 09:53:55,874 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:53:55,874 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:53:56,911 [dl_trainer.py:731] WARNING [ 99][19520/  196][rank:0] loss: 0.092, average forward (0.009412) and backward (0.018446) time: 0.033097, iotime: 0.004935 
2022-08-04 09:53:57,859 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045613, Speed: 701.553899 images/s
2022-08-04 09:53:58,684 [dl_trainer.py:731] WARNING [ 99][19560/  196][rank:0] loss: 0.071, average forward (0.009703) and backward (0.019267) time: 0.030656, iotime: 0.001453 
2022-08-04 09:53:59,626 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044144, Speed: 724.897021 images/s
2022-08-04 09:54:00,450 [dl_trainer.py:731] WARNING [ 99][19600/  196][rank:0] loss: 0.044, average forward (0.008097) and backward (0.019792) time: 0.029340, iotime: 0.001236 
2022-08-04 09:54:00,459 [dl_trainer.py:634] INFO train iter: 19600, num_batches_per_epoch: 196
2022-08-04 09:54:00,459 [dl_trainer.py:635] INFO Epoch 100, avg train acc: 97.161990, lr: 0.001000, avg loss: 0.086487
2022-08-04 09:54:03,116 [dl_trainer.py:822] INFO Epoch 100, lr: 0.001000, val loss: 0.371712, val top-1 acc: 89.696486, top-5 acc: 99.650559
2022-08-04 09:54:04,120 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112358, Speed: 284.805129 images/s
2022-08-04 09:54:04,910 [dl_trainer.py:731] WARNING [100][19640/  196][rank:0] loss: 0.154, average forward (0.009122) and backward (0.019158) time: 0.097401, iotime: 0.001329 
2022-08-04 09:54:05,856 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043394, Speed: 737.424591 images/s
2022-08-04 09:54:06,658 [dl_trainer.py:731] WARNING [100][19680/  196][rank:0] loss: 0.043, average forward (0.008790) and backward (0.017221) time: 0.027579, iotime: 0.001329 
2022-08-04 09:54:07,325 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:54:07,325 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:54:08,597 [dl_trainer.py:731] WARNING [100][19720/  196][rank:0] loss: 0.100, average forward (0.009338) and backward (0.018468) time: 0.032874, iotime: 0.004806 
2022-08-04 09:54:09,366 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046776, Speed: 684.108595 images/s
2022-08-04 09:54:10,399 [dl_trainer.py:731] WARNING [100][19760/  196][rank:0] loss: 0.010, average forward (0.008544) and backward (0.019250) time: 0.029320, iotime: 0.001294 
2022-08-04 09:54:11,092 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043145, Speed: 741.676598 images/s
2022-08-04 09:54:11,991 [dl_trainer.py:634] INFO train iter: 19796, num_batches_per_epoch: 196
2022-08-04 09:54:11,992 [dl_trainer.py:635] INFO Epoch 101, avg train acc: 97.241709, lr: 0.001000, avg loss: 0.077820
2022-08-04 09:54:14,659 [dl_trainer.py:822] INFO Epoch 101, lr: 0.001000, val loss: 0.375393, val top-1 acc: 89.776358, top-5 acc: 99.630591
2022-08-04 09:54:14,821 [dl_trainer.py:731] WARNING [101][19800/  196][rank:0] loss: 0.092, average forward (0.008853) and backward (0.017552) time: 0.094666, iotime: 0.001283 
2022-08-04 09:54:15,562 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111737, Speed: 286.386949 images/s
2022-08-04 09:54:16,644 [dl_trainer.py:731] WARNING [101][19840/  196][rank:0] loss: 0.125, average forward (0.008976) and backward (0.017683) time: 0.028248, iotime: 0.001354 
2022-08-04 09:54:17,346 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044577, Speed: 717.854338 images/s
2022-08-04 09:54:18,378 [dl_trainer.py:731] WARNING [101][19880/  196][rank:0] loss: 0.026, average forward (0.009936) and backward (0.017291) time: 0.028836, iotime: 0.001379 
2022-08-04 09:54:18,857 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:54:18,858 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:54:20,335 [dl_trainer.py:731] WARNING [101][19920/  196][rank:0] loss: 0.067, average forward (0.010987) and backward (0.018487) time: 0.035258, iotime: 0.005486 
2022-08-04 09:54:20,841 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046595, Speed: 686.772041 images/s
2022-08-04 09:54:22,087 [dl_trainer.py:731] WARNING [101][19960/  196][rank:0] loss: 0.078, average forward (0.010015) and backward (0.019280) time: 0.031037, iotime: 0.001506 
2022-08-04 09:54:22,602 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044016, Speed: 727.015586 images/s
2022-08-04 09:54:23,448 [dl_trainer.py:634] INFO train iter: 19992, num_batches_per_epoch: 196
2022-08-04 09:54:23,449 [dl_trainer.py:635] INFO Epoch 102, avg train acc: 96.779337, lr: 0.001000, avg loss: 0.092543
2022-08-04 09:54:26,120 [dl_trainer.py:822] INFO Epoch 102, lr: 0.001000, val loss: 0.367775, val top-1 acc: 89.756390, top-5 acc: 99.650559
2022-08-04 09:54:26,472 [dl_trainer.py:731] WARNING [102][20000/  196][rank:0] loss: 0.020, average forward (0.009018) and backward (0.019363) time: 0.097410, iotime: 0.001306 
2022-08-04 09:54:26,946 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.108577, Speed: 294.722168 images/s
2022-08-04 09:54:28,197 [dl_trainer.py:731] WARNING [102][20040/  196][rank:0] loss: 0.221, average forward (0.010321) and backward (0.018654) time: 0.030682, iotime: 0.001457 
2022-08-04 09:54:28,673 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043166, Speed: 741.319283 images/s
2022-08-04 09:54:29,912 [dl_trainer.py:731] WARNING [102][20080/  196][rank:0] loss: 0.056, average forward (0.010260) and backward (0.016458) time: 0.028439, iotime: 0.001478 
2022-08-04 09:54:30,177 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:54:30,177 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:54:31,755 [dl_trainer.py:731] WARNING [102][20120/  196][rank:0] loss: 0.054, average forward (0.009051) and backward (0.018407) time: 0.032713, iotime: 0.005003 
2022-08-04 09:54:32,047 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044968, Speed: 711.617435 images/s
2022-08-04 09:54:33,604 [dl_trainer.py:731] WARNING [102][20160/  196][rank:0] loss: 0.071, average forward (0.011344) and backward (0.018396) time: 0.031572, iotime: 0.001550 
2022-08-04 09:54:33,892 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046128, Speed: 693.726496 images/s
2022-08-04 09:54:34,935 [dl_trainer.py:634] INFO train iter: 20188, num_batches_per_epoch: 196
2022-08-04 09:54:34,935 [dl_trainer.py:635] INFO Epoch 103, avg train acc: 97.417092, lr: 0.001000, avg loss: 0.080754
2022-08-04 09:54:37,604 [dl_trainer.py:822] INFO Epoch 103, lr: 0.001000, val loss: 0.369998, val top-1 acc: 89.796326, top-5 acc: 99.650559
2022-08-04 09:54:38,159 [dl_trainer.py:731] WARNING [103][20200/  196][rank:0] loss: 0.048, average forward (0.009909) and backward (0.019286) time: 0.097634, iotime: 0.001430 
2022-08-04 09:54:38,428 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113391, Speed: 282.209584 images/s
2022-08-04 09:54:39,975 [dl_trainer.py:731] WARNING [103][20240/  196][rank:0] loss: 0.054, average forward (0.008883) and backward (0.020354) time: 0.030825, iotime: 0.001354 
2022-08-04 09:54:40,265 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045918, Speed: 696.889945 images/s
2022-08-04 09:54:41,799 [dl_trainer.py:731] WARNING [103][20280/  196][rank:0] loss: 0.138, average forward (0.009545) and backward (0.019985) time: 0.031201, iotime: 0.001429 
2022-08-04 09:54:41,825 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:54:41,826 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:54:43,677 [dl_trainer.py:731] WARNING [103][20320/  196][rank:0] loss: 0.057, average forward (0.010455) and backward (0.017926) time: 0.034287, iotime: 0.005619 
2022-08-04 09:54:43,733 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046210, Speed: 692.493951 images/s
2022-08-04 09:54:45,515 [dl_trainer.py:731] WARNING [103][20360/  196][rank:0] loss: 0.025, average forward (0.009271) and backward (0.018224) time: 0.029169, iotime: 0.001428 
2022-08-04 09:54:45,588 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046364, Speed: 690.195849 images/s
2022-08-04 09:54:46,661 [dl_trainer.py:634] INFO train iter: 20384, num_batches_per_epoch: 196
2022-08-04 09:54:46,661 [dl_trainer.py:635] INFO Epoch 104, avg train acc: 97.656250, lr: 0.001000, avg loss: 0.077231
2022-08-04 09:54:49,288 [dl_trainer.py:822] INFO Epoch 104, lr: 0.001000, val loss: 0.393235, val top-1 acc: 89.686502, top-5 acc: 99.610623
2022-08-04 09:54:50,015 [dl_trainer.py:731] WARNING [104][20400/  196][rank:0] loss: 0.054, average forward (0.009739) and backward (0.021061) time: 0.098680, iotime: 0.001414 
2022-08-04 09:54:50,074 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112150, Speed: 285.332489 images/s
2022-08-04 09:54:51,667 [dl_trainer.py:731] WARNING [104][20440/  196][rank:0] loss: 0.044, average forward (0.008947) and backward (0.018051) time: 0.028558, iotime: 0.001341 
2022-08-04 09:54:51,710 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040898, Speed: 782.434782 images/s
2022-08-04 09:54:53,125 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:54:53,125 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:54:53,508 [dl_trainer.py:731] WARNING [104][20480/  196][rank:0] loss: 0.034, average forward (0.008935) and backward (0.017291) time: 0.031843, iotime: 0.005364 
2022-08-04 09:54:55,199 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046497, Speed: 688.211056 images/s
2022-08-04 09:54:55,367 [dl_trainer.py:731] WARNING [104][20520/  196][rank:0] loss: 0.123, average forward (0.010220) and backward (0.021813) time: 0.033823, iotime: 0.001537 
2022-08-04 09:54:57,031 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045774, Speed: 699.090082 images/s
2022-08-04 09:54:57,202 [dl_trainer.py:731] WARNING [104][20560/  196][rank:0] loss: 0.159, average forward (0.010221) and backward (0.018133) time: 0.030077, iotime: 0.001481 
2022-08-04 09:54:58,055 [dl_trainer.py:634] INFO train iter: 20580, num_batches_per_epoch: 196
2022-08-04 09:54:58,055 [dl_trainer.py:635] INFO Epoch 105, avg train acc: 96.906888, lr: 0.001000, avg loss: 0.088989
2022-08-04 09:55:00,774 [dl_trainer.py:822] INFO Epoch 105, lr: 0.001000, val loss: 0.375115, val top-1 acc: 89.966054, top-5 acc: 99.660543
2022-08-04 09:55:01,505 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111859, Speed: 286.074495 images/s
2022-08-04 09:55:01,657 [dl_trainer.py:731] WARNING [105][20600/  196][rank:0] loss: 0.007, average forward (0.009979) and backward (0.017465) time: 0.097276, iotime: 0.001529 
2022-08-04 09:55:03,229 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043078, Speed: 742.838480 images/s
2022-08-04 09:55:03,379 [dl_trainer.py:731] WARNING [105][20640/  196][rank:0] loss: 0.088, average forward (0.009751) and backward (0.017846) time: 0.029283, iotime: 0.001438 
2022-08-04 09:55:04,701 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:55:04,701 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:55:05,291 [dl_trainer.py:731] WARNING [105][20680/  196][rank:0] loss: 0.119, average forward (0.010482) and backward (0.018398) time: 0.034524, iotime: 0.005346 
2022-08-04 09:55:06,570 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044528, Speed: 718.652564 images/s
2022-08-04 09:55:06,898 [dl_trainer.py:731] WARNING [105][20720/  196][rank:0] loss: 0.079, average forward (0.009409) and backward (0.015982) time: 0.026976, iotime: 0.001352 
2022-08-04 09:55:08,260 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042237, Speed: 757.626222 images/s
2022-08-04 09:55:08,606 [dl_trainer.py:731] WARNING [105][20760/  196][rank:0] loss: 0.135, average forward (0.009518) and backward (0.018009) time: 0.029170, iotime: 0.001407 
2022-08-04 09:55:09,347 [dl_trainer.py:634] INFO train iter: 20776, num_batches_per_epoch: 196
2022-08-04 09:55:09,347 [dl_trainer.py:635] INFO Epoch 106, avg train acc: 97.050383, lr: 0.001000, avg loss: 0.086917
2022-08-04 09:55:11,951 [dl_trainer.py:822] INFO Epoch 106, lr: 0.001000, val loss: 0.382725, val top-1 acc: 89.806310, top-5 acc: 99.630591
2022-08-04 09:55:12,630 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109231, Speed: 292.958020 images/s
2022-08-04 09:55:13,000 [dl_trainer.py:731] WARNING [106][20800/  196][rank:0] loss: 0.048, average forward (0.009124) and backward (0.020055) time: 0.096416, iotime: 0.001364 
2022-08-04 09:55:14,433 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045066, Speed: 710.072696 images/s
2022-08-04 09:55:14,792 [dl_trainer.py:731] WARNING [106][20840/  196][rank:0] loss: 0.053, average forward (0.010126) and backward (0.018295) time: 0.030164, iotime: 0.001494 
2022-08-04 09:55:15,909 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:55:15,909 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:55:16,707 [dl_trainer.py:731] WARNING [106][20880/  196][rank:0] loss: 0.060, average forward (0.009590) and backward (0.018465) time: 0.033840, iotime: 0.005513 
2022-08-04 09:55:17,770 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044470, Speed: 719.590426 images/s
2022-08-04 09:55:18,364 [dl_trainer.py:731] WARNING [106][20920/  196][rank:0] loss: 0.053, average forward (0.009058) and backward (0.017608) time: 0.028243, iotime: 0.001331 
2022-08-04 09:55:19,533 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044069, Speed: 726.130513 images/s
2022-08-04 09:55:20,143 [dl_trainer.py:731] WARNING [106][20960/  196][rank:0] loss: 0.065, average forward (0.009194) and backward (0.018696) time: 0.029489, iotime: 0.001364 
2022-08-04 09:55:20,705 [dl_trainer.py:634] INFO train iter: 20972, num_batches_per_epoch: 196
2022-08-04 09:55:20,705 [dl_trainer.py:635] INFO Epoch 107, avg train acc: 97.050383, lr: 0.001000, avg loss: 0.080299
2022-08-04 09:55:23,344 [dl_trainer.py:822] INFO Epoch 107, lr: 0.001000, val loss: 0.384225, val top-1 acc: 89.976038, top-5 acc: 99.630591
2022-08-04 09:55:24,008 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111853, Speed: 286.088657 images/s
2022-08-04 09:55:24,581 [dl_trainer.py:731] WARNING [107][21000/  196][rank:0] loss: 0.085, average forward (0.010603) and backward (0.020069) time: 0.098485, iotime: 0.001506 
2022-08-04 09:55:25,749 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043509, Speed: 735.474666 images/s
2022-08-04 09:55:26,313 [dl_trainer.py:731] WARNING [107][21040/  196][rank:0] loss: 0.042, average forward (0.010446) and backward (0.016645) time: 0.028964, iotime: 0.001620 
2022-08-04 09:55:27,135 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:55:27,135 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:55:28,194 [dl_trainer.py:731] WARNING [107][21080/  196][rank:0] loss: 0.117, average forward (0.010433) and backward (0.016981) time: 0.033076, iotime: 0.005370 
2022-08-04 09:55:29,177 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045681, Speed: 700.516351 images/s
2022-08-04 09:55:29,974 [dl_trainer.py:731] WARNING [107][21120/  196][rank:0] loss: 0.026, average forward (0.008724) and backward (0.018325) time: 0.028617, iotime: 0.001344 
2022-08-04 09:55:30,837 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041481, Speed: 771.435194 images/s
2022-08-04 09:55:31,575 [dl_trainer.py:731] WARNING [107][21160/  196][rank:0] loss: 0.044, average forward (0.009242) and backward (0.017309) time: 0.028135, iotime: 0.001341 
2022-08-04 09:55:31,889 [dl_trainer.py:634] INFO train iter: 21168, num_batches_per_epoch: 196
2022-08-04 09:55:31,890 [dl_trainer.py:635] INFO Epoch 108, avg train acc: 97.799745, lr: 0.001000, avg loss: 0.072226
2022-08-04 09:55:34,543 [dl_trainer.py:822] INFO Epoch 108, lr: 0.001000, val loss: 0.383823, val top-1 acc: 89.846246, top-5 acc: 99.670527
2022-08-04 09:55:35,109 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.106773, Speed: 299.701517 images/s
2022-08-04 09:55:35,844 [dl_trainer.py:731] WARNING [108][21200/  196][rank:0] loss: 0.070, average forward (0.009683) and backward (0.017972) time: 0.096090, iotime: 0.001322 
2022-08-04 09:55:36,745 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040886, Speed: 782.656409 images/s
2022-08-04 09:55:37,515 [dl_trainer.py:731] WARNING [108][21240/  196][rank:0] loss: 0.013, average forward (0.009377) and backward (0.018321) time: 0.029299, iotime: 0.001363 
2022-08-04 09:55:38,210 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:55:38,210 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:55:39,464 [dl_trainer.py:731] WARNING [108][21280/  196][rank:0] loss: 0.042, average forward (0.010828) and backward (0.018909) time: 0.035290, iotime: 0.005262 
2022-08-04 09:55:40,171 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045664, Speed: 700.769108 images/s
2022-08-04 09:55:41,193 [dl_trainer.py:731] WARNING [108][21320/  196][rank:0] loss: 0.060, average forward (0.009977) and backward (0.018763) time: 0.030439, iotime: 0.001457 
2022-08-04 09:55:41,908 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043392, Speed: 737.465615 images/s
2022-08-04 09:55:42,932 [dl_trainer.py:731] WARNING [108][21360/  196][rank:0] loss: 0.052, average forward (0.009251) and backward (0.020274) time: 0.031079, iotime: 0.001328 
2022-08-04 09:55:43,120 [dl_trainer.py:634] INFO train iter: 21364, num_batches_per_epoch: 196
2022-08-04 09:55:43,121 [dl_trainer.py:635] INFO Epoch 109, avg train acc: 97.289541, lr: 0.001000, avg loss: 0.082588
2022-08-04 09:55:45,743 [dl_trainer.py:822] INFO Epoch 109, lr: 0.001000, val loss: 0.381203, val top-1 acc: 89.746406, top-5 acc: 99.690495
2022-08-04 09:55:46,275 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109164, Speed: 293.135668 images/s
2022-08-04 09:55:47,283 [dl_trainer.py:731] WARNING [109][21400/  196][rank:0] loss: 0.083, average forward (0.009448) and backward (0.018531) time: 0.095159, iotime: 0.001311 
2022-08-04 09:55:47,989 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042843, Speed: 746.905942 images/s
2022-08-04 09:55:48,923 [dl_trainer.py:731] WARNING [109][21440/  196][rank:0] loss: 0.254, average forward (0.009098) and backward (0.015191) time: 0.025825, iotime: 0.001306 
2022-08-04 09:55:49,377 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:55:49,377 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:55:50,792 [dl_trainer.py:731] WARNING [109][21480/  196][rank:0] loss: 0.027, average forward (0.009750) and backward (0.017636) time: 0.033069, iotime: 0.005420 
2022-08-04 09:55:51,269 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043724, Speed: 731.863141 images/s
2022-08-04 09:55:52,536 [dl_trainer.py:731] WARNING [109][21520/  196][rank:0] loss: 0.118, average forward (0.009250) and backward (0.019190) time: 0.030049, iotime: 0.001384 
2022-08-04 09:55:53,016 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043655, Speed: 733.013532 images/s
2022-08-04 09:55:54,278 [dl_trainer.py:731] WARNING [109][21560/  196][rank:0] loss: 0.075, average forward (0.009998) and backward (0.018751) time: 0.030399, iotime: 0.001421 
2022-08-04 09:55:54,289 [dl_trainer.py:634] INFO train iter: 21560, num_batches_per_epoch: 196
2022-08-04 09:55:54,290 [dl_trainer.py:635] INFO Epoch 110, avg train acc: 97.385204, lr: 0.001000, avg loss: 0.084445
2022-08-04 09:55:56,960 [dl_trainer.py:822] INFO Epoch 110, lr: 0.001000, val loss: 0.378669, val top-1 acc: 89.716454, top-5 acc: 99.660543
2022-08-04 09:55:57,520 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112591, Speed: 284.214927 images/s
2022-08-04 09:55:58,829 [dl_trainer.py:731] WARNING [110][21600/  196][rank:0] loss: 0.055, average forward (0.010661) and backward (0.018665) time: 0.100025, iotime: 0.001605 
2022-08-04 09:55:59,282 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044040, Speed: 726.619146 images/s
2022-08-04 09:56:00,511 [dl_trainer.py:731] WARNING [110][21640/  196][rank:0] loss: 0.070, average forward (0.009295) and backward (0.019435) time: 0.030405, iotime: 0.001444 
2022-08-04 09:56:00,749 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:56:00,750 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:56:02,472 [dl_trainer.py:731] WARNING [110][21680/  196][rank:0] loss: 0.038, average forward (0.010246) and backward (0.018637) time: 0.034499, iotime: 0.005344 
2022-08-04 09:56:02,773 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046519, Speed: 687.894781 images/s
2022-08-04 09:56:04,274 [dl_trainer.py:731] WARNING [110][21720/  196][rank:0] loss: 0.068, average forward (0.009188) and backward (0.019853) time: 0.030625, iotime: 0.001341 
2022-08-04 09:56:04,566 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044794, Speed: 714.387202 images/s
2022-08-04 09:56:05,934 [dl_trainer.py:634] INFO train iter: 21756, num_batches_per_epoch: 196
2022-08-04 09:56:05,934 [dl_trainer.py:635] INFO Epoch 111, avg train acc: 97.480867, lr: 0.001000, avg loss: 0.078217
2022-08-04 09:56:08,621 [dl_trainer.py:822] INFO Epoch 111, lr: 0.001000, val loss: 0.380362, val top-1 acc: 89.716454, top-5 acc: 99.680511
2022-08-04 09:56:08,810 [dl_trainer.py:731] WARNING [111][21760/  196][rank:0] loss: 0.107, average forward (0.009634) and backward (0.020180) time: 0.098714, iotime: 0.001432 
2022-08-04 09:56:09,119 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113832, Speed: 281.115965 images/s
2022-08-04 09:56:10,701 [dl_trainer.py:731] WARNING [111][21800/  196][rank:0] loss: 0.045, average forward (0.009400) and backward (0.020444) time: 0.031491, iotime: 0.001411 
2022-08-04 09:56:10,988 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046710, Speed: 685.082739 images/s
2022-08-04 09:56:12,587 [dl_trainer.py:731] WARNING [111][21840/  196][rank:0] loss: 0.106, average forward (0.010235) and backward (0.020389) time: 0.032341, iotime: 0.001446 
2022-08-04 09:56:12,599 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:56:12,600 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:56:14,513 [dl_trainer.py:731] WARNING [111][21880/  196][rank:0] loss: 0.151, average forward (0.010518) and backward (0.019281) time: 0.035323, iotime: 0.005254 
2022-08-04 09:56:14,574 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047787, Speed: 669.631344 images/s
2022-08-04 09:56:16,359 [dl_trainer.py:731] WARNING [111][21920/  196][rank:0] loss: 0.039, average forward (0.009832) and backward (0.020270) time: 0.031824, iotime: 0.001479 
2022-08-04 09:56:16,421 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046163, Speed: 693.195690 images/s
2022-08-04 09:56:17,761 [dl_trainer.py:634] INFO train iter: 21952, num_batches_per_epoch: 196
2022-08-04 09:56:17,762 [dl_trainer.py:635] INFO Epoch 112, avg train acc: 97.369260, lr: 0.001000, avg loss: 0.079279
2022-08-04 09:56:20,414 [dl_trainer.py:822] INFO Epoch 112, lr: 0.001000, val loss: 0.389239, val top-1 acc: 89.886182, top-5 acc: 99.660543
2022-08-04 09:56:20,846 [dl_trainer.py:731] WARNING [112][21960/  196][rank:0] loss: 0.152, average forward (0.009192) and backward (0.019437) time: 0.098142, iotime: 0.001363 
2022-08-04 09:56:20,894 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111819, Speed: 286.176465 images/s
2022-08-04 09:56:22,655 [dl_trainer.py:731] WARNING [112][22000/  196][rank:0] loss: 0.076, average forward (0.009827) and backward (0.021038) time: 0.032565, iotime: 0.001455 
2022-08-04 09:56:22,721 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045670, Speed: 700.678101 images/s
2022-08-04 09:56:24,182 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:56:24,182 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:56:24,563 [dl_trainer.py:731] WARNING [112][22040/  196][rank:0] loss: 0.099, average forward (0.009008) and backward (0.018519) time: 0.032737, iotime: 0.004969 
2022-08-04 09:56:26,189 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046225, Speed: 692.264980 images/s
2022-08-04 09:56:26,352 [dl_trainer.py:731] WARNING [112][22080/  196][rank:0] loss: 0.014, average forward (0.009983) and backward (0.019074) time: 0.030756, iotime: 0.001442 
2022-08-04 09:56:27,988 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044956, Speed: 711.809292 images/s
2022-08-04 09:56:28,165 [dl_trainer.py:731] WARNING [112][22120/  196][rank:0] loss: 0.092, average forward (0.009833) and backward (0.019725) time: 0.031334, iotime: 0.001531 
2022-08-04 09:56:29,399 [dl_trainer.py:634] INFO train iter: 22148, num_batches_per_epoch: 196
2022-08-04 09:56:29,399 [dl_trainer.py:635] INFO Epoch 113, avg train acc: 97.353316, lr: 0.001000, avg loss: 0.083387
2022-08-04 09:56:32,108 [dl_trainer.py:822] INFO Epoch 113, lr: 0.001000, val loss: 0.386667, val top-1 acc: 89.946086, top-5 acc: 99.640575
2022-08-04 09:56:32,479 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112267, Speed: 285.034300 images/s
2022-08-04 09:56:32,639 [dl_trainer.py:731] WARNING [113][22160/  196][rank:0] loss: 0.136, average forward (0.010141) and backward (0.018831) time: 0.098483, iotime: 0.001471 
2022-08-04 09:56:34,098 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040468, Speed: 790.740881 images/s
2022-08-04 09:56:34,258 [dl_trainer.py:731] WARNING [113][22200/  196][rank:0] loss: 0.045, average forward (0.009089) and backward (0.016984) time: 0.027587, iotime: 0.001284 
2022-08-04 09:56:35,576 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:56:35,576 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:56:36,152 [dl_trainer.py:731] WARNING [113][22240/  196][rank:0] loss: 0.041, average forward (0.010166) and backward (0.018330) time: 0.034512, iotime: 0.005726 
2022-08-04 09:56:37,486 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045148, Speed: 708.781648 images/s
2022-08-04 09:56:37,864 [dl_trainer.py:731] WARNING [113][22280/  196][rank:0] loss: 0.052, average forward (0.009375) and backward (0.017267) time: 0.028290, iotime: 0.001414 
2022-08-04 09:56:39,204 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042939, Speed: 745.250057 images/s
2022-08-04 09:56:39,573 [dl_trainer.py:731] WARNING [113][22320/  196][rank:0] loss: 0.027, average forward (0.008650) and backward (0.018309) time: 0.028595, iotime: 0.001412 
2022-08-04 09:56:40,603 [dl_trainer.py:634] INFO train iter: 22344, num_batches_per_epoch: 196
2022-08-04 09:56:40,603 [dl_trainer.py:635] INFO Epoch 114, avg train acc: 97.448980, lr: 0.001000, avg loss: 0.082391
2022-08-04 09:56:43,173 [dl_trainer.py:822] INFO Epoch 114, lr: 0.001000, val loss: 0.380561, val top-1 acc: 89.776358, top-5 acc: 99.620607
2022-08-04 09:56:43,519 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.107865, Speed: 296.667918 images/s
2022-08-04 09:56:43,926 [dl_trainer.py:731] WARNING [114][22360/  196][rank:0] loss: 0.057, average forward (0.010340) and backward (0.017762) time: 0.094757, iotime: 0.001464 
2022-08-04 09:56:45,400 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047025, Speed: 680.483307 images/s
2022-08-04 09:56:45,778 [dl_trainer.py:731] WARNING [114][22400/  196][rank:0] loss: 0.061, average forward (0.009708) and backward (0.020518) time: 0.031950, iotime: 0.001472 
2022-08-04 09:56:46,947 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:56:46,947 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:56:47,799 [dl_trainer.py:731] WARNING [114][22440/  196][rank:0] loss: 0.098, average forward (0.010094) and backward (0.018949) time: 0.034883, iotime: 0.005577 
2022-08-04 09:56:49,002 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048005, Speed: 666.597947 images/s
2022-08-04 09:56:49,660 [dl_trainer.py:731] WARNING [114][22480/  196][rank:0] loss: 0.079, average forward (0.009341) and backward (0.020324) time: 0.031274, iotime: 0.001362 
2022-08-04 09:56:50,809 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045161, Speed: 708.582485 images/s
2022-08-04 09:56:51,473 [dl_trainer.py:731] WARNING [114][22520/  196][rank:0] loss: 0.013, average forward (0.008746) and backward (0.019090) time: 0.029454, iotime: 0.001380 
2022-08-04 09:56:52,404 [dl_trainer.py:634] INFO train iter: 22540, num_batches_per_epoch: 196
2022-08-04 09:56:52,404 [dl_trainer.py:635] INFO Epoch 115, avg train acc: 97.098214, lr: 0.001000, avg loss: 0.083732
2022-08-04 09:56:55,059 [dl_trainer.py:822] INFO Epoch 115, lr: 0.001000, val loss: 0.380640, val top-1 acc: 89.866214, top-5 acc: 99.660543
2022-08-04 09:56:55,323 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112841, Speed: 283.583838 images/s
2022-08-04 09:56:55,976 [dl_trainer.py:731] WARNING [115][22560/  196][rank:0] loss: 0.017, average forward (0.009524) and backward (0.019760) time: 0.097353, iotime: 0.001384 
2022-08-04 09:56:57,228 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047606, Speed: 672.178241 images/s
2022-08-04 09:56:57,863 [dl_trainer.py:731] WARNING [115][22600/  196][rank:0] loss: 0.018, average forward (0.008454) and backward (0.021621) time: 0.031622, iotime: 0.001328 
2022-08-04 09:56:58,823 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:56:58,823 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:56:59,815 [dl_trainer.py:731] WARNING [115][22640/  196][rank:0] loss: 0.089, average forward (0.010775) and backward (0.016970) time: 0.033280, iotime: 0.005241 
2022-08-04 09:57:00,825 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047948, Speed: 667.392575 images/s
2022-08-04 09:57:01,668 [dl_trainer.py:731] WARNING [115][22680/  196][rank:0] loss: 0.131, average forward (0.009582) and backward (0.018310) time: 0.029571, iotime: 0.001438 
2022-08-04 09:57:02,606 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044513, Speed: 718.894495 images/s
2022-08-04 09:57:03,405 [dl_trainer.py:731] WARNING [115][22720/  196][rank:0] loss: 0.064, average forward (0.009396) and backward (0.017867) time: 0.028853, iotime: 0.001358 
2022-08-04 09:57:04,102 [dl_trainer.py:634] INFO train iter: 22736, num_batches_per_epoch: 196
2022-08-04 09:57:04,102 [dl_trainer.py:635] INFO Epoch 116, avg train acc: 97.337372, lr: 0.001000, avg loss: 0.075439
2022-08-04 09:57:06,757 [dl_trainer.py:822] INFO Epoch 116, lr: 0.001000, val loss: 0.383196, val top-1 acc: 89.776358, top-5 acc: 99.670527
2022-08-04 09:57:06,995 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109707, Speed: 291.685250 images/s
2022-08-04 09:57:07,773 [dl_trainer.py:731] WARNING [116][22760/  196][rank:0] loss: 0.019, average forward (0.010170) and backward (0.016483) time: 0.095237, iotime: 0.001372 
2022-08-04 09:57:08,696 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042530, Speed: 752.416703 images/s
2022-08-04 09:57:09,478 [dl_trainer.py:731] WARNING [116][22800/  196][rank:0] loss: 0.024, average forward (0.010073) and backward (0.016901) time: 0.028704, iotime: 0.001475 
2022-08-04 09:57:10,179 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:57:10,180 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:57:11,458 [dl_trainer.py:731] WARNING [116][22840/  196][rank:0] loss: 0.122, average forward (0.010134) and backward (0.018935) time: 0.034653, iotime: 0.005303 
2022-08-04 09:57:12,178 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046402, Speed: 689.626820 images/s
2022-08-04 09:57:13,260 [dl_trainer.py:731] WARNING [116][22880/  196][rank:0] loss: 0.055, average forward (0.009901) and backward (0.018967) time: 0.030551, iotime: 0.001430 
2022-08-04 09:57:14,014 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045891, Speed: 697.301692 images/s
2022-08-04 09:57:15,102 [dl_trainer.py:731] WARNING [116][22920/  196][rank:0] loss: 0.007, average forward (0.008247) and backward (0.019613) time: 0.029380, iotime: 0.001303 
2022-08-04 09:57:15,712 [dl_trainer.py:634] INFO train iter: 22932, num_batches_per_epoch: 196
2022-08-04 09:57:15,712 [dl_trainer.py:635] INFO Epoch 117, avg train acc: 97.433036, lr: 0.001000, avg loss: 0.075717
2022-08-04 09:57:18,482 [dl_trainer.py:822] INFO Epoch 117, lr: 0.001000, val loss: 0.388802, val top-1 acc: 89.856230, top-5 acc: 99.640575
2022-08-04 09:57:18,674 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.116492, Speed: 274.697586 images/s
2022-08-04 09:57:19,654 [dl_trainer.py:731] WARNING [117][22960/  196][rank:0] loss: 0.044, average forward (0.009415) and backward (0.018244) time: 0.098661, iotime: 0.001437 
2022-08-04 09:57:20,344 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041720, Speed: 767.023862 images/s
2022-08-04 09:57:21,389 [dl_trainer.py:731] WARNING [117][23000/  196][rank:0] loss: 0.090, average forward (0.009681) and backward (0.017581) time: 0.028956, iotime: 0.001450 
2022-08-04 09:57:21,877 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:57:21,877 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:57:23,345 [dl_trainer.py:731] WARNING [117][23040/  196][rank:0] loss: 0.201, average forward (0.009901) and backward (0.018204) time: 0.034059, iotime: 0.005686 
2022-08-04 09:57:23,851 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046751, Speed: 684.476964 images/s
2022-08-04 09:57:25,191 [dl_trainer.py:731] WARNING [117][23080/  196][rank:0] loss: 0.088, average forward (0.010140) and backward (0.018918) time: 0.030794, iotime: 0.001488 
2022-08-04 09:57:25,693 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046029, Speed: 695.219626 images/s
2022-08-04 09:57:26,988 [dl_trainer.py:731] WARNING [117][23120/  196][rank:0] loss: 0.044, average forward (0.009114) and backward (0.019002) time: 0.029740, iotime: 0.001387 
2022-08-04 09:57:27,386 [dl_trainer.py:634] INFO train iter: 23128, num_batches_per_epoch: 196
2022-08-04 09:57:27,387 [dl_trainer.py:635] INFO Epoch 118, avg train acc: 97.496811, lr: 0.001000, avg loss: 0.074601
2022-08-04 09:57:30,033 [dl_trainer.py:822] INFO Epoch 118, lr: 0.001000, val loss: 0.387205, val top-1 acc: 89.566693, top-5 acc: 99.640575
2022-08-04 09:57:30,195 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112552, Speed: 284.312459 images/s
2022-08-04 09:57:31,477 [dl_trainer.py:731] WARNING [118][23160/  196][rank:0] loss: 0.096, average forward (0.009158) and backward (0.020152) time: 0.097580, iotime: 0.001359 
2022-08-04 09:57:31,995 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044989, Speed: 711.292586 images/s
2022-08-04 09:57:33,250 [dl_trainer.py:731] WARNING [118][23200/  196][rank:0] loss: 0.015, average forward (0.010045) and backward (0.017583) time: 0.029356, iotime: 0.001475 
2022-08-04 09:57:33,504 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:57:33,504 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:57:35,139 [dl_trainer.py:731] WARNING [118][23240/  196][rank:0] loss: 0.136, average forward (0.009046) and backward (0.018513) time: 0.033074, iotime: 0.005254 
2022-08-04 09:57:35,402 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045410, Speed: 704.695029 images/s
2022-08-04 09:57:36,789 [dl_trainer.py:731] WARNING [118][23280/  196][rank:0] loss: 0.075, average forward (0.009425) and backward (0.015857) time: 0.026803, iotime: 0.001291 
2022-08-04 09:57:37,043 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041007, Speed: 780.349579 images/s
2022-08-04 09:57:38,410 [dl_trainer.py:731] WARNING [118][23320/  196][rank:0] loss: 0.052, average forward (0.009209) and backward (0.016777) time: 0.027475, iotime: 0.001271 
2022-08-04 09:57:38,585 [dl_trainer.py:634] INFO train iter: 23324, num_batches_per_epoch: 196
2022-08-04 09:57:38,586 [dl_trainer.py:635] INFO Epoch 119, avg train acc: 97.305485, lr: 0.001000, avg loss: 0.081187
2022-08-04 09:57:41,218 [dl_trainer.py:822] INFO Epoch 119, lr: 0.001000, val loss: 0.395520, val top-1 acc: 89.486821, top-5 acc: 99.660543
2022-08-04 09:57:41,315 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.106801, Speed: 299.623055 images/s
2022-08-04 09:57:42,758 [dl_trainer.py:731] WARNING [119][23360/  196][rank:0] loss: 0.019, average forward (0.010088) and backward (0.018913) time: 0.096581, iotime: 0.001457 
2022-08-04 09:57:43,045 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043225, Speed: 740.309013 images/s
2022-08-04 09:57:44,509 [dl_trainer.py:731] WARNING [119][23400/  196][rank:0] loss: 0.058, average forward (0.009118) and backward (0.017604) time: 0.028321, iotime: 0.001375 
2022-08-04 09:57:44,527 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:57:44,527 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:57:46,338 [dl_trainer.py:731] WARNING [119][23440/  196][rank:0] loss: 0.128, average forward (0.009677) and backward (0.018806) time: 0.033985, iotime: 0.005238 
2022-08-04 09:57:46,399 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044702, Speed: 715.847226 images/s
2022-08-04 09:57:48,059 [dl_trainer.py:731] WARNING [119][23480/  196][rank:0] loss: 0.116, average forward (0.009801) and backward (0.016717) time: 0.028157, iotime: 0.001406 
2022-08-04 09:57:48,110 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042766, Speed: 748.262049 images/s
2022-08-04 09:57:49,758 [dl_trainer.py:731] WARNING [119][23520/  196][rank:0] loss: 0.016, average forward (0.010401) and backward (0.015653) time: 0.027696, iotime: 0.001397 
2022-08-04 09:57:49,773 [dl_trainer.py:634] INFO train iter: 23520, num_batches_per_epoch: 196
2022-08-04 09:57:49,773 [dl_trainer.py:635] INFO Epoch 120, avg train acc: 97.496811, lr: 0.001000, avg loss: 0.071236
2022-08-04 09:57:52,441 [dl_trainer.py:822] INFO Epoch 120, lr: 0.001000, val loss: 0.388348, val top-1 acc: 89.556709, top-5 acc: 99.600639
2022-08-04 09:57:52,507 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109923, Speed: 291.113314 images/s
2022-08-04 09:57:54,231 [dl_trainer.py:731] WARNING [120][23560/  196][rank:0] loss: 0.092, average forward (0.010297) and backward (0.016312) time: 0.095626, iotime: 0.001500 
2022-08-04 09:57:54,296 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044696, Speed: 715.950358 images/s
2022-08-04 09:57:55,845 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:57:55,845 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:57:56,201 [dl_trainer.py:731] WARNING [120][23600/  196][rank:0] loss: 0.116, average forward (0.009898) and backward (0.018749) time: 0.034187, iotime: 0.005268 
2022-08-04 09:57:57,795 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046641, Speed: 686.090746 images/s
2022-08-04 09:57:57,968 [dl_trainer.py:731] WARNING [120][23640/  196][rank:0] loss: 0.077, average forward (0.009679) and backward (0.019658) time: 0.030942, iotime: 0.001368 
2022-08-04 09:57:59,516 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043010, Speed: 744.010608 images/s
2022-08-04 09:57:59,674 [dl_trainer.py:731] WARNING [120][23680/  196][rank:0] loss: 0.021, average forward (0.010324) and backward (0.018021) time: 0.030021, iotime: 0.001424 
2022-08-04 09:58:01,218 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042542, Speed: 752.192372 images/s
2022-08-04 09:58:01,219 [dl_trainer.py:634] INFO train iter: 23716, num_batches_per_epoch: 196
2022-08-04 09:58:01,219 [dl_trainer.py:635] INFO Epoch 121, avg train acc: 97.289541, lr: 0.001000, avg loss: 0.077182
2022-08-04 09:58:03,859 [dl_trainer.py:822] INFO Epoch 121, lr: 0.001000, val loss: 0.386592, val top-1 acc: 89.746406, top-5 acc: 99.660543
2022-08-04 09:58:04,033 [dl_trainer.py:731] WARNING [121][23720/  196][rank:0] loss: 0.158, average forward (0.010436) and backward (0.018419) time: 0.096601, iotime: 0.001436 
2022-08-04 09:58:05,689 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111755, Speed: 286.341141 images/s
2022-08-04 09:58:05,849 [dl_trainer.py:731] WARNING [121][23760/  196][rank:0] loss: 0.073, average forward (0.009659) and backward (0.020023) time: 0.031313, iotime: 0.001399 
2022-08-04 09:58:07,315 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:58:07,315 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:58:07,911 [dl_trainer.py:731] WARNING [121][23800/  196][rank:0] loss: 0.071, average forward (0.010723) and backward (0.018683) time: 0.035155, iotime: 0.005465 
2022-08-04 09:58:09,296 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048074, Speed: 665.638217 images/s
2022-08-04 09:58:09,667 [dl_trainer.py:731] WARNING [121][23840/  196][rank:0] loss: 0.132, average forward (0.009580) and backward (0.018981) time: 0.030222, iotime: 0.001425 
2022-08-04 09:58:10,955 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041468, Speed: 771.678361 images/s
2022-08-04 09:58:11,311 [dl_trainer.py:731] WARNING [121][23880/  196][rank:0] loss: 0.034, average forward (0.009679) and backward (0.017379) time: 0.028674, iotime: 0.001359 
2022-08-04 09:58:12,718 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044047, Speed: 726.502333 images/s
2022-08-04 09:58:12,767 [dl_trainer.py:634] INFO train iter: 23912, num_batches_per_epoch: 196
2022-08-04 09:58:12,767 [dl_trainer.py:635] INFO Epoch 122, avg train acc: 97.783801, lr: 0.001000, avg loss: 0.068407
2022-08-04 09:58:15,392 [dl_trainer.py:822] INFO Epoch 122, lr: 0.001000, val loss: 0.393019, val top-1 acc: 89.836262, top-5 acc: 99.610623
2022-08-04 09:58:15,762 [dl_trainer.py:731] WARNING [122][23920/  196][rank:0] loss: 0.103, average forward (0.009063) and backward (0.017454) time: 0.094334, iotime: 0.001411 
2022-08-04 09:58:17,154 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110898, Speed: 288.552763 images/s
2022-08-04 09:58:17,512 [dl_trainer.py:731] WARNING [122][23960/  196][rank:0] loss: 0.197, average forward (0.009508) and backward (0.016294) time: 0.027515, iotime: 0.001463 
2022-08-04 09:58:18,582 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:58:18,582 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:58:19,385 [dl_trainer.py:731] WARNING [122][24000/  196][rank:0] loss: 0.042, average forward (0.009302) and backward (0.016425) time: 0.031126, iotime: 0.005145 
2022-08-04 09:58:20,498 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044561, Speed: 718.115332 images/s
2022-08-04 09:58:21,104 [dl_trainer.py:731] WARNING [122][24040/  196][rank:0] loss: 0.022, average forward (0.009159) and backward (0.018896) time: 0.029640, iotime: 0.001344 
2022-08-04 09:58:22,330 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045787, Speed: 698.891778 images/s
2022-08-04 09:58:23,000 [dl_trainer.py:731] WARNING [122][24080/  196][rank:0] loss: 0.181, average forward (0.011073) and backward (0.020850) time: 0.033762, iotime: 0.001569 
2022-08-04 09:58:24,107 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044429, Speed: 720.252925 images/s
2022-08-04 09:58:24,189 [dl_trainer.py:634] INFO train iter: 24108, num_batches_per_epoch: 196
2022-08-04 09:58:24,189 [dl_trainer.py:635] INFO Epoch 123, avg train acc: 97.241709, lr: 0.000100, avg loss: 0.077149
2022-08-04 09:58:26,857 [dl_trainer.py:822] INFO Epoch 123, lr: 0.000100, val loss: 0.387994, val top-1 acc: 89.806310, top-5 acc: 99.650559
2022-08-04 09:58:27,392 [dl_trainer.py:731] WARNING [123][24120/  196][rank:0] loss: 0.069, average forward (0.009419) and backward (0.017607) time: 0.095383, iotime: 0.001338 
2022-08-04 09:58:28,541 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110844, Speed: 288.693187 images/s
2022-08-04 09:58:29,110 [dl_trainer.py:731] WARNING [123][24160/  196][rank:0] loss: 0.133, average forward (0.009527) and backward (0.017647) time: 0.028795, iotime: 0.001377 
2022-08-04 09:58:30,050 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:58:30,050 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:58:31,024 [dl_trainer.py:731] WARNING [123][24200/  196][rank:0] loss: 0.149, average forward (0.009817) and backward (0.017573) time: 0.033086, iotime: 0.005426 
2022-08-04 09:58:31,932 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045192, Speed: 708.090076 images/s
2022-08-04 09:58:32,679 [dl_trainer.py:731] WARNING [123][24240/  196][rank:0] loss: 0.032, average forward (0.010460) and backward (0.016835) time: 0.028946, iotime: 0.001395 
2022-08-04 09:58:33,547 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.040362, Speed: 792.830779 images/s
2022-08-04 09:58:34,377 [dl_trainer.py:731] WARNING [123][24280/  196][rank:0] loss: 0.027, average forward (0.009166) and backward (0.018099) time: 0.028874, iotime: 0.001380 
2022-08-04 09:58:35,374 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045661, Speed: 700.817768 images/s
2022-08-04 09:58:35,514 [dl_trainer.py:634] INFO train iter: 24304, num_batches_per_epoch: 196
2022-08-04 09:58:35,515 [dl_trainer.py:635] INFO Epoch 124, avg train acc: 97.863520, lr: 0.000100, avg loss: 0.065142
2022-08-04 09:58:38,172 [dl_trainer.py:822] INFO Epoch 124, lr: 0.000100, val loss: 0.385049, val top-1 acc: 89.776358, top-5 acc: 99.650559
2022-08-04 09:58:38,901 [dl_trainer.py:731] WARNING [124][24320/  196][rank:0] loss: 0.042, average forward (0.009863) and backward (0.017585) time: 0.096093, iotime: 0.001430 
2022-08-04 09:58:39,797 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110578, Speed: 289.387689 images/s
2022-08-04 09:58:40,630 [dl_trainer.py:731] WARNING [124][24360/  196][rank:0] loss: 0.079, average forward (0.009202) and backward (0.016182) time: 0.026984, iotime: 0.001355 
2022-08-04 09:58:41,281 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:58:41,281 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:58:42,535 [dl_trainer.py:731] WARNING [124][24400/  196][rank:0] loss: 0.043, average forward (0.009591) and backward (0.018989) time: 0.034078, iotime: 0.005238 
2022-08-04 09:58:43,264 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046208, Speed: 692.522869 images/s
2022-08-04 09:58:44,299 [dl_trainer.py:731] WARNING [124][24440/  196][rank:0] loss: 0.175, average forward (0.010966) and backward (0.018458) time: 0.031238, iotime: 0.001556 
2022-08-04 09:58:45,018 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043825, Speed: 730.179612 images/s
2022-08-04 09:58:46,074 [dl_trainer.py:731] WARNING [124][24480/  196][rank:0] loss: 0.127, average forward (0.009004) and backward (0.019907) time: 0.030570, iotime: 0.001435 
2022-08-04 09:58:46,804 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044646, Speed: 716.757469 images/s
2022-08-04 09:58:46,997 [dl_trainer.py:634] INFO train iter: 24500, num_batches_per_epoch: 196
2022-08-04 09:58:46,997 [dl_trainer.py:635] INFO Epoch 125, avg train acc: 97.767857, lr: 0.000100, avg loss: 0.071961
2022-08-04 09:58:49,664 [dl_trainer.py:822] INFO Epoch 125, lr: 0.000100, val loss: 0.383023, val top-1 acc: 89.756390, top-5 acc: 99.660543
2022-08-04 09:58:50,609 [dl_trainer.py:731] WARNING [125][24520/  196][rank:0] loss: 0.044, average forward (0.009296) and backward (0.019049) time: 0.096771, iotime: 0.001437 
2022-08-04 09:58:51,422 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115437, Speed: 277.208352 images/s
2022-08-04 09:58:52,540 [dl_trainer.py:731] WARNING [125][24560/  196][rank:0] loss: 0.041, average forward (0.009897) and backward (0.020008) time: 0.031593, iotime: 0.001437 
2022-08-04 09:58:53,044 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:58:53,044 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:58:54,544 [dl_trainer.py:731] WARNING [125][24600/  196][rank:0] loss: 0.102, average forward (0.009702) and backward (0.019086) time: 0.034385, iotime: 0.005319 
2022-08-04 09:58:55,069 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048613, Speed: 658.258308 images/s
2022-08-04 09:58:56,382 [dl_trainer.py:731] WARNING [125][24640/  196][rank:0] loss: 0.059, average forward (0.010675) and backward (0.020762) time: 0.033242, iotime: 0.001543 
2022-08-04 09:58:56,893 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045596, Speed: 701.816995 images/s
2022-08-04 09:58:58,251 [dl_trainer.py:731] WARNING [125][24680/  196][rank:0] loss: 0.170, average forward (0.011574) and backward (0.020641) time: 0.034194, iotime: 0.001683 
2022-08-04 09:58:58,775 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047026, Speed: 680.471664 images/s
2022-08-04 09:58:59,028 [dl_trainer.py:634] INFO train iter: 24696, num_batches_per_epoch: 196
2022-08-04 09:58:59,028 [dl_trainer.py:635] INFO Epoch 126, avg train acc: 97.863520, lr: 0.000100, avg loss: 0.067866
2022-08-04 09:59:01,645 [dl_trainer.py:822] INFO Epoch 126, lr: 0.000100, val loss: 0.385360, val top-1 acc: 89.806310, top-5 acc: 99.650559
2022-08-04 09:59:02,757 [dl_trainer.py:731] WARNING [126][24720/  196][rank:0] loss: 0.023, average forward (0.010246) and backward (0.021686) time: 0.099713, iotime: 0.001546 
2022-08-04 09:59:03,293 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.112936, Speed: 283.345403 images/s
2022-08-04 09:59:04,617 [dl_trainer.py:731] WARNING [126][24760/  196][rank:0] loss: 0.037, average forward (0.010082) and backward (0.020555) time: 0.032372, iotime: 0.001480 
2022-08-04 09:59:04,866 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:59:04,866 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:59:06,489 [dl_trainer.py:731] WARNING [126][24800/  196][rank:0] loss: 0.058, average forward (0.009441) and backward (0.017652) time: 0.032763, iotime: 0.005415 
2022-08-04 09:59:06,794 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046665, Speed: 685.733998 images/s
2022-08-04 09:59:08,288 [dl_trainer.py:731] WARNING [126][24840/  196][rank:0] loss: 0.039, average forward (0.008674) and backward (0.019212) time: 0.029418, iotime: 0.001309 
2022-08-04 09:59:08,586 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044779, Speed: 714.628070 images/s
2022-08-04 09:59:10,066 [dl_trainer.py:731] WARNING [126][24880/  196][rank:0] loss: 0.070, average forward (0.008827) and backward (0.018317) time: 0.028710, iotime: 0.001326 
2022-08-04 09:59:10,343 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043926, Speed: 728.490900 images/s
2022-08-04 09:59:10,596 [dl_trainer.py:634] INFO train iter: 24892, num_batches_per_epoch: 196
2022-08-04 09:59:10,596 [dl_trainer.py:635] INFO Epoch 127, avg train acc: 97.704082, lr: 0.000100, avg loss: 0.067055
2022-08-04 09:59:13,405 [dl_trainer.py:822] INFO Epoch 127, lr: 0.000100, val loss: 0.385951, val top-1 acc: 89.846246, top-5 acc: 99.650559
2022-08-04 09:59:14,660 [dl_trainer.py:731] WARNING [127][24920/  196][rank:0] loss: 0.014, average forward (0.010076) and backward (0.018635) time: 0.100730, iotime: 0.001492 
2022-08-04 09:59:14,945 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115044, Speed: 278.153961 images/s
2022-08-04 09:59:16,533 [dl_trainer.py:731] WARNING [127][24960/  196][rank:0] loss: 0.021, average forward (0.010278) and backward (0.020249) time: 0.032286, iotime: 0.001483 
2022-08-04 09:59:16,544 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:59:16,544 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:59:18,522 [dl_trainer.py:731] WARNING [127][25000/  196][rank:0] loss: 0.012, average forward (0.009262) and backward (0.019801) time: 0.034893, iotime: 0.005565 
2022-08-04 09:59:18,599 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048697, Speed: 657.125469 images/s
2022-08-04 09:59:20,277 [dl_trainer.py:731] WARNING [127][25040/  196][rank:0] loss: 0.091, average forward (0.009367) and backward (0.020168) time: 0.031212, iotime: 0.001434 
2022-08-04 09:59:20,327 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043189, Speed: 740.925090 images/s
2022-08-04 09:59:22,092 [dl_trainer.py:731] WARNING [127][25080/  196][rank:0] loss: 0.026, average forward (0.010313) and backward (0.018242) time: 0.030268, iotime: 0.001469 
2022-08-04 09:59:22,139 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045296, Speed: 706.464682 images/s
2022-08-04 09:59:22,461 [dl_trainer.py:634] INFO train iter: 25088, num_batches_per_epoch: 196
2022-08-04 09:59:22,461 [dl_trainer.py:635] INFO Epoch 128, avg train acc: 97.911352, lr: 0.000100, avg loss: 0.066824
2022-08-04 09:59:25,119 [dl_trainer.py:822] INFO Epoch 128, lr: 0.000100, val loss: 0.383815, val top-1 acc: 89.856230, top-5 acc: 99.670527
2022-08-04 09:59:26,544 [dl_trainer.py:731] WARNING [128][25120/  196][rank:0] loss: 0.026, average forward (0.010783) and backward (0.020275) time: 0.099788, iotime: 0.001514 
2022-08-04 09:59:26,597 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111430, Speed: 287.174758 images/s
2022-08-04 09:59:28,074 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:59:28,074 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:59:28,444 [dl_trainer.py:731] WARNING [128][25160/  196][rank:0] loss: 0.050, average forward (0.009875) and backward (0.018542) time: 0.033964, iotime: 0.005282 
2022-08-04 09:59:29,946 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044645, Speed: 716.759862 images/s
2022-08-04 09:59:30,102 [dl_trainer.py:731] WARNING [128][25200/  196][rank:0] loss: 0.029, average forward (0.008985) and backward (0.017734) time: 0.028289, iotime: 0.001345 
2022-08-04 09:59:31,795 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046204, Speed: 692.582952 images/s
2022-08-04 09:59:31,960 [dl_trainer.py:731] WARNING [128][25240/  196][rank:0] loss: 0.051, average forward (0.012520) and backward (0.021497) time: 0.035969, iotime: 0.001650 
2022-08-04 09:59:33,542 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043671, Speed: 732.746411 images/s
2022-08-04 09:59:33,701 [dl_trainer.py:731] WARNING [128][25280/  196][rank:0] loss: 0.123, average forward (0.010402) and backward (0.018857) time: 0.031022, iotime: 0.001511 
2022-08-04 09:59:33,880 [dl_trainer.py:634] INFO train iter: 25284, num_batches_per_epoch: 196
2022-08-04 09:59:33,881 [dl_trainer.py:635] INFO Epoch 129, avg train acc: 97.464923, lr: 0.000100, avg loss: 0.070945
2022-08-04 09:59:36,574 [dl_trainer.py:822] INFO Epoch 129, lr: 0.000100, val loss: 0.384532, val top-1 acc: 89.816294, top-5 acc: 99.620607
2022-08-04 09:59:37,981 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110969, Speed: 288.369766 images/s
2022-08-04 09:59:38,142 [dl_trainer.py:731] WARNING [129][25320/  196][rank:0] loss: 0.032, average forward (0.010854) and backward (0.015452) time: 0.095602, iotime: 0.001612 
2022-08-04 09:59:39,465 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:59:39,465 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:59:40,041 [dl_trainer.py:731] WARNING [129][25360/  196][rank:0] loss: 0.067, average forward (0.009342) and backward (0.016093) time: 0.030923, iotime: 0.005218 
2022-08-04 09:59:41,343 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044805, Speed: 714.201509 images/s
2022-08-04 09:59:41,714 [dl_trainer.py:731] WARNING [129][25400/  196][rank:0] loss: 0.093, average forward (0.009256) and backward (0.017748) time: 0.028595, iotime: 0.001367 
2022-08-04 09:59:43,045 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042542, Speed: 752.190686 images/s
2022-08-04 09:59:43,441 [dl_trainer.py:731] WARNING [129][25440/  196][rank:0] loss: 0.053, average forward (0.009434) and backward (0.017231) time: 0.028293, iotime: 0.001392 
2022-08-04 09:59:44,865 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045490, Speed: 703.447673 images/s
2022-08-04 09:59:45,238 [dl_trainer.py:731] WARNING [129][25480/  196][rank:0] loss: 0.025, average forward (0.009765) and backward (0.018856) time: 0.030321, iotime: 0.001439 
2022-08-04 09:59:45,246 [dl_trainer.py:634] INFO train iter: 25480, num_batches_per_epoch: 196
2022-08-04 09:59:45,246 [dl_trainer.py:635] INFO Epoch 130, avg train acc: 97.799745, lr: 0.000100, avg loss: 0.068678
2022-08-04 09:59:47,936 [dl_trainer.py:822] INFO Epoch 130, lr: 0.000100, val loss: 0.382014, val top-1 acc: 89.816294, top-5 acc: 99.710463
2022-08-04 09:59:49,304 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110964, Speed: 288.382452 images/s
2022-08-04 09:59:49,715 [dl_trainer.py:731] WARNING [130][25520/  196][rank:0] loss: 0.031, average forward (0.009533) and backward (0.015760) time: 0.094748, iotime: 0.001378 
2022-08-04 09:59:50,806 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 09:59:50,807 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 09:59:51,644 [dl_trainer.py:731] WARNING [130][25560/  196][rank:0] loss: 0.048, average forward (0.009215) and backward (0.018267) time: 0.032873, iotime: 0.005149 
2022-08-04 09:59:52,903 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047970, Speed: 667.085195 images/s
2022-08-04 09:59:53,545 [dl_trainer.py:731] WARNING [130][25600/  196][rank:0] loss: 0.035, average forward (0.009518) and backward (0.020830) time: 0.032014, iotime: 0.001421 
2022-08-04 09:59:54,767 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046562, Speed: 687.257929 images/s
2022-08-04 09:59:55,425 [dl_trainer.py:731] WARNING [130][25640/  196][rank:0] loss: 0.068, average forward (0.008933) and backward (0.019978) time: 0.030496, iotime: 0.001351 
2022-08-04 09:59:56,609 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046042, Speed: 695.021173 images/s
2022-08-04 09:59:57,083 [dl_trainer.py:634] INFO train iter: 25676, num_batches_per_epoch: 196
2022-08-04 09:59:57,084 [dl_trainer.py:635] INFO Epoch 131, avg train acc: 97.528699, lr: 0.000100, avg loss: 0.072824
2022-08-04 09:59:59,793 [dl_trainer.py:822] INFO Epoch 131, lr: 0.000100, val loss: 0.383496, val top-1 acc: 89.766374, top-5 acc: 99.650559
2022-08-04 09:59:59,969 [dl_trainer.py:731] WARNING [131][25680/  196][rank:0] loss: 0.027, average forward (0.009070) and backward (0.019830) time: 0.098374, iotime: 0.001431 
2022-08-04 10:00:01,223 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115360, Speed: 277.392931 images/s
2022-08-04 10:00:01,896 [dl_trainer.py:731] WARNING [131][25720/  196][rank:0] loss: 0.034, average forward (0.009259) and backward (0.020762) time: 0.031707, iotime: 0.001437 
2022-08-04 10:00:02,847 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:00:02,848 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:00:03,848 [dl_trainer.py:731] WARNING [131][25760/  196][rank:0] loss: 0.012, average forward (0.011440) and backward (0.019423) time: 0.036727, iotime: 0.005568 
2022-08-04 10:00:04,789 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047528, Speed: 673.293992 images/s
2022-08-04 10:00:05,620 [dl_trainer.py:731] WARNING [131][25800/  196][rank:0] loss: 0.063, average forward (0.010379) and backward (0.017435) time: 0.029514, iotime: 0.001448 
2022-08-04 10:00:06,524 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043345, Speed: 738.265138 images/s
2022-08-04 10:00:07,309 [dl_trainer.py:731] WARNING [131][25840/  196][rank:0] loss: 0.035, average forward (0.009800) and backward (0.017456) time: 0.028846, iotime: 0.001353 
2022-08-04 10:00:08,209 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.042121, Speed: 759.717040 images/s
2022-08-04 10:00:08,651 [dl_trainer.py:634] INFO train iter: 25872, num_batches_per_epoch: 196
2022-08-04 10:00:08,651 [dl_trainer.py:635] INFO Epoch 132, avg train acc: 97.656250, lr: 0.000100, avg loss: 0.068811
2022-08-04 10:00:11,313 [dl_trainer.py:822] INFO Epoch 132, lr: 0.000100, val loss: 0.383115, val top-1 acc: 89.756390, top-5 acc: 99.640575
2022-08-04 10:00:11,669 [dl_trainer.py:731] WARNING [132][25880/  196][rank:0] loss: 0.053, average forward (0.009422) and backward (0.014868) time: 0.093113, iotime: 0.001398 
2022-08-04 10:00:12,649 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110984, Speed: 288.329871 images/s
2022-08-04 10:00:13,450 [dl_trainer.py:731] WARNING [132][25920/  196][rank:0] loss: 0.023, average forward (0.010353) and backward (0.017003) time: 0.029051, iotime: 0.001450 
2022-08-04 10:00:14,113 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:00:14,113 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:00:15,426 [dl_trainer.py:731] WARNING [132][25960/  196][rank:0] loss: 0.146, average forward (0.009265) and backward (0.020646) time: 0.035148, iotime: 0.004974 
2022-08-04 10:00:16,231 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047748, Speed: 670.180724 images/s
2022-08-04 10:00:17,357 [dl_trainer.py:731] WARNING [132][26000/  196][rank:0] loss: 0.052, average forward (0.010298) and backward (0.019674) time: 0.031700, iotime: 0.001478 
2022-08-04 10:00:18,111 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047004, Speed: 680.793177 images/s
2022-08-04 10:00:19,225 [dl_trainer.py:731] WARNING [132][26040/  196][rank:0] loss: 0.110, average forward (0.010700) and backward (0.020036) time: 0.032554, iotime: 0.001547 
2022-08-04 10:00:19,997 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047126, Speed: 679.032557 images/s
2022-08-04 10:00:20,536 [dl_trainer.py:634] INFO train iter: 26068, num_batches_per_epoch: 196
2022-08-04 10:00:20,536 [dl_trainer.py:635] INFO Epoch 133, avg train acc: 97.735969, lr: 0.000100, avg loss: 0.072529
2022-08-04 10:00:23,191 [dl_trainer.py:822] INFO Epoch 133, lr: 0.000100, val loss: 0.382195, val top-1 acc: 89.736422, top-5 acc: 99.680511
2022-08-04 10:00:23,717 [dl_trainer.py:731] WARNING [133][26080/  196][rank:0] loss: 0.031, average forward (0.010094) and backward (0.019289) time: 0.097486, iotime: 0.001417 
2022-08-04 10:00:24,374 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109409, Speed: 292.479923 images/s
2022-08-04 10:00:25,467 [dl_trainer.py:731] WARNING [133][26120/  196][rank:0] loss: 0.053, average forward (0.009726) and backward (0.019874) time: 0.031257, iotime: 0.001424 
2022-08-04 10:00:25,918 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:00:25,918 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:00:27,375 [dl_trainer.py:731] WARNING [133][26160/  196][rank:0] loss: 0.104, average forward (0.010094) and backward (0.019290) time: 0.034605, iotime: 0.004954 
2022-08-04 10:00:27,877 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046698, Speed: 685.256874 images/s
2022-08-04 10:00:29,181 [dl_trainer.py:731] WARNING [133][26200/  196][rank:0] loss: 0.039, average forward (0.009538) and backward (0.019277) time: 0.030437, iotime: 0.001390 
2022-08-04 10:00:29,732 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046362, Speed: 690.225132 images/s
2022-08-04 10:00:31,078 [dl_trainer.py:731] WARNING [133][26240/  196][rank:0] loss: 0.013, average forward (0.010546) and backward (0.019794) time: 0.032247, iotime: 0.001599 
2022-08-04 10:00:31,618 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047133, Speed: 678.933977 images/s
2022-08-04 10:00:32,249 [dl_trainer.py:634] INFO train iter: 26264, num_batches_per_epoch: 196
2022-08-04 10:00:32,250 [dl_trainer.py:635] INFO Epoch 134, avg train acc: 97.735969, lr: 0.000100, avg loss: 0.074106
2022-08-04 10:00:34,948 [dl_trainer.py:822] INFO Epoch 134, lr: 0.000100, val loss: 0.387885, val top-1 acc: 89.716454, top-5 acc: 99.660543
2022-08-04 10:00:35,660 [dl_trainer.py:731] WARNING [134][26280/  196][rank:0] loss: 0.151, average forward (0.010010) and backward (0.018995) time: 0.099396, iotime: 0.001475 
2022-08-04 10:00:36,207 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.114703, Speed: 278.981080 images/s
2022-08-04 10:00:37,435 [dl_trainer.py:731] WARNING [134][26320/  196][rank:0] loss: 0.047, average forward (0.009861) and backward (0.016538) time: 0.028085, iotime: 0.001446 
2022-08-04 10:00:37,704 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:00:37,704 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:00:39,395 [dl_trainer.py:731] WARNING [134][26360/  196][rank:0] loss: 0.031, average forward (0.009367) and backward (0.017923) time: 0.032601, iotime: 0.005047 
2022-08-04 10:00:39,690 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046421, Speed: 689.341908 images/s
2022-08-04 10:00:41,182 [dl_trainer.py:731] WARNING [134][26400/  196][rank:0] loss: 0.090, average forward (0.008726) and backward (0.018363) time: 0.028599, iotime: 0.001285 
2022-08-04 10:00:41,427 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043429, Speed: 736.838488 images/s
2022-08-04 10:00:42,915 [dl_trainer.py:731] WARNING [134][26440/  196][rank:0] loss: 0.029, average forward (0.009959) and backward (0.014274) time: 0.025990, iotime: 0.001496 
2022-08-04 10:00:43,207 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044487, Speed: 719.304907 images/s
2022-08-04 10:00:43,840 [dl_trainer.py:634] INFO train iter: 26460, num_batches_per_epoch: 196
2022-08-04 10:00:43,841 [dl_trainer.py:635] INFO Epoch 135, avg train acc: 97.640306, lr: 0.000100, avg loss: 0.071561
2022-08-04 10:00:46,523 [dl_trainer.py:822] INFO Epoch 135, lr: 0.000100, val loss: 0.389049, val top-1 acc: 89.826278, top-5 acc: 99.630591
2022-08-04 10:00:47,352 [dl_trainer.py:731] WARNING [135][26480/  196][rank:0] loss: 0.092, average forward (0.010482) and backward (0.014194) time: 0.093601, iotime: 0.001523 
2022-08-04 10:00:47,638 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.110768, Speed: 288.891300 images/s
2022-08-04 10:00:49,050 [dl_trainer.py:731] WARNING [135][26520/  196][rank:0] loss: 0.040, average forward (0.009781) and backward (0.018893) time: 0.030368, iotime: 0.001411 
2022-08-04 10:00:49,072 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:00:49,073 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:00:50,916 [dl_trainer.py:731] WARNING [135][26560/  196][rank:0] loss: 0.090, average forward (0.009616) and backward (0.018706) time: 0.034300, iotime: 0.005696 
2022-08-04 10:00:50,966 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044355, Speed: 721.453294 images/s
2022-08-04 10:00:52,553 [dl_trainer.py:731] WARNING [135][26600/  196][rank:0] loss: 0.064, average forward (0.008919) and backward (0.018672) time: 0.029139, iotime: 0.001327 
2022-08-04 10:00:52,610 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041081, Speed: 778.949935 images/s
2022-08-04 10:00:54,229 [dl_trainer.py:731] WARNING [135][26640/  196][rank:0] loss: 0.068, average forward (0.010225) and backward (0.015235) time: 0.027156, iotime: 0.001432 
2022-08-04 10:00:54,286 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.041887, Speed: 763.951315 images/s
2022-08-04 10:00:54,918 [dl_trainer.py:634] INFO train iter: 26656, num_batches_per_epoch: 196
2022-08-04 10:00:54,919 [dl_trainer.py:635] INFO Epoch 136, avg train acc: 97.608418, lr: 0.000100, avg loss: 0.073422
2022-08-04 10:00:57,588 [dl_trainer.py:822] INFO Epoch 136, lr: 0.000100, val loss: 0.391998, val top-1 acc: 89.846246, top-5 acc: 99.680511
2022-08-04 10:00:58,611 [dl_trainer.py:731] WARNING [136][26680/  196][rank:0] loss: 0.151, average forward (0.010047) and backward (0.019006) time: 0.098030, iotime: 0.001461 
2022-08-04 10:00:58,663 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.109404, Speed: 292.492910 images/s
2022-08-04 10:01:00,213 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:01:00,214 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:01:00,593 [dl_trainer.py:731] WARNING [136][26720/  196][rank:0] loss: 0.015, average forward (0.010428) and backward (0.018967) time: 0.034786, iotime: 0.005109 
2022-08-04 10:01:02,236 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047632, Speed: 671.813796 images/s
2022-08-04 10:01:02,413 [dl_trainer.py:731] WARNING [136][26760/  196][rank:0] loss: 0.075, average forward (0.010321) and backward (0.019080) time: 0.031104, iotime: 0.001448 
2022-08-04 10:01:04,118 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047028, Speed: 680.441478 images/s
2022-08-04 10:01:04,298 [dl_trainer.py:731] WARNING [136][26800/  196][rank:0] loss: 0.065, average forward (0.009785) and backward (0.020345) time: 0.031854, iotime: 0.001475 
2022-08-04 10:01:05,984 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046654, Speed: 685.897861 images/s
2022-08-04 10:01:06,171 [dl_trainer.py:731] WARNING [136][26840/  196][rank:0] loss: 0.024, average forward (0.009516) and backward (0.019229) time: 0.030411, iotime: 0.001418 
2022-08-04 10:01:06,770 [dl_trainer.py:634] INFO train iter: 26852, num_batches_per_epoch: 196
2022-08-04 10:01:06,771 [dl_trainer.py:635] INFO Epoch 137, avg train acc: 97.608418, lr: 0.000100, avg loss: 0.069926
2022-08-04 10:01:09,405 [dl_trainer.py:822] INFO Epoch 137, lr: 0.000100, val loss: 0.384991, val top-1 acc: 89.816294, top-5 acc: 99.640575
2022-08-04 10:01:10,445 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.111510, Speed: 286.970477 images/s
2022-08-04 10:01:10,581 [dl_trainer.py:731] WARNING [137][26880/  196][rank:0] loss: 0.266, average forward (0.008959) and backward (0.019147) time: 0.095577, iotime: 0.001313 
2022-08-04 10:01:11,913 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:01:11,913 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:01:12,481 [dl_trainer.py:731] WARNING [137][26920/  196][rank:0] loss: 0.025, average forward (0.009624) and backward (0.017296) time: 0.032241, iotime: 0.005046 
2022-08-04 10:01:13,842 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045268, Speed: 706.902736 images/s
2022-08-04 10:01:14,208 [dl_trainer.py:731] WARNING [137][26960/  196][rank:0] loss: 0.031, average forward (0.009582) and backward (0.018249) time: 0.029508, iotime: 0.001431 
2022-08-04 10:01:15,700 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.046435, Speed: 689.134400 images/s
2022-08-04 10:01:16,119 [dl_trainer.py:731] WARNING [137][27000/  196][rank:0] loss: 0.137, average forward (0.009962) and backward (0.022110) time: 0.033800, iotime: 0.001477 
2022-08-04 10:01:17,650 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.048740, Speed: 656.545982 images/s
2022-08-04 10:01:18,077 [dl_trainer.py:731] WARNING [137][27040/  196][rank:0] loss: 0.056, average forward (0.009953) and backward (0.021617) time: 0.033351, iotime: 0.001516 
2022-08-04 10:01:18,476 [dl_trainer.py:634] INFO train iter: 27048, num_batches_per_epoch: 196
2022-08-04 10:01:18,477 [dl_trainer.py:635] INFO Epoch 138, avg train acc: 97.576531, lr: 0.000100, avg loss: 0.071670
2022-08-04 10:01:21,144 [dl_trainer.py:822] INFO Epoch 138, lr: 0.000100, val loss: 0.385816, val top-1 acc: 89.706470, top-5 acc: 99.640575
2022-08-04 10:01:22,287 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.115923, Speed: 276.044811 images/s
2022-08-04 10:01:22,713 [dl_trainer.py:731] WARNING [138][27080/  196][rank:0] loss: 0.061, average forward (0.012369) and backward (0.021548) time: 0.103111, iotime: 0.001701 
2022-08-04 10:01:23,945 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:01:23,945 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:01:24,768 [dl_trainer.py:731] WARNING [138][27120/  196][rank:0] loss: 0.026, average forward (0.011792) and backward (0.021526) time: 0.039222, iotime: 0.005594 
2022-08-04 10:01:25,878 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047857, Speed: 668.660067 images/s
2022-08-04 10:01:26,430 [dl_trainer.py:731] WARNING [138][27160/  196][rank:0] loss: 0.081, average forward (0.009397) and backward (0.017381) time: 0.028333, iotime: 0.001335 
2022-08-04 10:01:27,641 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.044059, Speed: 726.306255 images/s
2022-08-04 10:01:28,245 [dl_trainer.py:731] WARNING [138][27200/  196][rank:0] loss: 0.021, average forward (0.009173) and backward (0.020605) time: 0.031333, iotime: 0.001333 
2022-08-04 10:01:29,465 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045595, Speed: 701.835253 images/s
2022-08-04 10:01:30,100 [dl_trainer.py:731] WARNING [138][27240/  196][rank:0] loss: 0.158, average forward (0.008938) and backward (0.020793) time: 0.031312, iotime: 0.001349 
2022-08-04 10:01:30,302 [dl_trainer.py:634] INFO train iter: 27244, num_batches_per_epoch: 196
2022-08-04 10:01:30,302 [dl_trainer.py:635] INFO Epoch 139, avg train acc: 97.305485, lr: 0.000100, avg loss: 0.075663
2022-08-04 10:01:32,980 [dl_trainer.py:822] INFO Epoch 139, lr: 0.000100, val loss: 0.386485, val top-1 acc: 89.836262, top-5 acc: 99.670527
2022-08-04 10:01:34,005 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.113506, Speed: 281.922620 images/s
2022-08-04 10:01:34,602 [dl_trainer.py:731] WARNING [139][27280/  196][rank:0] loss: 0.062, average forward (0.010664) and backward (0.020129) time: 0.099634, iotime: 0.001566 
2022-08-04 10:01:35,558 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:01:35,558 [distributed_optimizer.py:143] INFO The number of selected gradients: []
2022-08-04 10:01:36,603 [dl_trainer.py:731] WARNING [139][27320/  196][rank:0] loss: 0.057, average forward (0.009765) and backward (0.019627) time: 0.035238, iotime: 0.005566 
2022-08-04 10:01:37,582 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.047662, Speed: 671.393856 images/s
2022-08-04 10:01:38,427 [dl_trainer.py:731] WARNING [139][27360/  196][rank:0] loss: 0.053, average forward (0.009772) and backward (0.018041) time: 0.029501, iotime: 0.001409 
2022-08-04 10:01:39,388 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.045142, Speed: 708.866530 images/s
2022-08-04 10:01:40,216 [dl_trainer.py:731] WARNING [139][27400/  196][rank:0] loss: 0.208, average forward (0.010284) and backward (0.018835) time: 0.030882, iotime: 0.001480 
2022-08-04 10:01:41,138 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.043730, Speed: 731.768733 images/s
2022-08-04 10:01:41,988 [dl_trainer.py:731] WARNING [139][27440/  196][rank:0] loss: 0.027, average forward (0.010125) and backward (0.018904) time: 0.030779, iotime: 0.001486 
2022-08-04 10:01:42,001 [dl_trainer.py:634] INFO train iter: 27440, num_batches_per_epoch: 196
2022-08-04 10:01:42,001 [dl_trainer.py:635] INFO Epoch 140, avg train acc: 97.991071, lr: 0.000100, avg loss: 0.064461
2022-08-04 10:01:44,903 [dl_trainer.py:822] INFO Epoch 140, lr: 0.000100, val loss: 0.386252, val top-1 acc: 89.886182, top-5 acc: 99.660543
2022-08-04 10:01:45,893 [dist_trainer.py:90] WARNING Time per iteration including communication: 0.118869, Speed: 269.204344 images/s
2022-08-04 10:01:46,756 [dl_trainer.py:731] WARNING [140][27480/  196][rank:0] loss: 0.137, average forward (0.011990) and backward (0.020693) time: 0.107722, iotime: 0.001638 
2022-08-04 10:01:47,468 [distributed_optimizer.py:142] INFO Average number of selected gradients: nan, exact k: 269
2022-08-04 10:01:47,468 [distributed_optimizer.py:143] INFO The number of selected gradients: []
